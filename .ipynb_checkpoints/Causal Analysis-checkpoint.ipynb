{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Causal Analysis\n",
    "===============\n",
    "\n",
    "(1) Focussed on pairs of variables\n",
    "\n",
    "- cross-lagged correlation\n",
    "\n",
    "- Granger Causality:GC (https://en.wikipedia.org/wiki/Granger_causality)\n",
    "    - does Xt help forecast Yt+1? Doesn't deal with instantaneous causation/non-linear causation/latent confounding variables\n",
    "    - Vector autoregression:VAR (https://en.wikipedia.org/wiki/Vector_autoregression)\n",
    "            - generalises GC to multivariate case\n",
    "            - Python: statsmodels, PyFlux\n",
    "            - R: vars\n",
    "            - Stata: var\n",
    "    - Bayesian VAR (https://en.wikipedia.org/wiki/Bayesian_vector_autoregression)\n",
    "            - more appropriate for shorter time series\n",
    "            - Python: PyFlux\n",
    "            - Stata/Eviews: Can handle (don't know name of module/function!)\n",
    "    - Transfer entropy:TE (https://en.wikipedia.org/wiki/Transfer_entropy)\n",
    "            - generalisation GC to include non-linear interactions\n",
    "            - comes from information theory, has some multivariate implementations\n",
    "\n",
    "- Instrumental Variables: IV (https://en.wikipedia.org/wiki/Instrumental_variables_estimation)\n",
    "    - Python: linearmodels extends statsmodels to cover IV and panel data\n",
    "            Very very clear tutorial (https://bashtage.github.io/linearmodels/doc/iv/examples/advanced-examples.html)\n",
    "                                        \n",
    "    \n",
    "\n",
    "\n",
    "# before I sink more time into an exhaustive review of the theoretical background/applied computational options ...\n",
    "# ... here's one someone made earlier. It even has a nice concluding \"so, which method *should* you use?\"\n",
    "                                        \n",
    "https://towardsdatascience.com/inferring-causality-in-time-series-data-b8b75fe52c46"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"W19_comb\"\n",
    "df_list = [ \"BES_Panel\", \"BES_reduced_with_na\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>jQuery(function() {if (jQuery(\"body.notebook_app\").length == 0) { jQuery(\".input_area\").toggle(); jQuery(\".prompt\").toggle();}});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onclick=\"jQuery('.input_area').toggle(); jQuery('.prompt').toggle();\">Toggle code</button>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var_type (7911, 14)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from IPython.display import display\n",
    "from IPython.display import HTML\n",
    "import IPython.core.display as di # Example: di.display_html('<h3>%s:</h3>' % str, raw=True)\n",
    "\n",
    "# This line will hide code by default when the notebook is exported as HTML\n",
    "di.display_html('<script>jQuery(function() {if (jQuery(\"body.notebook_app\").length == 0) { jQuery(\".input_area\").toggle(); jQuery(\".prompt\").toggle();}});</script>', raw=True)\n",
    "\n",
    "# This line will add a button to toggle visibility of code blocks, for use with the HTML export version\n",
    "di.display_html('''<button onclick=\"jQuery('.input_area').toggle(); jQuery('.prompt').toggle();\">Toggle code</button>''', raw=True)\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt, seaborn as sns\n",
    "import pickle, os, gc, re\n",
    "\n",
    "sns.set();\n",
    "sns.set_palette(\"colorblind\")\n",
    "\n",
    "from IPython.display import display, display_html, HTML\n",
    "from IPython.core.debugger import set_trace\n",
    "# plt.rcParams[\"axes.grid\"] = False\n",
    "\n",
    "import Jupyter_module_loader\n",
    "from utility import *\n",
    "import gaussian_kde\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import holoviews as hv\n",
    "from holoviews import opts\n",
    "\n",
    "encoding = \"ISO-8859-1\"\n",
    "\n",
    "# you should clone this git to a subdirectory called 'BES_analysis_code' (in some directory - I call it BES_analysis - doesn't matter though)\n",
    "# %matplotlib inline\n",
    "(BES_code_folder, BES_small_data_files, BES_data_folder,\n",
    " BES_output_folder, BES_file_manifest, BES_R_data_files) = setup_directories()\n",
    "\n",
    "global BES_Panel, BES_numeric, BES_reduced, BES_reduced_with_na, BES_non_numeric\n",
    "data_subfolder = BES_data_folder + dataset_name + os.sep\n",
    "\n",
    "(manifest, dataset_filename, dataset_description, dataset_citation,\n",
    " dataset_start, dataset_stop, dataset_wave) = get_manifest(dataset_name, BES_file_manifest)\n",
    "\n",
    "for df in df_list:\n",
    "    if df==\"BES_Panel\":\n",
    "        globals()[df]  = pd.read_pickle(data_subfolder + dataset_filename.replace('.dta','.zip'),compression='zip')\n",
    "    else:\n",
    "        globals()[df]  = pd.read_pickle(data_subfolder + df + '.zip',compression='zip' )\n",
    "        globals()[df].replace(-1,np.nan,inplace=True)\n",
    "  \n",
    "(var_type, cat_dictionary, new_old_col_names, old_new_col_names) = get_small_files(data_subfolder, encoding)\n",
    "\n",
    "# get full set of inferred \"cross wave\" auth-lib/left-right values and ages\n",
    "pan_dataset_allr_values = pd.read_pickle(BES_small_data_files + \"pan_dataset_allr_valuesW19\"+\".zip\",compression='zip')\n",
    "pan_dataset_ages = pd.read_csv( BES_small_data_files + \"pan_dataset_ages\"+\".csv\" )\n",
    "pan_dataset_votes = pd.read_pickle(BES_small_data_files + \"pan_dataset_votes\"+\".zip\", compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BES_reduced_with_na = BES_reduced_with_na.set_index(BES_Panel['id']).sort_index()\n",
    "pan_dataset_votes = pan_dataset_votes.set_index(BES_Panel['id']).sort_index()\n",
    "BES_Panel = BES_Panel.set_index('id').sort_index()\n",
    "pan_dataset_allr_values = pan_dataset_allr_values.astype('float32')\n",
    "pan_dataset_ages = pan_dataset_ages.set_index(\"id\").sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:BES_analysis] *",
   "language": "python",
   "name": "conda-env-BES_analysis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
