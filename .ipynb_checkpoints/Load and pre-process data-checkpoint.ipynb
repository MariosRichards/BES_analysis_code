{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Process BES Panel for Wave 8\n",
    "\n",
    "## WORK IN PROGRESS - run this on all updated BES waves\n",
    "\n",
    "# Assign types to each column variables (mostly automatic - but there's room for manual editing)\n",
    "# Modifies categories (harmoning options, harmonising order, dropping weasel terms)\n",
    "# Creates:\n",
    "# var_type (types for column variables)\n",
    "# BES_numeric (fixed version with only useful columns all transformed into numeric values)\n",
    "    # non-numeric categorical values -> index number of category\n",
    "    # floats -> float\n",
    "    # numeric categories (i.e. income intervals/number of children) -> numeric\n",
    "# cat_dictionary\n",
    "    # so you can get the text categories back from the index values as and when it's necessary\n",
    "# BES_non_numeric\n",
    "    # basically everything else! (mostly meta-data - weights)\n",
    "\n",
    "# LIVE: Run all cells -> ~20s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "import re\n",
    "\n",
    "from itertools import cycle\n",
    "from IPython.display import display\n",
    "import pickle, os\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# BES_data_folder = \"../BES_analysis_data/\"\n",
    "# BES_code_folder = \"../BES_analysis_code/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# you should clone this git to this subdirectory (in some directory - I call it BES_analysis - doesn't matter though)\n",
    "\n",
    "if os.getcwd().split(os.sep)[-1] != 'BES_analysis_code':\n",
    "    raise Exception(\"Stop! You're in the wrong directory - should be in 'BES_analysis_code'\")\n",
    "\n",
    "BES_code_folder   = \"../BES_analysis_code/\" # we should be here!\n",
    "BES_small_data_files = BES_code_folder + \"small data files\" + os.sep\n",
    "if not os.path.exists( BES_small_data_files ):\n",
    "    os.makedirs( BES_small_data_files )\n",
    "\n",
    "# we should create these if they don't already exist\n",
    "BES_data_folder   = \"../BES_analysis_data/\"\n",
    "if not os.path.exists( BES_data_folder ):\n",
    "    os.makedirs( BES_data_folder )\n",
    "\n",
    "BES_output_folder = \"../BES_analysis_output/\"\n",
    "if not os.path.exists( BES_output_folder ):\n",
    "    os.makedirs( BES_output_folder )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31197, 312)\n",
      "Wall time: 3.75 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "dataset_name = \"W13_only\"\n",
    "\n",
    "BES_file_manifest = pd.read_csv( BES_small_data_files + \"BES_file_manifest.csv\" )\n",
    "manifest = BES_file_manifest[ BES_file_manifest[\"Name\"] == dataset_name ]\n",
    "\n",
    "filename = manifest[\"Stata_Filename\"].values[0]\n",
    "\n",
    "data_subfolder = BES_data_folder + dataset_name + os.sep\n",
    "\n",
    "Treatment = dataset_name\n",
    "\n",
    "\n",
    "# dataset = \"BES2017_W13_v1.0.dta\"\n",
    "# wave = \"W13_only\"\n",
    "\n",
    "BES_Panel = pd.read_stata( data_subfolder + filename)\n",
    "\n",
    "print( BES_Panel.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## HELPER FUNCTIONS / REPLACEMENT VALUE DICTIONARIES\n",
    "\n",
    "\n",
    "# changing the order of some sets of categories\n",
    "change_cat_dict = {\"Bad time to buy|Good time to buy|Neither good nor bad time to buy|Don't know\": [\"Bad time to buy\",\n",
    "                                                                                                    \"Neither good nor bad time to buy\",\n",
    "                                                                                                    \"Good time to buy\",\n",
    "                                                                                                    \"Don't know\"],\n",
    "                   \"Larger|Smaller|About the same|Don't know\": [\"Larger\", \"About the same\", \"Smaller\",\"Don't know\"],\n",
    "                   \"Yes|No|99.0\":       ['No', 'Yes', '99.0'],\n",
    "                   \"Yes|No|Don't know\": ['No', 'Yes', \"Don't know\"],\n",
    "                   \"Yes|No\" :           ['No', 'Yes'],\n",
    "                   \"Yes|No|Did not vote|Don't know\" : [\"No\",\"Yes\",\"Did not vote\",\"Don't know\"],\n",
    "                   \"Yes, voted|No, did not vote|Donâ??t know\" : ['No, did not vote', 'Yes, voted', 'Donâ??t know'],\n",
    "                   \"Yes, voted|No, did not vote|Don?t know\"   : ['No, did not vote', 'Yes, voted', 'Don?t know'],                   \n",
    "                   \"I would/will not vote|Leave the EU|Stay/remain in the EU|Don't know\": ['Stay/remain in the EU',\n",
    "                                                                                           'Leave the EU', 'I would/will not vote', \"Don't know\"],\n",
    "                   \"Mainly leave|Mainly remain|Fairly evenly divided|Don't know\": [\"Mainly remain\",\n",
    "                                                                                   \"Fairly evenly divided\", \"Mainly leave\", \"Don't know\"],\n",
    "                   \"An individual share in a company|A portfolio of different company shares|The risk is the same|Don't know|Prefer not to say\":\n",
    "                       ['An individual share in a company', 'The risk is the same', 'A portfolio of different company shares',\"Prefer not to say\",\"Don't know\"],\n",
    "                   'An individual share in a company|A portfolio of different company shares|The risk is the same|Don\\x92t know|Prefer not to say':\n",
    "                       ['An individual share in a company', 'The risk is the same', 'A portfolio of different company shares',\"Prefer not to say\",\"Don\\x92t know\"],\n",
    "                   \"No, I have never been a member|Yes, I am a member of a party|I am not a member now but I used to be|Don't know\":\n",
    "                       ['No, I have never been a member', 'I am not a member now but I used to be', 'Yes, I am a member of a party', \"Don't know\"],\n",
    "                   \"Never or practically never|Less often than once a year|Less often but at least once a year|Less often but at least twice a year|Less often but at least once a month|Less often but at least once in two weeks|Once a week or more|Varies too much to say|I am not religious|Don't know\":\n",
    "                       ['I am not religious', 'Never or practically never', 'Less often than once a year',\n",
    "                        'Less often but at least once a year', 'Less often but at least twice a year',\n",
    "                        'Less often but at least once a month', 'Less often but at least once in two weeks',\n",
    "                        'Once a week or more', \"Varies too much to say\",\"Don't know\"],\n",
    "                   \"under Â£5,000 per year|Â£5,000 to Â£9,999 per year|Â£10,000 to Â£14,999 per year|Â£15,000 to Â£19,999 per year|Â£20,000 to Â£24,999 per year|Â£25,000 to Â£29,999 per year|Â£30,000 to Â£34,999 per year|Â£35,000 to Â£39,999 per year|Â£40,000 to Â£44,999 per year|Â£45,000 to Â£49,999 per year|Â£50,000 to Â£59,999 per year|Â£60,000 to Â£69,999 per year|Â£70,000 to Â£99,999 per year|Â£100,000 to Â£149,999 per year|Â£150,000 and over|Don't know|Prefer not to answer\":\n",
    "                       [\"under Â£5,000 per year\",\"Â£5,000 to Â£9,999 per year\",\"Â£10,000 to Â£14,999 per year\",\"Â£15,000 to Â£19,999 per year\",\n",
    "                        \"Â£20,000 to Â£24,999 per year\",\"Â£25,000 to Â£29,999 per year\",\"Â£30,000 to Â£34,999 per year\",\n",
    "                        \"Â£35,000 to Â£39,999 per year\",\"Â£40,000 to Â£44,999 per year\",\"Â£45,000 to Â£49,999 per year\",\n",
    "                        \"Â£50,000 to Â£59,999 per year\",\"Â£60,000 to Â£69,999 per year\",\"Â£70,000 to Â£99,999 per year\",\n",
    "                        \"Â£100,000 to Â£149,999 per year\",\"Â£150,000 and over\",\"Prefer not to answer\",\"Don't know\"],\n",
    "                   \"1|2|3|4|5|6|7|8 or more|Don't know|Prefer not to say\":\n",
    "                       [\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8 or more\",\"Prefer not to say\",\"Don't know\"],\n",
    "                   \"The Yes side|The No side|Neither|Don't know\":\n",
    "                       [\"The Yes side\",\"Neither\",\"The No side\",\"Don't know\"] # is this ordinal - meh?\n",
    "                   \n",
    "                  }\n",
    "\n",
    "# Big set of actual answers **I interpet** as non-answers (and set to NaN)\n",
    "# REALLY MERITS RECHECKING WHAT THE IMPACT OF THIS IS!\n",
    "Weasel_answers = [\"Don't know\", 'Do\\x92t know', 'Dont know', 'Donât know', 'Don??t know',\n",
    "                  \"Prefer not to say\", \"Prefer not to answer\", \"Refused\", \"Unknown\",\n",
    "                  \"Neither\", \"Other\", \"I would/will not vote\", \"Will not vote\",\n",
    "                  \"I would not vote\", \"It depends\", \"Other\",\n",
    "                  \"Don’t follow politics on Facebook\", \"Don't follow politics on twitter\",\n",
    "                  \"Yes, other\", \"Haven't thought about it\",\n",
    "                  \"There wasn't a local election in my area\", \"No, haven't received it\",\n",
    "                  \"I don't know what was negotiated\", \"I never received a response\",\n",
    "                  \"There are not local elections in my area\", \"Can't remember\",\n",
    "                  \"Varies too much to say\", \"Will not state a choice\",\n",
    "                  \"All leaders equally good\", \"They are not eligible to vote\",\n",
    "                  \"There are not local elections in my area\", \"Both/neither\",\n",
    "                  \"Did not vote\",\"Can't remember\"]\n",
    "\n",
    "# BES codes for NaN\n",
    "Weasel_number_answers = [ \"9999.0\", \"997.0\", \"222.0\", \"99.0\", \"0.0\" ]\n",
    "\n",
    "# non-answer answers\n",
    "Weasel_set = set(Weasel_answers) # gets rid of duplicates!\n",
    "\n",
    "\n",
    "## define 'de_Weasel' function to remove Weasel Words from lists of options\n",
    "## ie. \"Yes|No|Don't know\" -> \"Yes|No\"\n",
    "\n",
    "# Weasel_answers = [\"Don't know\", 'Don?t know', 'Donâ??t know', 'Do\\x92t know', 'Dont know', 'Donât know',\n",
    "#                   \"Prefer not to say\", \"Prefer not to answer\", \"Refused\", \"Unknown\", \"Neither\", \"Other\",\n",
    "#                   \"I would/will not vote\", \"Will not vote\", \"No - not decided\", \"I would not vote\", \"It depends\",\n",
    "#                   \"Other\", \"Don’t follow politics on Facebook\", \"Don't follow politics on twitter\", \"9999.0\", \"997.0\",\n",
    "#                   \"222.0\", \"Yes, other\", \"Haven't thought about it\", \"There wasn't a local election in my area\",\n",
    "#                   \"No, haven't received it\", \"I don't know what was negotiated\", \"I never received a response\",\n",
    "#                   \"There are not local elections in my area\", \"Can't remember\", \"Varies too much to say\" ]\n",
    "\n",
    "# # non-answer answers\n",
    "# Weasel_set = set(Weasel_answers) # gets rid of duplicates!\n",
    "\n",
    "# remove weasel phrases\n",
    "def de_weasel(ques): \n",
    "\n",
    "    return \"|\".join( [x for x in ques.split(\"|\") if x not in Weasel_answers] )\n",
    "\n",
    "# reorder categories\n",
    "def re_order(ques):\n",
    "    if ques in change_cat_dict.keys():\n",
    "        return \"|\".join( change_cat_dict[ques] )\n",
    "    else:\n",
    "        return ques\n",
    "\n",
    "def de_num_el(el):\n",
    "    if el.isdigit():\n",
    "        el = \"%.1f\" % int( el )\n",
    "    return el\n",
    "\n",
    "def de_number(ques):\n",
    "    return \"|\".join( [de_num_el(x) for x in ques.split(\"|\")] )\n",
    "\n",
    "def de_num(ques):\n",
    "    return [de_num_el(x) for x in ques]\n",
    "\n",
    "def floatable(flt):\n",
    "    try:\n",
    "        float(flt)\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "# Weasel_number_answers\n",
    "# Remove 'weasel' numbers\n",
    "# but only if they are the last element\n",
    "# or not the last element, but the next is not a number\n",
    "# to avoid catching parts of sequential numerical categories\n",
    "def de_weasel_numbers(ques):\n",
    "    el_list = ques.split(\"|\")\n",
    "    el_list_len = len(el_list)\n",
    "    remove_list = []\n",
    "    for el_pos in range( 0, el_list_len ):\n",
    "        if el_list[el_pos] in Weasel_number_answers:\n",
    "            # last element, or not last element but next element is a not a number\n",
    "            if el_pos==(el_list_len-1) or not floatable(el_list[el_pos+1]):\n",
    "                remove_list.append(el_list[el_pos])\n",
    "\n",
    "    return \"|\".join( [x for x in el_list if x not in remove_list] )\n",
    "\n",
    "\n",
    "# version to act directly on cat.categories array\n",
    "def de_weasel_nums(el_list):\n",
    "\n",
    "    el_list_len = len(el_list)\n",
    "    remove_list = []\n",
    "    for el_pos in range( 0, el_list_len ):\n",
    "        if el_list[el_pos] in Weasel_number_answers:\n",
    "            # last element, or not last element but next element is a not a number\n",
    "            if el_pos==(el_list_len-1) or not floatable(el_list[el_pos+1]):\n",
    "                remove_list.append(el_list[el_pos])\n",
    "\n",
    "    return remove_list\n",
    "\n",
    "# s.cat.rename_categories([1,2,3])\n",
    "# EUContactRemainConW8|EUContactRemainLabW8|EUContactRemainLDW8|\n",
    "# EUContactRemainSNPW8|EUContactRemainPCW8|EUContactRemainUKIPW8|\n",
    "# EUContactRemainGreenW8|EUContactRemainOthW8|EUContactRemainNoneW8|\n",
    "# EUContactRemainDKW8|EUContactLeaveConW8|EUContactLeaveLabW8|\n",
    "# EUContactLeaveLDW8|EUContactLeaveSNPW8|EUContactLeavePCW8|\n",
    "# EUContactLeaveUKIPW8|EUContactLeaveGreenW8|EUContactLeaveOthW8|\n",
    "# EUContactLeaveNoneW8|EUContactLeaveDKW8\n",
    "\n",
    "# pattern match \"EUContact*****W8\"\n",
    "# debateOneWatchW8|debateTwoWatchW8\n",
    "\n",
    "# \"1.0|2.0|99.0\" -> \n",
    "\n",
    "# euRefVoteSqueezeW7 \"Will not vote|Yes - Leave|Yes - Remain|No - not decided\"\n",
    "#    -> Stay/remain in the EU|Leave the EU|I would/will not vote|Don't know\n",
    "#    HMM - RENAME AND REORDER!\n",
    "\n",
    "# miieuW7\n",
    "# \"Issue stated|Nothing|Don't know\" -> \"Issue stated|None|Don't know\"\n",
    "# MIIEUW8\n",
    "# \"1.0|Nothing|Don't know\" -> \"Issue stated|None|Don't know\"\n",
    "# partyIdEUW7|partyIdEUW8\n",
    "# \"Mainly leave|Mainly remain|Fairly evenly split|Don't know\" -> \"Mainly remain|Fairly evenly divided|Mainly leave|Don't know\"\n",
    "#    HMM - RENAME AND REORDER!\n",
    "\n",
    "# 1. campaignVisionYesW3|campaignVisionNoW3, govtNatSecuritySuccessW4\n",
    "# Very unsuccessful|Fairly unsuccessful|Neither successful nor unsuccessful|Fairly successful|Very successful|Don't know\n",
    "# Very unsuccessful|Somewhat unsuccessful|Neither successful or unsuccessful|Somewhat successful|Very successful|Don't know\n",
    "\n",
    "# Fairly <-> Somewhat\n",
    "\n",
    "# 2. euroTurnoutW1, scotReferendumTurnoutW1|scotReferendumTurnoutW2|welshTurnoutW7|scotTurnoutW7, turnoutUKGeneralW1|turnoutUKGeneralW2|turnoutUKGeneralW3|turnoutUKGeneralW4|turnoutUKGeneralW5|euRefTurnoutW7|euRefTurnoutW8\n",
    "# Very unlikely that I vote|Fairly unlikely|Neither likely nor unlikely|Fairly likely|Very likely that I vote|Don't know\n",
    "# Very unlikely that I would vote|Fairly unlikely|Neither likely nor unlikely|Fairly likely|Very likely that I would vote|Don't know\n",
    "# There are not local elections in my area\n",
    "    #|Very unlikely that I will vote|Fairly unlikely|Neither likely nor unlikely|Fairly likely|Very likely that I will vote|Don't know\n",
    "# Very unlikely that I will vote|Fairly unlikely|Neither likely nor unlikely|Fairly likely|Very likely that I will vote|Don't know\n",
    "\n",
    "# \"Very unlikely that I vote\", \"Very unlikely that I would vote\" ->  \"Very unlikely that I will vote\" \n",
    "\n",
    "rename_cat_dict = {\"North East|North West\": [ \"No\", \"Yes\" ],\n",
    "                   \"1.0|2.0|99.0\": [\"No\", \"Yes\", \"99.0\"],\n",
    "                   \"Will not vote|Yes - Leave|Yes - Remain|No - not decided\": ['I would/will not vote', 'Leave the EU',\n",
    "                                                                               'Stay/remain in the EU', \"Don't know\"],\n",
    "                   \"Issue stated|Nothing|Don't know\":  ['Issue stated', 'None', \"Don't know\"],\n",
    "                   \"1.0|Nothing|Don't know\":           ['Issue stated', 'None', \"Don't know\"],\n",
    "                   \"a|b|C1|C2|d|e|Refused|Unknown\" : ['A', 'B', 'C1', 'C2', 'D', 'E', 'Refused', 'Unknown'],\n",
    "                   \"Mainly leave|Mainly remain|Fairly evenly split|Don't know\": ['Mainly leave',\n",
    "                                                                                 'Mainly remain', 'Fairly evenly divided', \"Don't know\"],\n",
    "                   \"Very unsuccessful|Somewhat unsuccessful|Neither successful or unsuccessful|Somewhat successful|Very successful|Don't know\": ['Very unsuccessful',\n",
    "                        'Fairly unsuccessful', 'Neither successful nor unsuccessful', 'Fairly successful', 'Very successful', \"Don't know\"],\n",
    "                   \"Very unlikely that I vote|Fairly unlikely|Neither likely nor unlikely|Fairly likely|Very likely that I vote|Don't know\":\n",
    "                       ['Very unlikely that I will vote',\n",
    "                     'Fairly unlikely', 'Neither likely nor unlikely', 'Fairly likely', 'Very likely that I will vote', \"Don't know\"],\n",
    "                   \"Very unlikely that I would vote|Fairly unlikely|Neither likely nor unlikely|Fairly likely|Very likely that I would vote|Don't know\":\n",
    "                       ['Very unlikely that I will vote', 'Fairly unlikely',\n",
    "                        'Neither likely nor unlikely', 'Fairly likely', 'Very likely that I will vote', \"Don't know\"],\n",
    "                   \"No, did not vote|Yes, voted|3.0|4.0|5.0|Don't know\":   \n",
    "                       [\"Very unlikely that I will vote\", \"Fairly unlikely\",\n",
    "                        \"Neither likely nor unlikely\", \"Fairly likely\", \"Very likely that I will vote\", \"Don't know\"], #londonTurnoutW7\n",
    "                   \"No, I do not regard myself as belonging to any particular religion.|Yes - Church of England/Anglican/Episcopal|Yes - Roman Catholic|Yes - Presbyterian/Church of Scotland|Yes - Methodist|Yes - Baptist|Yes - United Reformed Church|Yes - Free Presbyterian|Yes - Brethren|Yes - Judaism|Yes - Hinduism|Yes - Islam|Yes - Sikhism|Yes - Buddhism|Yes - Other|Prefer not to say|Yes â€“ Orthodox Christian|Yes - Pentecostal (e.g. Assemblies of God, Elim Pentecostal Church, New Testament Church of God, Redeemed Christian Chur|Yes - Evangelical â€“ independent/non-denominational (e.g. FIEC, Pioneer, Vineyard, Newfrontiers)\":\n",
    "                       [\"No, I do not regard myself as belonging to any particular religion.\",\"Yes - Church of England/Anglican/Episcopal\",\n",
    "                        \"Yes - Roman Catholic\",\"Yes - Presbyterian/Church of Scotland\",\"Yes - Methodist\",\"Yes - Baptist\",\n",
    "                        \"Yes - United Reformed Church\",\"Yes - Free Presbyterian\",\"Yes - Brethren\",\"Yes - Judaism\",\"Yes - Hinduism\",\n",
    "                        \"Yes - Islam\",\"Yes - Sikhism\",\"Yes - Buddhism\",\"Yes - Other\",\"Prefer not to say\",\"Yes - Orthodox Christian\",\n",
    "                        \"Yes - Pentecostal\",\"Yes - Evangelical /independent/non-denominational\"], #xprofile_religionW10\n",
    "                   \"Own â€“ outright|Own â€“ with a mortgage|Own (part-own) â€“ through shared ownership scheme (i.e. pay part mortgage, part rent)|Rent â€“ from a private landlord|Rent â€“ from my local authority|Rent â€“ from a housing association|Neither â€“ I live with my parents, family or friends but pay some rent to them|Neither â€“ I live rent-free with my parents, family or friends|Other\":\n",
    "                       [\"Own outright\",\"Own with a mortgage\",\"Own (part-own) through shared ownership scheme (i.e. pay part mortgage, part rent)\",\n",
    "                        \"Rent from a private landlord\",\"Rent from my local authority\",\"Rent from a housing association\",\n",
    "                        \"Neither I live with my parents, family or friends but pay some rent to them\",\n",
    "                        \"Neither I live rent-free with my parents, family or friends\",\"Other\"], #xprofile_house_tenureW10\n",
    "                   \"I voted 'No' (Scotland should not be an independent country)|I voted 'Yes' (Scotland should be an independent country)|111.0|Don't know\":\n",
    "                       [\"No\",\"Yes\",\"Did not vote\",\"Don't know\"],\n",
    "                   \"Voted Yes|Voted No|Did not vote|Can't remember\":\n",
    "                       [\"Yes\",\"No\",\"Did not vote\",\"Don't know\"]\n",
    "                   \n",
    "                   \n",
    "                   }\n",
    "\n",
    "\n",
    "\n",
    "def re_name(ques):\n",
    "    if ques in rename_cat_dict.keys():\n",
    "        return \"|\".join( rename_cat_dict[ques] )\n",
    "    else:\n",
    "        return ques\n",
    "\n",
    "## COLUMNS THAT EITHER LACK ALL DATA OR HAVE ACTUAL ERRORS\n",
    "# check back on these periodically - one assumes they will get fixed!\n",
    "# maybe tell them about them so that they can?\n",
    "ignore_list = ['approveEUW2',\n",
    "               'whichPartiesHelped_99W6',\n",
    "               'partyContactGrnW1',\n",
    "               'partyContactGrnW2',\n",
    "               'partyContactGrnW3',\n",
    "               'reasonNotRegistered_noneW2',               \n",
    "               'reasonNotRegistered_noneW3',\n",
    "               'reasonNotRegistered_noneW4',\n",
    "               'reasonNotRegistered_noneW6',\n",
    "               'reasonNotRegistered_noneW7',\n",
    "               'reasonNotRegistered_noneW8',\n",
    "               'reasonNotRegistered_none',\n",
    "               'partyContactSNPW1',\n",
    "               'partyContactSNPW2',\n",
    "               'changeIssue1W9',\n",
    "               'conLeaderLikeW9',\n",
    "               \"locusControlW9\",\n",
    "               \"generalElecCertaintyW1\", # wave 10 forwards\n",
    "               \"generalElecCertaintyW2\",\n",
    "               \"generalElecCertaintyW3\",\n",
    "               \"londonMayorVoteW7\",\n",
    "               \"fatherNumEmployeesW4\",\n",
    "               \"motherNumEmployeesW4\",\n",
    "               \"selfNumEmployeesW6W7W8W9\",\n",
    "               \"selfNumEmployeesLastW6W7W8W9\"\n",
    "              ]\n",
    "\n",
    "#- approveEUW2 'Strongly disapprove|Disapprove|Don't know' - should be \"approve|disapprove|don't know\"??? NOT SURE (distribution weird)\n",
    "#- whichPartiesHelped_99W6 - answer set = [\"No\"]\n",
    "#- partyContactGrnW1 ... reasonNotRegistered_noneW8 answer set = [\"No\", \"Don't know\"]\n",
    "# -partyContactSNPW1, partyContactSNPW2 - answer set = [\"Don't know\"]\n",
    "# -changeIssue1W9|conLeaderLikeW9|locusControlW9 - answer set = [\"No formal qualifications\"]\n",
    "\n",
    "## define 'prune' function to prune wave indicators and return question stubs\n",
    "## ie. \"ptvConW1|ptvLabW1\" -> \"ptvCon|ptvLab\"\n",
    "\n",
    "def prune(x):\n",
    "    \n",
    "    y= []\n",
    "    for el in x.split(\"|\"):\n",
    "        match_attempt = re.match('(\\w*?)_?(W[0-9]+)+' , el )   \n",
    "        if match_attempt:\n",
    "            el = match_attempt.groups()[0]\n",
    "        y.append(el)\n",
    "    # should we ditch identical repeats?\n",
    "    # return \"|\".join(set(y)) NEEDS TO BE TESTED\n",
    "    return \"|\".join(y)\n",
    "\n",
    "               \n",
    "def prune2(x):\n",
    "    \n",
    "    y= []\n",
    "    for el in x.split(\"|\"):\n",
    "        # fgdfhfghg_5, fgdfhfghg_4, fgdfhfghg_3 -> fgdfhfghg\n",
    "        # problem - indicator variables fgdfhfghg_99, fgdfhfghg_111 really are different!\n",
    "        # solution - leave them distinct\n",
    "        indicator_variable = re.match('(\\w*?)_?(99|111)' , el )       \n",
    "        match_attempt = re.match('(\\w*?)_?[0-9]+' , el )   \n",
    "        if (not indicator_variable) and (match_attempt):\n",
    "            el = match_attempt.groups()[0]\n",
    "        y.append(el)\n",
    "    # should we ditch identical repeats?\n",
    "    # return \"|\".join(set(y)) NEEDS TO BE TESTED\n",
    "    return \"|\".join(y)\n",
    "#variable_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'W13_only'"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this dataframe to store *everything* we're doing to transform/ignore variables!\n",
    "var_type = pd.DataFrame(columns = [\"type\",\"pruned\",\"original_cat_list\",\n",
    "                                   \"renamed_cat_list\",\"reordered_cat_list\",\n",
    "                                   \"dataset_specific_hardcoded_fix\",\n",
    "                                   \"numerical_dont_knows\",\n",
    "                                   \"weasel_words\" ] )\n",
    "\n",
    "\n",
    "# type - practical classification\n",
    "# pruned\n",
    "# original_cat_list\n",
    "# renamed_cat_list\n",
    "# reordered_cat_list\n",
    "# dataset_specific_hardcoded_fix\n",
    "# numerical_dont_knows\n",
    "# weasel_words\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## dataset specific issues\n",
    "# (i.e. probably what I should have done all along!)\n",
    "\n",
    "# \"BES2017_W13_v1.0.dta\"\n",
    "\n",
    "## Should I make this *filename specific* or *wave specific*?\n",
    "## Comes down to a question of whether it's safer to assume that things get fixed\n",
    "## or that they probably won't get fixed\n",
    "\n",
    "if ( dataset_name == 'W13_only' ):     #  BES2017_W13_v1.0.dta\n",
    "\n",
    "    col = \"headHouseholdPast\"\n",
    "    BES_Panel[col] = \\\n",
    "        BES_Panel[col].astype(\"category\").cat.rename_categories(            [\"My father\",\n",
    "                                                                             \"My mother\",\n",
    "                                                                             \"Someone else\",\n",
    "                                                                             \"No one in my house worked\",\n",
    "                                                                             \"Don't know\"])\n",
    "    var_type.loc[ col , \"dataset_specific_hardcoded_fix\" ] = \"|\".join( BES_Panel[col].cat.categories.values )\n",
    "    \n",
    "    \n",
    "    col = \"fatherNumEmployees\" \n",
    "    BES_Panel[col] = \\\n",
    "        BES_Panel[col].astype(\"category\").cat.rename_categories(            [\"1 to 24 employees\",\n",
    "                                                                             \"25 to 499 employees\",\n",
    "                                                                             \"500 or more employees\",\n",
    "                                                                             \"Don't know\"])        \n",
    "    var_type.loc[ col , \"dataset_specific_hardcoded_fix\" ] = \"|\".join( BES_Panel[col].cat.categories.values )\n",
    "        \n",
    "        \n",
    "    col = \"motherNumEmployees\"         \n",
    "    BES_Panel[col] = \\\n",
    "        BES_Panel[col].astype(\"category\").cat.rename_categories(            [\"1 to 24 employees\",\n",
    "                                                                             \"25 to 499 employees\",\n",
    "                                                                             \"500 or more employees\",\n",
    "                                                                             \"Don't know\"])\n",
    "    var_type.loc[ col , \"dataset_specific_hardcoded_fix\" ] = \"|\".join( BES_Panel[col].cat.categories.values )\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "variable_categories = pd.read_csv( BES_small_data_files + \"question_categories_correct.csv\",\n",
    "                                   encoding = \"ISO-8859-1\" )\n",
    "variable_categories.drop('Unnamed: 0', axis=1,inplace=True)\n",
    "# flipping list\n",
    "var_cat_dict = dict()\n",
    "for typ in [0,1,2,3,4,5,6,7]:\n",
    "    # \n",
    "    e = variable_categories[variable_categories.type==typ][\"column_name\"].values\n",
    "    var_cat_dict[typ] = [item for sublist in [i.split(\"|\") for i in e] for item in sublist]\n",
    "    var_cat_dict[typ] = [item for item in var_cat_dict[typ] if item not in ignore_list]\n",
    "    \n",
    "# dictionary comprehension to prune column-names to wave non-specific stubs\n",
    "# list(set()) gets rid of repetitions\n",
    "var_cat_dict_pruned   = {k: list(set([prune(x)  for x in v])) for k, v in var_cat_dict.items()}\n",
    "var_cat_dict_pruned_2 = {k: list(set([prune2(x) for x in v])) for k, v in var_cat_dict_pruned.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "missing_col_names = []\n",
    "\n",
    "for col in BES_Panel.columns:\n",
    "    dt =  BES_Panel[col].dtype.name # data type\n",
    "    not_found = False\n",
    "    \n",
    "    if col in ignore_list: # exclude values from ignore_list\n",
    "        var_type.loc[col,\"type\"] = -2\n",
    "        \n",
    "    elif (col == \"id\"): # id\n",
    "        var_type.loc[col,\"type\"] = -5\n",
    "\n",
    "    elif (dt == 'object'): # text\n",
    "        var_type.loc[col,\"type\"] = -4\n",
    "\n",
    "    elif (\"datetime\" in dt): # datetime\n",
    "        var_type.loc[col,\"type\"] = -3\n",
    "    \n",
    "    elif col in ['wave11', 'wave12', 'wave13', 'wt_new_W13', 'w10full', 'w11full']: # wave flags/weights (int and float)\n",
    "        var_type.loc[col,\"type\"] = -1\n",
    "        \n",
    "    # waveX - wave int wave 0/1 flag\n",
    "    # wave 1-11: wt_full_W6, wt_core_W6, wt_full_W1W2W3W4W5W6W7W8W9), \n",
    "    # waves 10: wt_new_W10, wt_full_W1_W13\n",
    "        \n",
    "    else:\n",
    "        not_found = True\n",
    "\n",
    "        for typ in [0,1,2,3,4,5,6,7]:\n",
    "            pruned_variable_name = prune2( prune(col) )\n",
    "            if pruned_variable_name in var_cat_dict_pruned_2[typ]:\n",
    "                var_type.loc[col,\"type\"] = typ\n",
    "                var_type.loc[col,\"pruned\"] = pruned_variable_name\n",
    "                not_found = False\n",
    "\n",
    "    if not_found == True:\n",
    "#         var_type.loc[col] = -1\n",
    "        pruned_variable_name = prune2( prune(col) )\n",
    "        print(\"what's up with this? \" + col, pruned_variable_name )\n",
    "        missing_col_names.append(col)\n",
    "        \n",
    "var_type[\"type\"] = var_type[\"type\"].astype(\"int8\")\n",
    "missing_col_names\n",
    "\n",
    "# reset order of var_type rows to be same as BES_Panel\n",
    "\n",
    "var_type = var_type.loc[BES_Panel.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#######################################################################\n",
    "## MANUAL FIXING OF COLUMN NAMES THAT DON'T ALREADY HAVE A TYPE\n",
    "## Only works for category type variables (you may need to manually drop non-category columns!)\n",
    "## Basically, does its best to automatically guess the matching types (based on the near match of the {answer set})\n",
    "## Appends them to the a copy of \"questions_category_correct\" named 'question_categories_correct_updatesneeded!.csv'\n",
    "## Then I'm afraid you have to look at them, fix them if needed, and then run the code in the cell below again\n",
    "manual_fixing = False\n",
    "missing_col_names_cat_only = []\n",
    "if manual_fixing:\n",
    "    print(\"#######################################\")\n",
    "    print(\"CATEGORIES\")\n",
    "    print(\"#######################################\")\n",
    "    print(\"\\n\")\n",
    "    for col in missing_col_names:\n",
    "        if BES_Panel[col].dtypes.name == 'category':\n",
    "            print(col)\n",
    "            missing_col_names_cat_only.append(col)\n",
    "    print(\"\\n\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"#######################################\")\n",
    "    print(\"NON CATEGORIES\")\n",
    "    print(\"#######################################\")\n",
    "    print(\"\\n\")\n",
    "    for col in missing_col_names:\n",
    "        if BES_Panel[col].dtypes.name != 'category':\n",
    "            print(col)\n",
    "    print(\"\\n\")\n",
    "    print(\"\\n\")\n",
    "    ## if this only shows \"weight\" variables, it's fine - set manual_fixing to false and ignore!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if manual_fixing:\n",
    "\n",
    "    updated_variable_categories = variable_categories.copy()\n",
    "\n",
    "    # question\tfrequency\tquestion_length\tquestion_options\tcolumn_name\ttype\n",
    "\n",
    "    for i in missing_col_names_cat_only:\n",
    "        str_list = [ str(cat) for cat in BES_Panel[i].cat.categories ]\n",
    "        joined_list = \"|\".join(str_list)\n",
    "        match  = (joined_list == updated_variable_categories[\"question\"])\n",
    "        # print(i, \" : \" , \"|\".join(str_list ), \" : \", len(str_list) )\n",
    "        if match.any(): # answer set already in records\n",
    "            index = updated_variable_categories[match].index\n",
    "            if len(index)>1: # answer set (\"question\") index should be unique!\n",
    "                raise ValueError('answer set (\"question\") index should be unique!')\n",
    "\n",
    "            # add column name and increase frequency\n",
    "            updated_variable_categories.loc[index,\"frequency\"] = updated_variable_categories.loc[index,\"frequency\"]+1\n",
    "            current_list_col_names = updated_variable_categories.loc[index,\"column_name\"].values[0].split(\"|\")\n",
    "            current_list_col_names.append(i)\n",
    "            updated_variable_categories.loc[index,\"column_name\"] = \"|\".join( current_list_col_names )\n",
    "        else: # answer set not already in records - add new line to dataframe\n",
    "            df = pd.DataFrame([],  columns = updated_variable_categories.columns )\n",
    "\n",
    "            # no need to add index\n",
    "            # updated_variable_categories.shape[0], \n",
    "            df.loc[0] = [joined_list,\n",
    "                         1,\n",
    "                         len(joined_list),\n",
    "                         len(str_list),\n",
    "                         i,-1]\n",
    "            updated_variable_categories = updated_variable_categories.append(df, ignore_index=True)\n",
    "\n",
    "    variable_categories = updated_variable_categories\n",
    "    updated_variable_categories.to_csv(\"question_categories_correct_updatesneeded!.csv\", encoding = \"ISO-8859-1\")\n",
    "    \n",
    "    # rerun after updating list!\n",
    "    \n",
    "    #variable_categories = pd.read_csv(\"question_categories_correct.csv\", encoding = \"ISO-8859-1\")\n",
    "\n",
    "    # flipping list\n",
    "    var_cat_dict = dict()\n",
    "    for typ in [0,1,2,3,4,5,6,7]:\n",
    "        e = variable_categories[variable_categories.type==typ][\"column_name\"].values\n",
    "        var_cat_dict[typ] = [item for sublist in [i.split(\"|\") for i in e] for item in sublist]\n",
    "\n",
    "    # dictionary comprehension to prune column-names to wave non-specific stubs\n",
    "    # list(set()) gets rid of repetitions\n",
    "    var_cat_dict_pruned   = {k: list(set([prune(x)  for x in v])) for k, v in var_cat_dict.items()}\n",
    "    var_cat_dict_pruned_2 = {k: list(set([prune2(x) for x in v])) for k, v in var_cat_dict_pruned.items()}        \n",
    "        \n",
    "    var_type = pd.DataFrame(columns = ['type'] )\n",
    "    missing_col_names = []\n",
    "\n",
    "    for col in BES_Panel.columns:\n",
    "        dt =  BES_Panel[col].dtype.name # data type\n",
    "        not_found = False\n",
    "        if col in ignore_list: # exclude values from ignore_list\n",
    "            var_type.loc[col] = -2\n",
    "            \n",
    "        elif (col == \"id\"): # id\n",
    "            var_type.loc[col] = -5\n",
    "            \n",
    "        elif (dt == 'object'): # text\n",
    "            var_type.loc[col] = -4\n",
    "\n",
    "        elif (\"datetime\" in dt): # datetime\n",
    "            var_type.loc[col] = -3          \n",
    "\n",
    "        else:\n",
    "            not_found = True\n",
    "\n",
    "            for typ in [0,1,2,3,4,5,6,7]:\n",
    "                if prune2( prune(col) ) in var_cat_dict_pruned_2[typ]:\n",
    "                    var_type.loc[col] = typ\n",
    "                    not_found = False\n",
    "\n",
    "        if not_found == True:\n",
    "            var_type.loc[col] = -1\n",
    "            missing_col_names.append(col)\n",
    "#             raise ValueError('Values still missing second time around! ', col)\n",
    "    var_type[\"type\"] = var_type[\"type\"].astype(\"int8\")\n",
    "    display([x for x in zip(missing_col_names, BES_Panel[missing_col_names].dtypes)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# ditch ignore_list values\n",
    "# ditch indicator values\n",
    "\n",
    "# 'numeric' columns (ones that can be transformed into numbers)\n",
    "num_cols     = BES_Panel.columns[ (var_type[\"type\"].apply( lambda x: x in [0,1,2,3,5,6,7] )).values ]\n",
    "# can't be transformed into numbers / are numbers but are meta-data rather than raw content (e.g. weights)\n",
    "non_num_cols = BES_Panel.columns[ (var_type[\"type\"].apply( lambda x: x in [-5,-4,-3,-1 ]  )).values ]\n",
    "\n",
    "BES_numeric  = BES_Panel[num_cols].copy()\n",
    "\n",
    "\n",
    "pos = 0\n",
    "for col in BES_numeric:\n",
    "    pos = pos + 1\n",
    "#     print(col)\n",
    "    \n",
    "    if col not in var_type[\"type\"].index:\n",
    "        print(col, \" not in var_type\")\n",
    "        continue\n",
    "    typ = var_type.loc[ col, \"type\" ]\n",
    "    \n",
    "    if (typ==0) | (typ==7):\n",
    "        continue\n",
    "    \n",
    "    # force all category elements into strings\n",
    "    # ARE THEY EVER NOT?\n",
    "    BES_numeric[col].cat.rename_categories( BES_numeric[col].cat.categories.map(str), inplace=True )\n",
    "    \n",
    "    # rename categories\n",
    "    join_list = \"|\".join( BES_numeric[col].cat.categories ) # create category_list_string \"strongly agree|agree|neither|...\"\n",
    "    var_type.loc[ col, \"original_cat_list\" ] = join_list\n",
    "    \n",
    "    if join_list in rename_cat_dict.keys():\n",
    "        BES_numeric[col].cat.rename_categories(  rename_cat_dict[join_list], inplace=True )\n",
    "        var_type.loc[ col, \"renamed_cat_list\" ]   = \"|\".join( BES_numeric[col].cat.categories )\n",
    "        # note renaming!\n",
    "    # update join_list!\n",
    "    \n",
    "    # reorder categories\n",
    "    join_list = \"|\".join( BES_numeric[col].cat.categories )\n",
    "    if join_list in change_cat_dict.keys():\n",
    "        BES_numeric[col].cat.reorder_categories( change_cat_dict[join_list], inplace=True )\n",
    "        var_type.loc[ col, \"reordered_cat_list\" ] = \"|\".join( BES_numeric[col].cat.categories )\n",
    "        # note reordering\n",
    "    \n",
    "    # remove \"Don't Know\"s that are in weird numerical form (eg. [ \"9999.0\", \"997.0\", \"222.0\", \"99.0\", \"0.0\" ])\n",
    "    # de_weasel numbers\n",
    "    \n",
    "    numerical_dont_knows = de_weasel_nums( BES_numeric[col].cat.categories )\n",
    "    if len(numerical_dont_knows) != 0:\n",
    "        BES_numeric[col].cat.remove_categories( numerical_dont_knows , inplace=True )\n",
    "        var_type.loc[ col, \"numerical_dont_knows\" ] = \"|\".join( numerical_dont_knows )\n",
    "    \n",
    "    # set all digits to floating point format, one decimal place\n",
    "    BES_numeric[col].cat.rename_categories( de_num( BES_numeric[col].cat.categories ), inplace=True )\n",
    "                                          \n",
    "    # de_weasel\n",
    "    weasel_words = BES_numeric[col].cat.categories.intersection(Weasel_set)\n",
    "    if len(weasel_words) != 0:    \n",
    "        BES_numeric[col].cat.remove_categories( weasel_words, inplace=True )\n",
    "        var_type.loc[ col, \"weasel_words\" ] = \"|\".join( weasel_words )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# types\n",
    "# -5    id\n",
    "# -4    text\n",
    "# -3    datetimes\n",
    "# -2 - ignore_list\n",
    "# -1 - anything not a category or one of the below floats -> should all be weights! (wave indicators/campaign day indicators)\n",
    "# 0 - personality measures (in steps of .5?), personality_agreeableness ...etc, riskScale\n",
    "# 1 - linear category, just use  (some made linear by dropping \"Weasel_answers\")\n",
    "# 2 - categories need to be modified - order changed\n",
    "# 3 - set of non-ordered options\n",
    "# 4 - indirect variables - did someone fill something in in the free text box or not?\n",
    "# 5 - categories need to modified - things removed\n",
    "# 6 - categories are integers - should maybe be transformed directly into numbers (mostly \"how much money do people need minimum/well off\"?)\n",
    "# 7 - pano, mapNames\n",
    "\n",
    "\n",
    "\n",
    "# [-5, -4, -3, -2, -1, 4] -> meta list\n",
    "# [0, 1, 2, 3, 5, 6, 7] -> \n",
    "\n",
    "# ordinal: 0, 1, 2, 5, 6\n",
    "# non-ordinal: 3, 7\n",
    "\n",
    "# load question_categories_correct.csv\n",
    "# sanity check by type!\n",
    "# turn into list of variables by type\n",
    "# 1, 5 handled the same way -> cat.codes\n",
    "# 6 -> int()\n",
    "# 4 ignored\n",
    "# 3 ignored for now (-> vectorized?)\n",
    "# 2 direct modification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "413"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save category data\n",
    "cat_dictionary = {}\n",
    "\n",
    "for col in BES_numeric.columns:\n",
    "#     print(col)\n",
    "    if var_type[\"type\"][col] in [1, 2, 3, 5]: # not just cat, but one not already numerical!\n",
    "        cat_dictionary[col] = BES_numeric[col].cat.categories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# turn categories into numbers\n",
    "\n",
    "for col in BES_numeric:\n",
    "    \n",
    "    typ = var_type[\"type\"][col]\n",
    "    \n",
    "    if (typ == 0): # not necessarily already float now!\n",
    "        BES_numeric[col] = BES_numeric[col].astype('float64')\n",
    "        \n",
    "    elif (typ==1) | (typ==2) | (typ==5): # more or less ordinal, replace string categories with \n",
    "        BES_numeric[col] = BES_numeric[col].cat.codes\n",
    "        BES_numeric[col] = BES_numeric[col].astype('float64')\n",
    "     \n",
    "    elif (typ==3): # categporical not ordinal\n",
    "        BES_numeric[col] = BES_numeric[col].cat.codes\n",
    "        BES_numeric[col] = BES_numeric[col].astype('float64')\n",
    "        \n",
    "    elif (typ==6): # categories are integers - better to translate directly\n",
    "        BES_numeric[col] = BES_numeric[col].astype('float64')\n",
    "        \n",
    "    elif (typ==7): # integers - better to translate directly\n",
    "        BES_numeric[col] = BES_numeric[col].astype('float64')        \n",
    "        \n",
    "BES_numeric.replace(-1,np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "382"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# BES_numeric.replace(-1,np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# BES_numerics_only = BES_numeric.drop( BES_numeric.columns[~( (var_type[\"type\"]==0) |\n",
    "#                                                              (var_type[\"type\"]==1) |\n",
    "#                                                              (var_type[\"type\"]==2) |\n",
    "#                                                              (var_type[\"type\"]==5) |\n",
    "#                                                              (var_type[\"type\"]==6) ) ], axis=1 )\n",
    "\n",
    "# BES_numerics_only.replace(-1,np.nan, inplace=True)\n",
    "# # gender only column that has no nan -> still an int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# BES_all_categories = BES_numeric.drop( BES_numeric.columns[~( (var_type[\"type\"]==0) |\n",
    "#                                                              (var_type[\"type\"]==1) |\n",
    "#                                                              (var_type[\"type\"]==2) |\n",
    "#                                                              (var_type[\"type\"]==3) |\n",
    "#                                                              (var_type[\"type\"]==5) |\n",
    "#                                                              (var_type[\"type\"]==6) ) ], axis=1 )\n",
    "\n",
    "# BES_all_categories.replace(-1,np.nan, inplace=True)\n",
    "# # gender only column that has no nan -> still an int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# BES_numerics_only = BES_all_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# BES_num_and_cat.to_stata( BES_data_folder+\"BESW8num_and_cat.hdf\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# wave = \"W13_only\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fname = data_subfolder + \"cat_dictionary.pkl\"\n",
    "with open(fname, \"wb\") as f:\n",
    "    pickle.dump( cat_dictionary, f )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BES_non_numeric = BES_Panel[non_num_cols].copy()\n",
    "BES_non_numeric.to_hdf( data_subfolder + \"BESnon_numeric.hdf\", \"BESnon_numeric\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BES_numeric.to_hdf( data_subfolder + \"BESnumeric.hdf\", \"BESnumeric\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Marios\\Anaconda3\\envs\\BES_analysis\\lib\\site-packages\\pandas\\core\\generic.py:1299: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['pruned', 'original_cat_list', 'renamed_cat_list', 'reordered_cat_list', 'dataset_specific_hardcoded_fix', 'numerical_dont_knows', 'weasel_words']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "var_type.to_hdf( data_subfolder + \"var_type.hdf\", \"var_type\")\n",
    "# don't think the performance warning will be relevant on such a small dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fname = BES_data_folder+\"cat_dictionary\"+\".pkl\"\n",
    "# with open(fname, \"wb\") as f:\n",
    "#     pickle.dump( cat_dictionary, f )\n",
    "    \n",
    "# BES_non_numeric = BES_Panel[non_num_cols].copy()\n",
    "# BES_non_numeric.to_hdf( BES_data_folder+\"BESW8non_numeric.hdf\", \"BESW8non_numeric\" )\n",
    "\n",
    "# BES_numeric.to_hdf( BES_data_folder+\"BESW8numeric.hdf\", \"BESW8numeric\" )\n",
    "\n",
    "# var_type.to_hdf( BES_data_folder+\"var_type.hdf\", \"var_type\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_type[\"type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import sys\n",
    "# for var, obj in locals().items():\n",
    "#     if sys.getsizeof(obj) >100000:\n",
    "#         print(var, sys.getsizeof(obj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TEST CODE\n",
    "# Checking to see if different column names have same question set but are assigned different types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test to see if pruning \"_wave\" leads to differing variable categories\n",
    "for key in var_cat_dict_pruned.keys():\n",
    "    for val in var_cat_dict_pruned[key]:\n",
    "        for other_key in var_cat_dict_pruned.keys():\n",
    "            if key==other_key: # don't check same category\n",
    "                continue\n",
    "            if val in var_cat_dict_pruned[other_key]:\n",
    "                print(\"problem: {0} {1} {2}\".format(key, val, other_key) )\n",
    "            \n",
    "# mixing 1 and 5 is fine, because 5 (mis-ordered ordinal) is turned into 1 (correctly ordered ordinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test to see if further pruning \"_num\" leads to differing variable categories\n",
    "for key in var_cat_dict_pruned_2.keys():\n",
    "    for val in var_cat_dict_pruned_2[key]:\n",
    "        for other_key in var_cat_dict_pruned_2.keys():\n",
    "            if key==other_key: # don't check same category\n",
    "                continue\n",
    "            if val in var_cat_dict_pruned_2[other_key]:\n",
    "                print(\"problem: {0} {1} {2}\".format(key, val, other_key) )\n",
    "            \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pano, mapNames\n",
    "# weights\n",
    "# personality\n",
    "# datetimes -> remove on type\n",
    "# text -> remove on type\n",
    "\n",
    "# weights, datetimes, text -> saved separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (BES_Panel[ 'CampaignDayW5' ]-19).abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# W5_cats_df.corrwith( (BES_Panel[ 'CampaignDayW5' ]-19).abs() ).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# corr_df[\"absolute corr\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sample_size = W5_cats_df.notnull().apply(lambda x: x& BES_Panel[ 'CampaignDayW5' ].notnull()).sum()\n",
    "# corr = W5_cats_df.corrwith(BES_Panel[ 'CampaignDayW5' ])\n",
    "\n",
    "\n",
    "# corr_df = pd.DataFrame(corr, columns= [\"corr\"])\n",
    "# corr_df[\"sample_size\"] = sample_size\n",
    "# corr_df[\"absolute corr\"] = corr.abs()\n",
    "# corr_df[corr_df[\"sample_size\"]>2000].sort_values(by=\"absolute corr\", ascending=False).head(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # BES_Panel[ 'CampaignDayW5' ].corr(W5_cats_df)\n",
    "# W5_cats_df.corrwith(BES_Panel[ 'CampaignDayW5' ]).sort_values().hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # 283 with \"W5\" in\n",
    "# # 248 with \"W5\" in AND category\n",
    "\n",
    "# W5cats = [x for x in BES_Panel.columns if (\"W5\" in x) & (BES_Panel[x].dtype.name =='category')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# W5_cats_df = BES_Panel[W5cats].apply(lambda x : x.cat.codes).replace(-1,np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# BES_Panel[\"selfNumEmployeesLastW6W7W8W9\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# BES_Panel[\"londonTurnoutW7\"].cat.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:BES_analysis]",
   "language": "python",
   "name": "conda-env-BES_analysis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
