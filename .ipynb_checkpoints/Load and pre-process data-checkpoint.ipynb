{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Process BES Panel for Wave 8\n",
    "\n",
    "## WORK IN PROGRESS - run this on all updated BES waves\n",
    "\n",
    "# Assign types to each column variables (mostly automatic - but there's room for manual editing)\n",
    "# Modifies categories (harmoning options, harmonising order, dropping weasel terms)\n",
    "# Creates:\n",
    "# var_type (types for column variables)\n",
    "# BES_numeric (fixed version with only useful columns all transformed into numeric values)\n",
    "    # non-numeric categorical values -> index number of category\n",
    "    # floats -> float\n",
    "    # numeric categories (i.e. income intervals/number of children) -> numeric\n",
    "# cat_dictionary\n",
    "    # so you can get the text categories back from the index values as and when it's necessary\n",
    "# BES_non_numeric\n",
    "    # basically everything else! (mostly meta-data - weights)\n",
    "\n",
    "# LIVE: Run all cells -> ~20s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "import re\n",
    "\n",
    "from itertools import cycle\n",
    "from IPython.display import display\n",
    "import pickle, os\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# BES_data_folder = \"../BES_analysis_data/\"\n",
    "# BES_code_folder = \"../BES_analysis_code/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# you should clone this git to this subdirectory (in some directory - I call it BES_analysis - doesn't matter though)\n",
    "\n",
    "if os.getcwd().split(os.sep)[-1] != 'BES_analysis_code':\n",
    "    raise Exception(\"Stop! You're in the wrong directory - should be in 'BES_analysis_code'\")\n",
    "\n",
    "BES_code_folder   = \"../BES_analysis_code/\" # we should be here!\n",
    "BES_small_data_files = BES_code_folder + \"small data files\" + os.sep\n",
    "if not os.path.exists( BES_small_data_files ):\n",
    "    os.makedirs( BES_small_data_files )\n",
    "\n",
    "# we should create these if they don't already exist\n",
    "BES_data_folder   = \"../BES_analysis_data/\"\n",
    "if not os.path.exists( BES_data_folder ):\n",
    "    os.makedirs( BES_data_folder )\n",
    "\n",
    "BES_output_folder = \"../BES_analysis_output/\"\n",
    "if not os.path.exists( BES_output_folder ):\n",
    "    os.makedirs( BES_output_folder )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# W13_only, W13_comb\n",
    "\n",
    "\n",
    "dataset_name = \"W12_only\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34464, 421)\n",
      "Wall time: 5.66 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "BES_file_manifest = pd.read_csv( BES_small_data_files + \"BES_file_manifest.csv\" )\n",
    "manifest = BES_file_manifest[ BES_file_manifest[\"Name\"] == dataset_name ]\n",
    "\n",
    "filename = manifest[\"Stata_Filename\"].values[0]\n",
    "\n",
    "data_subfolder = BES_data_folder + dataset_name + os.sep\n",
    "\n",
    "Treatment = dataset_name\n",
    "\n",
    "\n",
    "# dataset = \"BES2017_W13_v1.0.dta\"\n",
    "# wave = \"W13_only\"\n",
    "\n",
    "BES_Panel = pd.read_stata( data_subfolder + filename)\n",
    "\n",
    "print( BES_Panel.shape )\n",
    "\n",
    "# 20 mins for W13_comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## HELPER FUNCTIONS / REPLACEMENT VALUE DICTIONARIES\n",
    "\n",
    "\n",
    "# changing the order of some sets of categories\n",
    "change_cat_dict = {\"Bad time to buy|Good time to buy|Neither good nor bad time to buy|Don't know\": [\"Bad time to buy\",\n",
    "                                                                                                    \"Neither good nor bad time to buy\",\n",
    "                                                                                                    \"Good time to buy\",\n",
    "                                                                                                    \"Don't know\"],\n",
    "                   \"Larger|Smaller|About the same|Don't know\": [\"Larger\", \"About the same\", \"Smaller\",\"Don't know\"],\n",
    "                   \"Yes|No|99.0\":       ['No', 'Yes', '99.0'],\n",
    "                   \"Yes|No|Don't know\": ['No', 'Yes', \"Don't know\"],\n",
    "                   \"Yes|No\" :           ['No', 'Yes'],\n",
    "                   \"Yes|No|Did not vote|Don't know\" : [\"No\",\"Yes\",\"Did not vote\",\"Don't know\"],\n",
    "                   \"Yes, voted|No, did not vote|Donâ??t know\" : ['No, did not vote', 'Yes, voted', 'Donâ??t know'],\n",
    "                   \"Yes, voted|No, did not vote|Don?t know\"   : ['No, did not vote', 'Yes, voted', 'Don?t know'],                   \n",
    "                   \"I would/will not vote|Leave the EU|Stay/remain in the EU|Don't know\": ['Stay/remain in the EU',\n",
    "                                                                                           'Leave the EU', 'I would/will not vote', \"Don't know\"],\n",
    "                   \"Mainly leave|Mainly remain|Fairly evenly divided|Don't know\": [\"Mainly remain\",\n",
    "                                                                                   \"Fairly evenly divided\", \"Mainly leave\", \"Don't know\"],\n",
    "                   \"An individual share in a company|A portfolio of different company shares|The risk is the same|Don't know|Prefer not to say\":\n",
    "                       ['An individual share in a company', 'The risk is the same', 'A portfolio of different company shares',\"Prefer not to say\",\"Don't know\"],\n",
    "                   'An individual share in a company|A portfolio of different company shares|The risk is the same|Don\\x92t know|Prefer not to say':\n",
    "                       ['An individual share in a company', 'The risk is the same', 'A portfolio of different company shares',\"Prefer not to say\",\"Don\\x92t know\"],\n",
    "                   \"No, I have never been a member|Yes, I am a member of a party|I am not a member now but I used to be|Don't know\":\n",
    "                       ['No, I have never been a member', 'I am not a member now but I used to be', 'Yes, I am a member of a party', \"Don't know\"],\n",
    "                   \"Never or practically never|Less often than once a year|Less often but at least once a year|Less often but at least twice a year|Less often but at least once a month|Less often but at least once in two weeks|Once a week or more|Varies too much to say|I am not religious|Don't know\":\n",
    "                       ['I am not religious', 'Never or practically never', 'Less often than once a year',\n",
    "                        'Less often but at least once a year', 'Less often but at least twice a year',\n",
    "                        'Less often but at least once a month', 'Less often but at least once in two weeks',\n",
    "                        'Once a week or more', \"Varies too much to say\",\"Don't know\"],\n",
    "                   \"under Â£5,000 per year|Â£5,000 to Â£9,999 per year|Â£10,000 to Â£14,999 per year|Â£15,000 to Â£19,999 per year|Â£20,000 to Â£24,999 per year|Â£25,000 to Â£29,999 per year|Â£30,000 to Â£34,999 per year|Â£35,000 to Â£39,999 per year|Â£40,000 to Â£44,999 per year|Â£45,000 to Â£49,999 per year|Â£50,000 to Â£59,999 per year|Â£60,000 to Â£69,999 per year|Â£70,000 to Â£99,999 per year|Â£100,000 to Â£149,999 per year|Â£150,000 and over|Don't know|Prefer not to answer\":\n",
    "                       [\"under Â£5,000 per year\",\"Â£5,000 to Â£9,999 per year\",\"Â£10,000 to Â£14,999 per year\",\"Â£15,000 to Â£19,999 per year\",\n",
    "                        \"Â£20,000 to Â£24,999 per year\",\"Â£25,000 to Â£29,999 per year\",\"Â£30,000 to Â£34,999 per year\",\n",
    "                        \"Â£35,000 to Â£39,999 per year\",\"Â£40,000 to Â£44,999 per year\",\"Â£45,000 to Â£49,999 per year\",\n",
    "                        \"Â£50,000 to Â£59,999 per year\",\"Â£60,000 to Â£69,999 per year\",\"Â£70,000 to Â£99,999 per year\",\n",
    "                        \"Â£100,000 to Â£149,999 per year\",\"Â£150,000 and over\",\"Prefer not to answer\",\"Don't know\"],\n",
    "                   \"1|2|3|4|5|6|7|8 or more|Don't know|Prefer not to say\":\n",
    "                       [\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8 or more\",\"Prefer not to say\",\"Don't know\"],\n",
    "                   \"The Yes side|The No side|Neither|Don't know\":\n",
    "                       [\"The Yes side\",\"Neither\",\"The No side\",\"Don't know\"] # is this ordinal - meh?\n",
    "                   \n",
    "                  }\n",
    "\n",
    "## typos - more directly useful for the BES!\n",
    "typos = set(['Do\\x92t know', 'Dont know', 'Donât know', 'Don??t know',\n",
    "         \"9999.0\", \"997.0\", \"222.0\", \"99.0\", \"0.0\", \"1.0\", \"2.0\"   ])\n",
    "\n",
    "\n",
    "\n",
    "# Big set of actual answers **I interpet** as non-answers (and set to NaN)\n",
    "# REALLY MERITS RECHECKING WHAT THE IMPACT OF THIS IS!\n",
    "Weasel_answers = [\"Don't know\", 'Do\\x92t know', 'Dont know', 'Donât know', 'Don??t know',\n",
    "                  \"Prefer not to say\", \"Prefer not to answer\", \"Refused\", \"Unknown\",\n",
    "                  \"Neither\", \"Other\", \"I would/will not vote\", \"Will not vote\",\n",
    "                  \"I would not vote\", \"It depends\", \"Other\",\n",
    "                  \"Don’t follow politics on Facebook\", \"Don't follow politics on twitter\",\n",
    "                  \"Yes, other\", \"Haven't thought about it\",\n",
    "                  \"There wasn't a local election in my area\", \"No, haven't received it\",\n",
    "                  \"I don't know what was negotiated\", \"I never received a response\",\n",
    "                  \"There are not local elections in my area\", \"Can't remember\",\n",
    "                  \"Varies too much to say\", \"Will not state a choice\",\n",
    "                  \"All leaders equally good\", \"They are not eligible to vote\",\n",
    "                  \"There are not local elections in my area\", \"Both/neither\",\n",
    "                  \"Did not vote\",\"Can't remember\"]\n",
    "\n",
    "# BES codes for NaN\n",
    "Weasel_number_answers = [ \"9999.0\", \"997.0\", \"222.0\", \"99.0\", \"0.0\" ]\n",
    "\n",
    "# non-answer answers\n",
    "Weasel_set = set(Weasel_answers) # gets rid of duplicates!\n",
    "\n",
    "\n",
    "## define 'de_Weasel' function to remove Weasel Words from lists of options\n",
    "## ie. \"Yes|No|Don't know\" -> \"Yes|No\"\n",
    "\n",
    "# Weasel_answers = [\"Don't know\", 'Don?t know', 'Donâ??t know', 'Do\\x92t know', 'Dont know', 'Donât know',\n",
    "#                   \"Prefer not to say\", \"Prefer not to answer\", \"Refused\", \"Unknown\", \"Neither\", \"Other\",\n",
    "#                   \"I would/will not vote\", \"Will not vote\", \"No - not decided\", \"I would not vote\", \"It depends\",\n",
    "#                   \"Other\", \"Don’t follow politics on Facebook\", \"Don't follow politics on twitter\", \"9999.0\", \"997.0\",\n",
    "#                   \"222.0\", \"Yes, other\", \"Haven't thought about it\", \"There wasn't a local election in my area\",\n",
    "#                   \"No, haven't received it\", \"I don't know what was negotiated\", \"I never received a response\",\n",
    "#                   \"There are not local elections in my area\", \"Can't remember\", \"Varies too much to say\" ]\n",
    "\n",
    "# # non-answer answers\n",
    "# Weasel_set = set(Weasel_answers) # gets rid of duplicates!\n",
    "\n",
    "# remove weasel phrases\n",
    "def de_weasel(ques): \n",
    "\n",
    "    return \"|\".join( [x for x in ques.split(\"|\") if x not in Weasel_answers] )\n",
    "\n",
    "# reorder categories\n",
    "def re_order(ques):\n",
    "    if ques in change_cat_dict.keys():\n",
    "        return \"|\".join( change_cat_dict[ques] )\n",
    "    else:\n",
    "        return ques\n",
    "\n",
    "def de_num_el(el):\n",
    "    if el.isdigit():\n",
    "        el = \"%.1f\" % int( el )\n",
    "    return el\n",
    "\n",
    "def de_number(ques):\n",
    "    return \"|\".join( [de_num_el(x) for x in ques.split(\"|\")] )\n",
    "\n",
    "def de_num(ques):\n",
    "    return [de_num_el(x) for x in ques]\n",
    "\n",
    "def floatable(flt):\n",
    "    try:\n",
    "        float(flt)\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "# Weasel_number_answers\n",
    "# Remove 'weasel' numbers\n",
    "# but only if they are the last element\n",
    "# or not the last element, but the next is not a number\n",
    "# to avoid catching parts of sequential numerical categories\n",
    "def de_weasel_numbers(ques):\n",
    "    el_list = ques.split(\"|\")\n",
    "    el_list_len = len(el_list)\n",
    "    remove_list = []\n",
    "    for el_pos in range( 0, el_list_len ):\n",
    "        if el_list[el_pos] in Weasel_number_answers:\n",
    "            # last element, or not last element but next element is a not a number\n",
    "            if el_pos==(el_list_len-1) or not floatable(el_list[el_pos+1]):\n",
    "                remove_list.append(el_list[el_pos])\n",
    "\n",
    "    return \"|\".join( [x for x in el_list if x not in remove_list] )\n",
    "\n",
    "\n",
    "# version to act directly on cat.categories array\n",
    "def de_weasel_nums(el_list):\n",
    "\n",
    "    el_list_len = len(el_list)\n",
    "    remove_list = []\n",
    "    for el_pos in range( 0, el_list_len ):\n",
    "        if el_list[el_pos] in Weasel_number_answers:\n",
    "            # last element, or not last element but next element is a not a number\n",
    "            if el_pos==(el_list_len-1) or not floatable(el_list[el_pos+1]):\n",
    "                remove_list.append(el_list[el_pos])\n",
    "\n",
    "    return remove_list\n",
    "\n",
    "# s.cat.rename_categories([1,2,3])\n",
    "# EUContactRemainConW8|EUContactRemainLabW8|EUContactRemainLDW8|\n",
    "# EUContactRemainSNPW8|EUContactRemainPCW8|EUContactRemainUKIPW8|\n",
    "# EUContactRemainGreenW8|EUContactRemainOthW8|EUContactRemainNoneW8|\n",
    "# EUContactRemainDKW8|EUContactLeaveConW8|EUContactLeaveLabW8|\n",
    "# EUContactLeaveLDW8|EUContactLeaveSNPW8|EUContactLeavePCW8|\n",
    "# EUContactLeaveUKIPW8|EUContactLeaveGreenW8|EUContactLeaveOthW8|\n",
    "# EUContactLeaveNoneW8|EUContactLeaveDKW8\n",
    "\n",
    "# pattern match \"EUContact*****W8\"\n",
    "# debateOneWatchW8|debateTwoWatchW8\n",
    "\n",
    "# \"1.0|2.0|99.0\" -> \n",
    "\n",
    "# euRefVoteSqueezeW7 \"Will not vote|Yes - Leave|Yes - Remain|No - not decided\"\n",
    "#    -> Stay/remain in the EU|Leave the EU|I would/will not vote|Don't know\n",
    "#    HMM - RENAME AND REORDER!\n",
    "\n",
    "# miieuW7\n",
    "# \"Issue stated|Nothing|Don't know\" -> \"Issue stated|None|Don't know\"\n",
    "# MIIEUW8\n",
    "# \"1.0|Nothing|Don't know\" -> \"Issue stated|None|Don't know\"\n",
    "# partyIdEUW7|partyIdEUW8\n",
    "# \"Mainly leave|Mainly remain|Fairly evenly split|Don't know\" -> \"Mainly remain|Fairly evenly divided|Mainly leave|Don't know\"\n",
    "#    HMM - RENAME AND REORDER!\n",
    "\n",
    "# 1. campaignVisionYesW3|campaignVisionNoW3, govtNatSecuritySuccessW4\n",
    "# Very unsuccessful|Fairly unsuccessful|Neither successful nor unsuccessful|Fairly successful|Very successful|Don't know\n",
    "# Very unsuccessful|Somewhat unsuccessful|Neither successful or unsuccessful|Somewhat successful|Very successful|Don't know\n",
    "\n",
    "# Fairly <-> Somewhat\n",
    "\n",
    "# 2. euroTurnoutW1, scotReferendumTurnoutW1|scotReferendumTurnoutW2|welshTurnoutW7|scotTurnoutW7, turnoutUKGeneralW1|turnoutUKGeneralW2|turnoutUKGeneralW3|turnoutUKGeneralW4|turnoutUKGeneralW5|euRefTurnoutW7|euRefTurnoutW8\n",
    "# Very unlikely that I vote|Fairly unlikely|Neither likely nor unlikely|Fairly likely|Very likely that I vote|Don't know\n",
    "# Very unlikely that I would vote|Fairly unlikely|Neither likely nor unlikely|Fairly likely|Very likely that I would vote|Don't know\n",
    "# There are not local elections in my area\n",
    "    #|Very unlikely that I will vote|Fairly unlikely|Neither likely nor unlikely|Fairly likely|Very likely that I will vote|Don't know\n",
    "# Very unlikely that I will vote|Fairly unlikely|Neither likely nor unlikely|Fairly likely|Very likely that I will vote|Don't know\n",
    "\n",
    "# \"Very unlikely that I vote\", \"Very unlikely that I would vote\" ->  \"Very unlikely that I will vote\" \n",
    "\n",
    "rename_cat_dict = {\"North East|North West\": [ \"No\", \"Yes\" ],\n",
    "                   \"1.0|2.0|99.0\": [\"No\", \"Yes\", \"99.0\"],\n",
    "                   \"Will not vote|Yes - Leave|Yes - Remain|No - not decided\": ['I would/will not vote', 'Leave the EU',\n",
    "                                                                               'Stay/remain in the EU', \"Don't know\"],\n",
    "                   \"Issue stated|Nothing|Don't know\":  ['Issue stated', 'None', \"Don't know\"],\n",
    "                   \"1.0|Nothing|Don't know\":           ['Issue stated', 'None', \"Don't know\"],\n",
    "                   \"a|b|C1|C2|d|e|Refused|Unknown\" : ['A', 'B', 'C1', 'C2', 'D', 'E', 'Refused', 'Unknown'],\n",
    "                   \"Mainly leave|Mainly remain|Fairly evenly split|Don't know\": ['Mainly leave',\n",
    "                                                                                 'Mainly remain', 'Fairly evenly divided', \"Don't know\"],\n",
    "                   \"Very unsuccessful|Somewhat unsuccessful|Neither successful or unsuccessful|Somewhat successful|Very successful|Don't know\": ['Very unsuccessful',\n",
    "                        'Fairly unsuccessful', 'Neither successful nor unsuccessful', 'Fairly successful', 'Very successful', \"Don't know\"],\n",
    "                   \"Very unlikely that I vote|Fairly unlikely|Neither likely nor unlikely|Fairly likely|Very likely that I vote|Don't know\":\n",
    "                       ['Very unlikely that I will vote',\n",
    "                     'Fairly unlikely', 'Neither likely nor unlikely', 'Fairly likely', 'Very likely that I will vote', \"Don't know\"],\n",
    "                   \"Very unlikely that I would vote|Fairly unlikely|Neither likely nor unlikely|Fairly likely|Very likely that I would vote|Don't know\":\n",
    "                       ['Very unlikely that I will vote', 'Fairly unlikely',\n",
    "                        'Neither likely nor unlikely', 'Fairly likely', 'Very likely that I will vote', \"Don't know\"],\n",
    "                   \"No, did not vote|Yes, voted|3.0|4.0|5.0|Don't know\":   \n",
    "                       [\"Very unlikely that I will vote\", \"Fairly unlikely\",\n",
    "                        \"Neither likely nor unlikely\", \"Fairly likely\", \"Very likely that I will vote\", \"Don't know\"], #londonTurnoutW7\n",
    "                   \"No, I do not regard myself as belonging to any particular religion.|Yes - Church of England/Anglican/Episcopal|Yes - Roman Catholic|Yes - Presbyterian/Church of Scotland|Yes - Methodist|Yes - Baptist|Yes - United Reformed Church|Yes - Free Presbyterian|Yes - Brethren|Yes - Judaism|Yes - Hinduism|Yes - Islam|Yes - Sikhism|Yes - Buddhism|Yes - Other|Prefer not to say|Yes â€“ Orthodox Christian|Yes - Pentecostal (e.g. Assemblies of God, Elim Pentecostal Church, New Testament Church of God, Redeemed Christian Chur|Yes - Evangelical â€“ independent/non-denominational (e.g. FIEC, Pioneer, Vineyard, Newfrontiers)\":\n",
    "                       [\"No, I do not regard myself as belonging to any particular religion.\",\"Yes - Church of England/Anglican/Episcopal\",\n",
    "                        \"Yes - Roman Catholic\",\"Yes - Presbyterian/Church of Scotland\",\"Yes - Methodist\",\"Yes - Baptist\",\n",
    "                        \"Yes - United Reformed Church\",\"Yes - Free Presbyterian\",\"Yes - Brethren\",\"Yes - Judaism\",\"Yes - Hinduism\",\n",
    "                        \"Yes - Islam\",\"Yes - Sikhism\",\"Yes - Buddhism\",\"Yes - Other\",\"Prefer not to say\",\"Yes - Orthodox Christian\",\n",
    "                        \"Yes - Pentecostal\",\"Yes - Evangelical /independent/non-denominational\"], #xprofile_religionW10\n",
    "                   \"Own â€“ outright|Own â€“ with a mortgage|Own (part-own) â€“ through shared ownership scheme (i.e. pay part mortgage, part rent)|Rent â€“ from a private landlord|Rent â€“ from my local authority|Rent â€“ from a housing association|Neither â€“ I live with my parents, family or friends but pay some rent to them|Neither â€“ I live rent-free with my parents, family or friends|Other\":\n",
    "                       [\"Own outright\",\"Own with a mortgage\",\"Own (part-own) through shared ownership scheme (i.e. pay part mortgage, part rent)\",\n",
    "                        \"Rent from a private landlord\",\"Rent from my local authority\",\"Rent from a housing association\",\n",
    "                        \"Neither I live with my parents, family or friends but pay some rent to them\",\n",
    "                        \"Neither I live rent-free with my parents, family or friends\",\"Other\"], #xprofile_house_tenureW10\n",
    "                   \"I voted 'No' (Scotland should not be an independent country)|I voted 'Yes' (Scotland should be an independent country)|111.0|Don't know\":\n",
    "                       [\"No\",\"Yes\",\"Did not vote\",\"Don't know\"], # referendumrecall\n",
    "                   \"Voted Yes|Voted No|Did not vote|Can't remember\":\n",
    "                       [\"Yes\",\"No\",\"Did not vote\",\"Don't know\"] # scotRefVoteW4_\n",
    "                   \n",
    "                   \n",
    "                   }\n",
    "\n",
    "\n",
    "\n",
    "def re_name(ques):\n",
    "    if ques in rename_cat_dict.keys():\n",
    "        return \"|\".join( rename_cat_dict[ques] )\n",
    "    else:\n",
    "        return ques\n",
    "\n",
    "## COLUMNS THAT EITHER LACK ALL DATA OR HAVE ACTUAL ERRORS\n",
    "# check back on these periodically - one assumes they will get fixed!\n",
    "# maybe tell them about them so that they can?\n",
    "ignore_list = ['approveEUW2',\n",
    "               'whichPartiesHelped_99W6',\n",
    "               'partyContactGrnW1',\n",
    "               'partyContactGrnW2',\n",
    "               'partyContactGrnW3',\n",
    "               'reasonNotRegistered_noneW2',               \n",
    "               'reasonNotRegistered_noneW3',\n",
    "               'reasonNotRegistered_noneW4',\n",
    "               'reasonNotRegistered_noneW6',\n",
    "               'reasonNotRegistered_noneW7',\n",
    "               'reasonNotRegistered_noneW8',\n",
    "               'reasonNotRegistered_none',\n",
    "               'partyContactSNPW1',\n",
    "               'partyContactSNPW2',\n",
    "               'changeIssue1W9',\n",
    "               'conLeaderLikeW9',\n",
    "               \"locusControlW9\",\n",
    "               \"generalElecCertaintyW1\", # wave 10 forwards\n",
    "               \"generalElecCertaintyW2\",\n",
    "               \"generalElecCertaintyW3\",\n",
    "               \"londonMayorVoteW7\",\n",
    "               \"fatherNumEmployeesW4\",\n",
    "               \"motherNumEmployeesW4\",\n",
    "               \"selfNumEmployeesW6W7W8W9\",\n",
    "               \"selfNumEmployeesLastW6W7W8W9\"\n",
    "               \n",
    "              ]\n",
    "\n",
    "#- approveEUW2 'Strongly disapprove|Disapprove|Don't know' - should be \"approve|disapprove|don't know\"??? NOT SURE (distribution weird)\n",
    "#- whichPartiesHelped_99W6 - answer set = [\"No\"]\n",
    "#- partyContactGrnW1 ... reasonNotRegistered_noneW8 answer set = [\"No\", \"Don't know\"]\n",
    "# -partyContactSNPW1, partyContactSNPW2 - answer set = [\"Don't know\"]\n",
    "# -changeIssue1W9|conLeaderLikeW9|locusControlW9 - answer set = [\"No formal qualifications\"]\n",
    "\n",
    "## define 'prune' function to prune wave indicators and return question stubs\n",
    "## ie. \"ptvConW1|ptvLabW1\" -> \"ptvCon|ptvLab\"\n",
    "\n",
    "def prune(x):\n",
    "    \n",
    "    y= []\n",
    "    for el in x.split(\"|\"):\n",
    "        match_attempt = re.match('(\\w*?)_?(W[0-9]+)+' , el )   \n",
    "        if match_attempt:\n",
    "            el = match_attempt.groups()[0]\n",
    "        y.append(el)\n",
    "    # should we ditch identical repeats?\n",
    "    # return \"|\".join(set(y)) NEEDS TO BE TESTED\n",
    "    return \"|\".join(y)\n",
    "\n",
    "               \n",
    "def prune2(x):\n",
    "    \n",
    "    y= []\n",
    "    for el in x.split(\"|\"):\n",
    "        # fgdfhfghg_5, fgdfhfghg_4, fgdfhfghg_3 -> fgdfhfghg\n",
    "        # problem - indicator variables fgdfhfghg_99, fgdfhfghg_111 really are different!\n",
    "        # solution - leave them distinct\n",
    "        indicator_variable = re.match('(\\w*?)_?(99|111)' , el )       \n",
    "        match_attempt = re.match('(\\w*?)_?[0-9]+' , el )   \n",
    "        if (not indicator_variable) and (match_attempt):\n",
    "            el = match_attempt.groups()[0]\n",
    "        y.append(el)\n",
    "    # should we ditch identical repeats?\n",
    "    # return \"|\".join(set(y)) NEEDS TO BE TESTED\n",
    "    return \"|\".join(y)\n",
    "#variable_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use this dataframe to store *everything* we're doing to transform/ignore variables!\n",
    "var_type = pd.DataFrame(columns = [\"type\",\"pruned\",\"original_cat_list\",\n",
    "                                   \"renamed_cat_list\",\"reordered_cat_list\",\n",
    "                                   \"dataset_specific_hardcoded_fix\",\n",
    "                                   \"numerical_dont_knows\",\n",
    "                                   \"weasel_words\",\"typos\" ] )\n",
    "\n",
    "\n",
    "# type - practical classification\n",
    "# pruned\n",
    "# original_cat_list\n",
    "# renamed_cat_list\n",
    "# reordered_cat_list\n",
    "# dataset_specific_hardcoded_fix\n",
    "# numerical_dont_knows\n",
    "# weasel_words\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "## dataset specific issues\n",
    "# (i.e. probably what I should have done all along!)\n",
    "\n",
    "# \"BES2017_W13_v1.0.dta\"\n",
    "\n",
    "## Should I make this *filename specific* or *wave specific*?\n",
    "## Comes down to a question of whether it's safer to assume that things get fixed\n",
    "## or that they probably won't get fixed\n",
    "\n",
    "if ( dataset_name == 'W13_only' ):     #  BES2017_W13_v1.0.dta\n",
    "\n",
    "    col = \"headHouseholdPast\"\n",
    "    BES_Panel[col] = \\\n",
    "        BES_Panel[col].astype(\"category\").cat.rename_categories(            [\"My father\",\n",
    "                                                                             \"My mother\",\n",
    "                                                                             \"Someone else\",\n",
    "                                                                             \"No one in my house worked\",\n",
    "                                                                             \"Don't know\"])\n",
    "    var_type.loc[ col , \"dataset_specific_hardcoded_fix\" ] = \"|\".join( BES_Panel[col].cat.categories.values )\n",
    "    \n",
    "    \n",
    "    col = \"fatherNumEmployees\" \n",
    "    BES_Panel[col] = \\\n",
    "        BES_Panel[col].astype(\"category\").cat.rename_categories(            [\"1 to 24 employees\",\n",
    "                                                                             \"25 to 499 employees\",\n",
    "                                                                             \"500 or more employees\",\n",
    "                                                                             \"Don't know\"])        \n",
    "    var_type.loc[ col , \"dataset_specific_hardcoded_fix\" ] = \"|\".join( BES_Panel[col].cat.categories.values )\n",
    "        \n",
    "        \n",
    "    col = \"motherNumEmployees\"         \n",
    "    BES_Panel[col] = \\\n",
    "        BES_Panel[col].astype(\"category\").cat.rename_categories(            [\"1 to 24 employees\",\n",
    "                                                                             \"25 to 499 employees\",\n",
    "                                                                             \"500 or more employees\",\n",
    "                                                                             \"Don't know\"])\n",
    "    var_type.loc[ col , \"dataset_specific_hardcoded_fix\" ] = \"|\".join( BES_Panel[col].cat.categories.values )\n",
    "    \n",
    "elif ( dataset_name == \"W12_only\"):\n",
    "    \n",
    "    col = \"headHouseholdPast\"\n",
    "    BES_Panel[col] = \\\n",
    "        BES_Panel[col].astype(\"category\").cat.rename_categories(            [\"My father\",\n",
    "                                                                             \"My mother\",\n",
    "                                                                             \"Someone else\",\n",
    "                                                                             \"No one in my house worked\",\n",
    "                                                                             \"Don't know\"])\n",
    "    var_type.loc[ col , \"dataset_specific_hardcoded_fix\" ] = \"|\".join( BES_Panel[col].cat.categories.values )\n",
    "\n",
    "    col = \"knowf2f2\"\n",
    "    BES_Panel[col] = \\\n",
    "        BES_Panel[col].astype(\"category\").cat.rename_categories( \"False|True|Don't know\".split(\"|\") )\n",
    "    var_type.loc[ col , \"dataset_specific_hardcoded_fix\" ] = \"|\".join( BES_Panel[col].cat.categories.values )    \n",
    "\n",
    "    col = \"knowf2f3\"\n",
    "    BES_Panel[col] = \\\n",
    "        BES_Panel[col].astype(\"category\").cat.rename_categories( \"False|True|Don't know\".split(\"|\") )\n",
    "    var_type.loc[ col , \"dataset_specific_hardcoded_fix\" ] = \"|\".join( BES_Panel[col].cat.categories.values )     \n",
    "#                \"knowf2f2\",\"knowf2f3\", # some of these are categories, some are floats (0.0, 1.0, 99.0)   \n",
    "\n",
    "\n",
    "    # necessary because motherNumEmployees lacks some categories!\n",
    "    NumEmployees = {1.0:\"1 to 24 employees\",\n",
    "                    2.0:\"25 to 499 employees\",\n",
    "                    3.0:\"500 or more employees\",\n",
    "                    9999.0:\"Don't know\"}\n",
    "\n",
    "    col = \"fatherNumEmployees\"\n",
    "    BES_Panel[col] = \\\n",
    "        BES_Panel[col]\\\n",
    "            .apply(lambda x: x if np.isnan(x) else NumEmployees[x] )\\\n",
    "            .astype('category',categories=list( NumEmployees.values() ), ordered = True)\n",
    "\n",
    "    var_type.loc[ col , \"dataset_specific_hardcoded_fix\" ] = \"|\".join( BES_Panel[col].cat.categories.values )      \n",
    "\n",
    "    \n",
    "    col = \"motherNumEmployees\"\n",
    "    BES_Panel[col] = \\\n",
    "        BES_Panel[col]\\\n",
    "            .apply(lambda x: x if np.isnan(x) else NumEmployees[x] )\\\n",
    "            .astype('category',categories=list( NumEmployees.values() ), ordered = True)\n",
    "\n",
    "    var_type.loc[ col , \"dataset_specific_hardcoded_fix\" ] = \"|\".join( BES_Panel[col].cat.categories.values ) \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "variable_categories = pd.read_csv( BES_small_data_files + \"question_categories_correct.csv\",\n",
    "                                   encoding = \"ISO-8859-1\" )\n",
    "variable_categories.drop('Unnamed: 0', axis=1,inplace=True)\n",
    "# flipping list\n",
    "var_cat_dict = dict()\n",
    "# [0,1,2,3,4,5,6,7,-99]\n",
    "type_range = set(variable_categories[\"type\"].values)\n",
    "\n",
    "for typ in type_range:\n",
    "\n",
    "    # \n",
    "    e = variable_categories[variable_categories.type==typ][\"column_name\"].values\n",
    "    var_cat_dict[typ] = [item for sublist in [i.split(\"|\") for i in e] for item in sublist]\n",
    "    var_cat_dict[typ] = [item for item in var_cat_dict[typ] if item not in ignore_list]\n",
    "    \n",
    "# dictionary comprehension to prune column-names to wave non-specific stubs\n",
    "# list(set()) gets rid of repetitions\n",
    "var_cat_dict_pruned   = {k: list(set([prune(x)  for x in v])) for k, v in var_cat_dict.items()}\n",
    "var_cat_dict_pruned_2 = {k: list(set([prune2(x) for x in v])) for k, v in var_cat_dict_pruned.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "missing_col_names = []\n",
    "\n",
    "for col in BES_Panel.columns:\n",
    "    dt =  BES_Panel[col].dtype.name # data type\n",
    "    not_found = False\n",
    "    \n",
    "    if col in ignore_list: # exclude values from ignore_list\n",
    "        var_type.loc[col,\"type\"] = -2\n",
    "        \n",
    "    elif (col == \"id\"): # id\n",
    "        var_type.loc[col,\"type\"] = -5\n",
    "\n",
    "    elif (dt == 'object'): # (probably) text\n",
    "        var_type.loc[col,\"type\"] = -4\n",
    "\n",
    "    elif (\"datetime\" in dt): # datetime\n",
    "        var_type.loc[col,\"type\"] = -3\n",
    "\n",
    "# 0 - personality measures (in steps of .5?), personality_agreeableness ...etc, riskScaleW8        \n",
    "    elif (col in [\"personality_agreeableness\",\n",
    "                 \"personality_conscientiousness\",\n",
    "                 \"personality_extraversion\",\n",
    "                 \"personality_neuroticism\",\n",
    "                 \"personality_openness\"]) or (re.match(\"riskScale(W[0-9]+)?\",col) is not None):\n",
    "        var_type.loc[col,\"type\"] = 0\n",
    "\n",
    "# 7 - pano, mapNames        \n",
    "    elif re.match(\"pano(W[0-9]+)?|mapNames(W[0-9]+)?\" ,col) is not None:\n",
    "        var_type.loc[col,\"type\"] = 7\n",
    "        \n",
    "    \n",
    "    # wave flags/weights (int and float)\n",
    "    elif re.match(\"wave[0-9]+|\"\\\n",
    "                  \"w[0-9]+core|\"\\\n",
    "                  \"w[0-9]+full|\"\\\n",
    "                  \"wt_daily_W[0-9]+|\"\\\n",
    "                  \"wt_core_W[0-9]+|\"\\\n",
    "                  \"wt_full_[W0-9]+|\"\\\n",
    "                  \"wt_new_[W0-9]+|\"\\\n",
    "                  \"CampaignDay(W[0-9]+)?|\"\\\n",
    "                  \"miilabelcertainty(W[0-9]+)?\"\n",
    "                  , col) is not None: \n",
    "        \n",
    "        var_type.loc[col,\"type\"] = -1\n",
    "        \n",
    "    # waveX - wave int wave 0/1 flag\n",
    "    # wave 1-11: wt_full_W6, wt_core_W6, wt_full_W1W2W3W4W5W6W7W8W9), \n",
    "    # waves 10: wt_new_W10, wt_full_W1_W13\n",
    "    # CampaignDayWX\n",
    "    # miilabelcertaintyWX\n",
    "        \n",
    "    else:\n",
    "        not_found = True\n",
    "\n",
    "        for typ in type_range:\n",
    "            pruned_variable_name = prune2( prune(col) )\n",
    "            if pruned_variable_name in var_cat_dict_pruned_2[typ]:\n",
    "                var_type.loc[col,\"type\"] = typ\n",
    "                var_type.loc[col,\"pruned\"] = pruned_variable_name\n",
    "                not_found = False\n",
    "\n",
    "    if not_found == True:\n",
    "        var_type.loc[col] = -99\n",
    "        pruned_variable_name = prune2( prune(col) )\n",
    "        print(\"what's up with this? \" + col, pruned_variable_name )\n",
    "        missing_col_names.append(col)\n",
    "        \n",
    "var_type[\"type\"] = var_type[\"type\"].astype(\"int8\")\n",
    "missing_col_names\n",
    "\n",
    "# reset order of var_type rows to be same as BES_Panel\n",
    "\n",
    "var_type = var_type.loc[BES_Panel.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# BES_Panel[ BES_Panel[missing_col_names].columns[(BES_Panel[missing_col_names].dtypes != \"category\").values] ]\n",
    "\n",
    "\n",
    "# miilabelcertaintyWX -> float\n",
    "# CampaignDayWX -> int -> in with the weights\n",
    "# cciW1W2W3W4W5\tccinoITW1W2W3W4W5\tjustITW1W2W3W4W5\tcciW6W7W8W9\tccinoITW6W7W8W9\tjustITW6W7W8W9\n",
    "#    confusing indicator variables???\n",
    "\n",
    "# knowf2f2W12 knowf2f3W12\n",
    "    # hard to chase down, we don't have \n",
    "\n",
    "\n",
    "# pano|mapNames\n",
    "# personality_agreeableness|personality_conscientiousness|personality_extraversion|personality_neuroticism|personality_openness|riskScale\n",
    "\n",
    "# BES_Panel[\"mapNames\"]\n",
    "\n",
    "\n",
    "# BES_Panel[[\"cciW1W2W3W4W5\" ,\"ccinoITW1W2W3W4W5\", \"justITW1W2W3W4W5\", \"cciW6W7W8W9\", \"ccinoITW6W7W8W9\", \"justITW6W7W8W9\"]]\n",
    "\n",
    "## ?????\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#######################################\n",
      "CATEGORIES\n",
      "#######################################\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "#######################################\n",
      "NON CATEGORIES\n",
      "#######################################\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#######################################################################\n",
    "## MANUAL FIXING OF COLUMN NAMES THAT DON'T ALREADY HAVE A TYPE\n",
    "## Only works for category type variables (you may need to manually drop non-category columns!)\n",
    "## Basically, does its best to automatically guess the matching types (based on the near match of the {answer set})\n",
    "## Appends them to the a copy of \"questions_category_correct\" named 'question_categories_correct_updatesneeded!.csv'\n",
    "## Then I'm afraid you have to look at them, fix them if needed, and then run the code in the cell below again\n",
    "\n",
    "manual_fixing = True\n",
    "missing_col_names_cat_only = []\n",
    "if manual_fixing:\n",
    "    print(\"#######################################\")\n",
    "    print(\"CATEGORIES\")\n",
    "    print(\"#######################################\")\n",
    "    print(\"\\n\")\n",
    "    for col in missing_col_names:\n",
    "        if BES_Panel[col].dtypes.name == 'category':\n",
    "            print(col)\n",
    "            missing_col_names_cat_only.append(col)\n",
    "    print(\"\\n\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"#######################################\")\n",
    "    print(\"NON CATEGORIES\")\n",
    "    print(\"#######################################\")\n",
    "    print(\"\\n\")\n",
    "    for col in missing_col_names:\n",
    "        if BES_Panel[col].dtypes.name != 'category':\n",
    "            print(col)\n",
    "    print(\"\\n\")\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    ## if this only shows \"weight\" variables, it's fine - set manual_fixing to false and ignore!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('lrMay', category),\n",
       " ('manchesterFirst', category),\n",
       " ('manchesterSecond', category),\n",
       " ('liverpoolFirst', category),\n",
       " ('liverpoolSecond', category),\n",
       " ('teesFirst', category),\n",
       " ('teesSecond', category),\n",
       " ('wmidsFirst', category),\n",
       " ('wmidsSecond', category),\n",
       " ('westFirst', category),\n",
       " ('westSecond', category),\n",
       " ('doncasterFirst', category),\n",
       " ('doncasterSecond', category),\n",
       " ('tyneFirst', category),\n",
       " ('tyneSecond', category),\n",
       " ('xprofile_GOR', category),\n",
       " ('profile_GOR', category)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if manual_fixing:\n",
    "\n",
    "    updated_variable_categories = variable_categories.copy()\n",
    "\n",
    "    # question\tfrequency\tquestion_length\tquestion_options\tcolumn_name\ttype\n",
    "\n",
    "    for i in missing_col_names_cat_only:\n",
    "        str_list = [ str(cat) for cat in BES_Panel[i].cat.categories ]\n",
    "        joined_list = \"|\".join(str_list)\n",
    "        match  = (joined_list == updated_variable_categories[\"question\"])\n",
    "        # print(i, \" : \" , \"|\".join(str_list ), \" : \", len(str_list) )\n",
    "        \n",
    "        if match.any(): # answer set already in records\n",
    "            index = updated_variable_categories[match].index\n",
    "            if len(index)>1: # answer set (\"question\") index should be unique!\n",
    "                raise ValueError('answer set (\"question\") index should be unique!')\n",
    "\n",
    "            # add column name and increase frequency\n",
    "            updated_variable_categories.loc[index,\"frequency\"] = updated_variable_categories.loc[index,\"frequency\"]+1\n",
    "            current_list_col_names = updated_variable_categories.loc[index,\"column_name\"].values[0].split(\"|\")\n",
    "            current_list_col_names.append(i)\n",
    "            updated_variable_categories.loc[index,\"column_name\"] = \"|\".join( current_list_col_names )\n",
    "            \n",
    "        else: # answer set not already in records - add new line to dataframe\n",
    "            df = pd.DataFrame([],  columns = updated_variable_categories.columns )\n",
    "\n",
    "            # no need to add index\n",
    "            # updated_variable_categories.shape[0], \n",
    "            df.loc[0] = [joined_list,\n",
    "                         1,\n",
    "                         len(joined_list),\n",
    "                         len(str_list),\n",
    "                         i,-99]\n",
    "            updated_variable_categories = updated_variable_categories.append(df, ignore_index=True)\n",
    "\n",
    "    variable_categories = updated_variable_categories\n",
    "    updated_variable_categories.to_csv(BES_small_data_files + \"question_categories_correct_updatesneeded!.csv\",\n",
    "                                       encoding = \"ISO-8859-1\")\n",
    "    \n",
    "    # rerun after updating list!\n",
    "    \n",
    "    #variable_categories = pd.read_csv(\"question_categories_correct.csv\", encoding = \"ISO-8859-1\")\n",
    "\n",
    "    # flipping list\n",
    "    var_cat_dict = dict()\n",
    "    for typ in [0,1,2,3,4,5,6,7]:\n",
    "        e = variable_categories[variable_categories.type==typ][\"column_name\"].values\n",
    "        var_cat_dict[typ] = [item for sublist in [i.split(\"|\") for i in e] for item in sublist]\n",
    "\n",
    "    # dictionary comprehension to prune column-names to wave non-specific stubs\n",
    "    # list(set()) gets rid of repetitions\n",
    "    var_cat_dict_pruned   = {k: list(set([prune(x)  for x in v])) for k, v in var_cat_dict.items()}\n",
    "    var_cat_dict_pruned_2 = {k: list(set([prune2(x) for x in v])) for k, v in var_cat_dict_pruned.items()}        \n",
    "        \n",
    "#     var_type = pd.DataFrame(columns = ['type'] )\n",
    "    missing_col_names = []\n",
    "\n",
    "    # now update types among 'uncategorised' -99 variable names\n",
    "    for col in BES_Panel.columns:\n",
    "        not_found = True\n",
    "        if var_type.loc[col,\"type\"] == -99:\n",
    "\n",
    "            for typ in [0,1,2,3,4,5,6,7]:\n",
    "                if prune2( prune(col) ) in var_cat_dict_pruned_2[typ]:\n",
    "                    var_type.loc[col,\"type\"] = typ\n",
    "                    not_found = False\n",
    "\n",
    "            if not_found == True:\n",
    "                missing_col_names.append(col)\n",
    "#             raise ValueError('Values still missing second time around! ', col)\n",
    "    var_type[\"type\"] = var_type[\"type\"].astype(\"int8\")\n",
    "    display([x for x in zip(missing_col_names, BES_Panel[missing_col_names].dtypes)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country 3\n",
      "turnoutUKGeneral 1\n",
      "generalElectionVote 3\n",
      "generalElectionVotePost 3\n",
      "generalElectionVoteUnsqueeze 3\n",
      "generalElectionVoteSqueeze 3\n",
      "generalElectionCertaintyUnsq 1\n",
      "generalElectionCertaintySq 1\n",
      "generalElectionCertainty 1\n",
      "partyIdStrength 1\n",
      "partyId 3\n",
      "partyIdSqueeze 3\n",
      "countryOfBirth 3\n",
      "knowf2f1W11 1\n",
      "bestOnMII 3\n",
      "postalapply 1\n",
      "postalTurnout 1\n",
      "decidedVote 5\n",
      "noChanceCoalitionLab 1\n",
      "noChanceCoalitionCon 1\n",
      "noChanceCoalitionLD 1\n",
      "noChanceCoalitionSNP 1\n",
      "noChanceCoalitionPC 1\n",
      "noChanceCoalitionGrn 1\n",
      "noChanceCoalitionUKIP 1\n",
      "noChanceCoalitionNone 1\n",
      "ldCoalition_1 1\n",
      "ldCoalition_2 1\n",
      "ldCoalition_111 1\n",
      "winConstituencyCon 1\n",
      "winConstituencyLab 1\n",
      "winConstituencyLD 1\n",
      "winConstituencyUKIP 1\n",
      "winConstituencyGreen 1\n",
      "winConstituencySNP 1\n",
      "winConstituencyPC 1\n",
      "electionInterest 1\n",
      "likeMay 1\n",
      "likeCorbyn 1\n",
      "likeFarron 1\n",
      "likeSturgeon 1\n",
      "likeWood 1\n",
      "likeNuttall 1\n",
      "likeLucas 1\n",
      "bestPM 5\n",
      "trustMPs 1\n",
      "majorityPartyCon 1\n",
      "majorityPartyLab 1\n",
      "tripleLock 1\n",
      "councilHouse 1\n",
      "energyPriceCap 1\n",
      "keepNukes 1\n",
      "houseBuild 1\n",
      "likeCon 1\n",
      "likeLab 1\n",
      "likeLD 1\n",
      "likeSNP 1\n",
      "likePC 1\n",
      "likeUKIP 1\n",
      "likeGrn 1\n",
      "redistSelf 1\n",
      "redistCon 1\n",
      "redistLab 1\n",
      "redistLD 1\n",
      "redistUKIP 1\n",
      "redistSNP 1\n",
      "redistPC 1\n",
      "redistGreen 1\n",
      "successReduceInequalityCon 1\n",
      "successReduceInequalityLab 1\n",
      "successReduceInequalityLD 1\n",
      "successReduceInequalitySNP 1\n",
      "successReduceInequalityPC 1\n",
      "successReduceInequalityUKIP 1\n",
      "successReduceInequalityGrn 1\n",
      "successReduceInequalityNone 1\n",
      "successReduceInequalityDK 1\n",
      "cutsTooFarNational 1\n",
      "cutsTooFarNHS 1\n",
      "cutsTooFarLocal 1\n",
      "privatTooFar 1\n",
      "enviroProtection 1\n",
      "conUnited 1\n",
      "labUnited 1\n",
      "ldUnited 1\n",
      "snpUnited 1\n",
      "pcUnited 1\n",
      "ukipUnited 1\n",
      "grnUnited 1\n",
      "EUIntegrationSelf 1\n",
      "EUIntegrationCon 1\n",
      "EUIntegrationLab 1\n",
      "EUIntegrationLD 1\n",
      "EUIntegrationSNP 1\n",
      "EUIntegrationPC 1\n",
      "EUIntegrationUKIP 1\n",
      "EUIntegrationGreen 1\n",
      "euRefVote 1\n",
      "mpBrexitView 1\n",
      "handleEUNegotiate 1\n",
      "euPriorityBalance 1\n",
      "euID 5\n",
      "euID1 5\n",
      "euID2 5\n",
      "euID3 5\n",
      "euID4 5\n",
      "euID6 5\n",
      "euID7 5\n",
      "achieveReduceImmigCon 1\n",
      "achieveReduceImmigLab 1\n",
      "achieveReduceImmigLD 1\n",
      "achieveReduceImmigSNP 1\n",
      "achieveReduceImmigPC 1\n",
      "achieveReduceImmigUKIP 1\n",
      "achieveReduceImmigGrn 1\n",
      "achieveReduceImmigNone 1\n",
      "achieveReduceImmigDK 1\n",
      "ptvCon 1\n",
      "ptvLab 1\n",
      "ptvLD 1\n",
      "ptvSNP 1\n",
      "ptvPC 1\n",
      "ptvUKIP 1\n",
      "ptvGrn 1\n",
      "changeEconomy 1\n",
      "changeNHS 1\n",
      "changeEducation 1\n",
      "changeEconomyLab 1\n",
      "changeNHSLab 1\n",
      "changeEducationLab 1\n",
      "localEconNow 1\n",
      "localEcon1520Yr 1\n",
      "leftRight 1\n",
      "lrCon 1\n",
      "lrLab 1\n",
      "lrLD 1\n",
      "lrUKIP 1\n",
      "lrSNP 1\n",
      "lrPC 1\n",
      "lrgreens 1\n",
      "lrCorbyn 1\n",
      "labCandCorbynite 1\n",
      "scotReferendumIntention 1\n",
      "partyMember 2\n",
      "partyMemberPast 3\n",
      "partyMemberNow 3\n",
      "partyContact1 1\n",
      "partyContactCon 1\n",
      "partyContactLab 1\n",
      "partyContactLD 1\n",
      "partyContactSNP 1\n",
      "partyContactPC 1\n",
      "partyContactUKIP 1\n",
      "partyContactOtherParty 1\n",
      "partyContactNone 1\n",
      "partyContactGrn 1\n",
      "partyContactCon_1 1\n",
      "partyContactCon_2 1\n",
      "partyContactCon_3 1\n",
      "partyContactCon_4 1\n",
      "partyContactCon_5 1\n",
      "partyContactCon_6 1\n",
      "partyContactCon_7 1\n",
      "partyContactLab_1 1\n",
      "partyContactLab_2 1\n",
      "partyContactLab_3 1\n",
      "partyContactLab_4 1\n",
      "partyContactLab_5 1\n",
      "partyContactLab_6 1\n",
      "partyContactLab_7 1\n",
      "partyContactLD_1 1\n",
      "partyContactLD_2 1\n",
      "partyContactLD_3 1\n",
      "partyContactLD_4 1\n",
      "partyContactLD_5 1\n",
      "partyContactLD_6 1\n",
      "partyContactLD_7 1\n",
      "partyContactSNP_1 1\n",
      "partyContactSNP_2 1\n",
      "partyContactSNP_3 1\n",
      "partyContactSNP_4 1\n",
      "partyContactSNP_5 1\n",
      "partyContactSNP_6 1\n",
      "partyContactSNP_7 1\n",
      "partyContactPC_1 1\n",
      "partyContactPC_2 1\n",
      "partyContactPC_3 1\n",
      "partyContactPC_4 1\n",
      "partyContactPC_5 1\n",
      "partyContactPC_6 1\n",
      "partyContactPC_7 1\n",
      "partyContactUKIP_1 1\n",
      "partyContactUKIP_2 1\n",
      "partyContactUKIP_3 1\n",
      "partyContactUKIP_4 1\n",
      "partyContactUKIP_5 1\n",
      "partyContactUKIP_6 1\n",
      "partyContactUKIP_7 1\n",
      "partyContactOther_1 1\n",
      "partyContactOther_2 1\n",
      "partyContactOther_3 1\n",
      "partyContactOther_4 1\n",
      "partyContactOther_5 1\n",
      "partyContactOther_6 1\n",
      "partyContactOther_7 1\n",
      "localTurnoutRetro 1\n",
      "localElectionVote 3\n",
      "conLookAfterMC 1\n",
      "conLookAfterWC 1\n",
      "labLookAfterMC 1\n",
      "labLookAfterWC 1\n",
      "ukipLookAfterMC 1\n",
      "ukipLookAfterWC 1\n",
      "snpLookAfterMC 1\n",
      "snpLookAfterWC 1\n",
      "discussPolDays 1\n",
      "debateOneWatch 1\n",
      "debateThreeWatch 1\n",
      "debateTwoWatch 1\n",
      "conTone 1\n",
      "labTone 1\n",
      "ldTone 1\n",
      "snpTone 1\n",
      "pcTone 1\n",
      "ukipTone 1\n",
      "grnTone 1\n",
      "participation_1 1\n",
      "participation_2 1\n",
      "participation_3 1\n",
      "participation_4 1\n",
      "participation_5 1\n",
      "participation_6 1\n",
      "infoSourceTV 1\n",
      "infoSourcePaper 1\n",
      "infoSourceRadio 1\n",
      "infoSourceInternet 1\n",
      "twitterUse 1\n",
      "twitterInfo_1 1\n",
      "twitterInfo_2 1\n",
      "twitterInfo_3 1\n",
      "fbUse 1\n",
      "fbInfo_1 1\n",
      "fbInfo_2 1\n",
      "fbInfo_3 1\n",
      "sharedContentOnline_1 1\n",
      "sharedContentOnline_2 1\n",
      "sharedContentOnline_3 1\n",
      "sharedContentOnline_4 1\n",
      "sharedContentOnline_5 1\n",
      "dutyToVote2 1\n",
      "socialPressureVote 1\n",
      "subjClass 3\n",
      "handleMIICon 1\n",
      "handleMIILab 1\n",
      "handleMIILD 1\n",
      "handleMIISNP 1\n",
      "handleMIIPC 1\n",
      "handleMIIUKIP 1\n",
      "handleMIIGrn 1\n",
      "relationshipName1 3\n",
      "relationshipName2 3\n",
      "relationshipName3 3\n",
      "discussantsSameAddress_1 1\n",
      "discussantsSameAddress_2 1\n",
      "discussantsSameAddress_3 1\n",
      "discussantsSameAddress_222 1\n",
      "discussantsSameAddress_99 1\n",
      "discussantVoteName1 3\n",
      "discussantVoteName2 3\n",
      "discussantVoteName3 3\n",
      "discussantturnoutName1 1\n",
      "discussantturnoutName2 1\n",
      "discussantturnoutName3 1\n",
      "discussantApprovalVoteName1 1\n",
      "discussantApprovalVoteName2 1\n",
      "discussantApprovalVoteName3 1\n",
      "askVoteDiscuss1 1\n",
      "askVoteDiscuss2 1\n",
      "askVoteDiscuss3 1\n",
      "askVotePartner 1\n",
      "askVoteLivingWith 1\n",
      "askVoteOther 1\n",
      "discussAskVoteNone 1\n",
      "ashcroft 3\n",
      "reaskVote 3\n",
      "changeView 1\n",
      "newspaper 3\n",
      "britishness 1\n",
      "scottishness 1\n",
      "welshness 1\n",
      "englishness 1\n",
      "europeanness 1\n",
      "knowf2f2 1\n",
      "knowf2f3 1\n",
      "knowf2f4 1\n",
      "knowf2f5 1\n",
      "knowf2f6 1\n",
      "econPersonalRetro 1\n",
      "econGenRetro 1\n",
      "renationaliseRail 1\n",
      "overseasAid 1\n",
      "immigSelf 1\n",
      "immigCon 1\n",
      "immigLab 1\n",
      "immigLD 1\n",
      "immigSNP 1\n",
      "immigPC 1\n",
      "immigUKIP 1\n",
      "immigGreen 1\n",
      "blackEquality 1\n",
      "femaleEquality 1\n",
      "gayEquality 1\n",
      "currentUnionMember 1\n",
      "everUnionMember 1\n",
      "workingStatus 3\n",
      "preschoolKidsInHouse 1\n",
      "schoolKidsInHouse 1\n",
      "sickElderlyInHouse 1\n",
      "noDependentsInHouse 1\n",
      "prevJob 1\n",
      "selfOccStatus 1\n",
      "selfOccSupervise 1\n",
      "selfOccOrgSize 1\n",
      "selfOccEmployees 1\n",
      "selfNumEmployees 1\n",
      "selfOccStatusLast 1\n",
      "selfOccSuperviseLast 1\n",
      "selfOccOrgSizeLast 1\n",
      "selfOccEmployeesLast 1\n",
      "selfNumEmployeesLast 1\n",
      "anyUni 1\n",
      "euRefTurnoutRetro 1\n",
      "euRefpastVote 1\n",
      "referendumrecall 2\n",
      "age 6\n",
      "profile_work_stat 3\n",
      "disability 1\n",
      "ageGroup 1\n",
      "voted2015 1\n",
      "edlevel 1\n",
      "gender 1\n",
      "marital 3\n",
      "housing 3\n",
      "gor 3\n",
      "education 3\n",
      "profile_ethnicity 3\n",
      "profile_socialgrade_cie 5\n",
      "profile_religion 3\n",
      "profile_education_age 1\n",
      "profile_lea 3\n",
      "profile_oslaua 3\n",
      "profile_gross_personal 1\n",
      "profile_household_children 1\n",
      "profile_past_vote_2005 3\n",
      "profile_religion_denom 3\n",
      "profile_past_vote_2015 3\n",
      "profile_turnout_2015 1\n",
      "profile_eurefvote 1\n",
      "profile_eurefturnout 1\n",
      "personality_agreeableness 0\n",
      "personality_conscientiousness 0\n",
      "personality_extraversion 0\n",
      "personality_neuroticism 0\n",
      "personality_openness 0\n",
      "lr1W10W11 1\n",
      "lr2W10W11 1\n",
      "lr3W10W11 1\n",
      "lr4W10W11 1\n",
      "lr5W10W11 1\n",
      "al1W10W11 1\n",
      "al2W10W11 1\n",
      "al3W10W11 1\n",
      "al4W10W11 1\n",
      "al5W10W11 1\n",
      "privPrimSchoolW1_W4W7W9_ 1\n",
      "privSecondSchoolW1_W4W7W9_ 1\n",
      "neverPrivSchoolW1_W4W7W9_ 1\n",
      "RPrivSchnew_dkW1_W4W7W9_ 1\n",
      "speakWelshW1_W4W7W9_ 1\n",
      "lr_scaleW10W11 1\n",
      "al_scaleW10W11 1\n",
      "pano 7\n",
      "headHouseholdPast 3\n",
      "fatherNumEmployees 1\n",
      "motherNumEmployees 1\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "\n",
    "# ditch ignore_list values\n",
    "# ditch indicator values\n",
    "\n",
    "# 'numeric' columns (ones that can be transformed into numbers)\n",
    "num_cols     = BES_Panel.columns[ (var_type[\"type\"].apply( lambda x: x in [0,1,2,3,5,6,7] )).values ]\n",
    "# can't be transformed into numbers / are numbers but are meta-data rather than raw content (e.g. weights)\n",
    "non_num_cols = BES_Panel.columns[ (var_type[\"type\"].apply( lambda x: x in [-99,-5,-4,-3,-1 ]  )).values ]\n",
    "\n",
    "BES_numeric  = BES_Panel[num_cols].copy()\n",
    "\n",
    "\n",
    "pos = 0\n",
    "for col in BES_numeric:\n",
    "    pos = pos + 1\n",
    "\n",
    "    \n",
    "    if col not in var_type[\"type\"].index:\n",
    "        print(col, \" not in var_type\")\n",
    "        continue\n",
    "    typ = var_type.loc[ col, \"type\" ]\n",
    "#     print(col,typ)    \n",
    "    \n",
    "    if (typ==0) | (typ==7):\n",
    "        continue\n",
    "    \n",
    "    # force all category elements into strings\n",
    "    # ARE THEY EVER NOT?\n",
    "    BES_numeric[col].cat.rename_categories( BES_numeric[col].cat.categories.map(str), inplace=True )\n",
    "    \n",
    "    # flag up typos for BES\n",
    "    typos_in_categopries = typos.intersection(BES_numeric[col].cat.categories)\n",
    "    if typos_in_categopries:\n",
    "        var_type.loc[ col, \"typos\" ]   = \"|\".join( typos_in_categopries )\n",
    "    \n",
    "    \n",
    "    # rename categories\n",
    "    join_list = \"|\".join( BES_numeric[col].cat.categories ) # create category_list_string \"strongly agree|agree|neither|...\"\n",
    "    var_type.loc[ col, \"original_cat_list\" ] = join_list\n",
    "    \n",
    "    if join_list in rename_cat_dict.keys():\n",
    "        BES_numeric[col].cat.rename_categories(  rename_cat_dict[join_list], inplace=True )\n",
    "        var_type.loc[ col, \"renamed_cat_list\" ]   = \"|\".join( BES_numeric[col].cat.categories )\n",
    "        # note renaming!\n",
    "    # update join_list!\n",
    "    \n",
    "    # reorder categories\n",
    "    join_list = \"|\".join( BES_numeric[col].cat.categories )\n",
    "    if join_list in change_cat_dict.keys():\n",
    "        BES_numeric[col].cat.reorder_categories( change_cat_dict[join_list], inplace=True )\n",
    "        var_type.loc[ col, \"reordered_cat_list\" ] = \"|\".join( BES_numeric[col].cat.categories )\n",
    "        # note reordering\n",
    "    \n",
    "    # remove \"Don't Know\"s that are in weird numerical form (eg. [ \"9999.0\", \"997.0\", \"222.0\", \"99.0\", \"0.0\" ])\n",
    "    # de_weasel numbers\n",
    "    \n",
    "    numerical_dont_knows = de_weasel_nums( BES_numeric[col].cat.categories )\n",
    "    if len(numerical_dont_knows) != 0:\n",
    "        BES_numeric[col].cat.remove_categories( numerical_dont_knows , inplace=True )\n",
    "        var_type.loc[ col, \"numerical_dont_knows\" ] = \"|\".join( numerical_dont_knows )\n",
    "    \n",
    "    # set all digits to floating point format, one decimal place\n",
    "    BES_numeric[col].cat.rename_categories( de_num( BES_numeric[col].cat.categories ), inplace=True )\n",
    "                                          \n",
    "    # de_weasel\n",
    "    weasel_words = BES_numeric[col].cat.categories.intersection(Weasel_set)\n",
    "    if len(weasel_words) != 0:    \n",
    "        BES_numeric[col].cat.remove_categories( weasel_words, inplace=True )\n",
    "        var_type.loc[ col, \"weasel_words\" ] = \"|\".join( weasel_words )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# types\n",
    "# -99 - Uncategorised!\n",
    "# -5 - id\n",
    "# -4 - text\n",
    "# -3 - datetimes\n",
    "# -2 - ignore_list\n",
    "# -1 - weights/wave indicators/campaign day indicators/miilabeluncertainty\n",
    "# 0 - personality measures (in steps of .5?), personality_agreeableness ...etc, riskScale\n",
    "# 1 - linear category, just use  (some made linear by dropping \"Weasel_answers\")\n",
    "# 2 - categories need to be modified - order changed\n",
    "# 3 - set of non-ordered options\n",
    "# 4 - indirect variables - did someone fill something in in the free text box or not?\n",
    "# 5 - categories need to modified - things removed\n",
    "    # not so clear when this one applies - is it supposed to be whenever weasel words are removed?\n",
    "    # or when variables are *changed*\n",
    "# 6 - categories are integers - should maybe be transformed directly into numbers (mostly \"how much money do people need minimum/well off\"?)\n",
    "# 7 - pano, mapNames\n",
    "\n",
    "\n",
    "\n",
    "# [-5, -4, -3, -2, -1, 4] -> meta list\n",
    "# [0, 1, 2, 3, 5, 6, 7] -> \n",
    "\n",
    "# ordinal: 0, 1, 2, 5, 6\n",
    "# non-ordinal: 3, 7\n",
    "\n",
    "# load question_categories_correct.csv\n",
    "# sanity check by type!\n",
    "# turn into list of variables by type\n",
    "# 1, 5 handled the same way -> cat.codes\n",
    "# 6 -> int()\n",
    "# 4 ignored\n",
    "# 3 ignored for now (-> vectorized?)\n",
    "# 2 direct modification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2799"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save category data\n",
    "cat_dictionary = {}\n",
    "\n",
    "for col in BES_numeric.columns:\n",
    "#     print(col)\n",
    "    if var_type[\"type\"][col] in [1, 2, 3, 5]: # not just cat, but one not already numerical!\n",
    "        cat_dictionary[col] = BES_numeric[col].cat.categories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# turn categories into numbers\n",
    "\n",
    "for col in BES_numeric:\n",
    "    \n",
    "    typ = var_type[\"type\"][col]\n",
    "    \n",
    "    if (typ == 0): # not necessarily already float now!\n",
    "        BES_numeric[col] = BES_numeric[col].astype('float64')\n",
    "        \n",
    "    elif (typ==1) | (typ==2) | (typ==5): # more or less ordinal, replace string categories with \n",
    "        BES_numeric[col] = BES_numeric[col].cat.codes\n",
    "        BES_numeric[col] = BES_numeric[col].astype('float64')\n",
    "     \n",
    "    elif (typ==3): # categporical not ordinal\n",
    "        BES_numeric[col] = BES_numeric[col].cat.codes\n",
    "        BES_numeric[col] = BES_numeric[col].astype('float64')\n",
    "        \n",
    "    elif (typ==6): # categories are integers - better to translate directly\n",
    "        BES_numeric[col] = BES_numeric[col].astype('float64')\n",
    "        \n",
    "    elif (typ==7): # integers - better to translate directly\n",
    "        BES_numeric[col] = BES_numeric[col].astype('float64')        \n",
    "        \n",
    "BES_numeric.replace(-1,np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "401"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# BES_numeric.replace(-1,np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# BES_numerics_only = BES_numeric.drop( BES_numeric.columns[~( (var_type[\"type\"]==0) |\n",
    "#                                                              (var_type[\"type\"]==1) |\n",
    "#                                                              (var_type[\"type\"]==2) |\n",
    "#                                                              (var_type[\"type\"]==5) |\n",
    "#                                                              (var_type[\"type\"]==6) ) ], axis=1 )\n",
    "\n",
    "# BES_numerics_only.replace(-1,np.nan, inplace=True)\n",
    "# # gender only column that has no nan -> still an int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# BES_all_categories = BES_numeric.drop( BES_numeric.columns[~( (var_type[\"type\"]==0) |\n",
    "#                                                              (var_type[\"type\"]==1) |\n",
    "#                                                              (var_type[\"type\"]==2) |\n",
    "#                                                              (var_type[\"type\"]==3) |\n",
    "#                                                              (var_type[\"type\"]==5) |\n",
    "#                                                              (var_type[\"type\"]==6) ) ], axis=1 )\n",
    "\n",
    "# BES_all_categories.replace(-1,np.nan, inplace=True)\n",
    "# # gender only column that has no nan -> still an int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# BES_numerics_only = BES_all_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# BES_num_and_cat.to_stata( BES_data_folder+\"BESW8num_and_cat.hdf\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# wave = \"W13_only\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fname = data_subfolder + \"cat_dictionary.pkl\"\n",
    "with open(fname, \"wb\") as f:\n",
    "    pickle.dump( cat_dictionary, f )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Cannot store a category dtype in a HDF5 dataset that uses format=\"fixed\". Use format=\"table\".",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-251-0815be52a91e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mBES_non_numeric\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBES_Panel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnon_num_cols\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mBES_non_numeric\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_hdf\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mdata_subfolder\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"BESnon_numeric.hdf\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"BESnon_numeric\"\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\BES_analysis\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_hdf\u001b[1;34m(self, path_or_buf, key, **kwargs)\u001b[0m\n\u001b[0;32m   1297\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1298\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpytables\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1299\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mpytables\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_hdf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1300\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1301\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mto_msgpack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath_or_buf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\BES_analysis\\lib\\site-packages\\pandas\\io\\pytables.py\u001b[0m in \u001b[0;36mto_hdf\u001b[1;34m(path_or_buf, key, value, mode, complevel, complib, append, **kwargs)\u001b[0m\n\u001b[0;32m    278\u001b[0m         with HDFStore(path_or_buf, mode=mode, complevel=complevel,\n\u001b[0;32m    279\u001b[0m                       complib=complib) as store:\n\u001b[1;32m--> 280\u001b[1;33m             \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    281\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m         \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\BES_analysis\\lib\\site-packages\\pandas\\io\\pytables.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(store)\u001b[0m\n\u001b[0;32m    272\u001b[0m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mstore\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 274\u001b[1;33m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mstore\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    275\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m     \u001b[0mpath_or_buf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_stringify_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\BES_analysis\\lib\\site-packages\\pandas\\io\\pytables.py\u001b[0m in \u001b[0;36mput\u001b[1;34m(self, key, value, format, append, **kwargs)\u001b[0m\n\u001b[0;32m    889\u001b[0m             \u001b[0mformat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_option\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"io.hdf.default_format\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;34m'fixed'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    890\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 891\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_write_to_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mappend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    892\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\BES_analysis\\lib\\site-packages\\pandas\\io\\pytables.py\u001b[0m in \u001b[0;36m_write_to_group\u001b[1;34m(self, key, value, format, index, append, complib, encoding, **kwargs)\u001b[0m\n\u001b[0;32m   1331\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1332\u001b[0m         \u001b[1;31m# write the object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1333\u001b[1;33m         \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mappend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcomplib\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcomplib\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1334\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1335\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_table\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\BES_analysis\\lib\\site-packages\\pandas\\io\\pytables.py\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(self, obj, **kwargs)\u001b[0m\n\u001b[0;32m   2911\u001b[0m             \u001b[1;31m# I have no idea why, but writing values before items fixed #2299\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2912\u001b[0m             \u001b[0mblk_items\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2913\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'block%d_values'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitems\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mblk_items\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2914\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'block%d_items'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblk_items\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2915\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\BES_analysis\\lib\\site-packages\\pandas\\io\\pytables.py\u001b[0m in \u001b[0;36mwrite_array\u001b[1;34m(self, key, value, items)\u001b[0m\n\u001b[0;32m   2630\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2631\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_categorical_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2632\u001b[1;33m             raise NotImplementedError('Cannot store a category dtype in '\n\u001b[0m\u001b[0;32m   2633\u001b[0m                                       \u001b[1;34m'a HDF5 dataset that uses format='\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2634\u001b[0m                                       '\"fixed\". Use format=\"table\".')\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: Cannot store a category dtype in a HDF5 dataset that uses format=\"fixed\". Use format=\"table\"."
     ]
    }
   ],
   "source": [
    "BES_non_numeric = BES_Panel[non_num_cols].copy()\n",
    "BES_non_numeric.to_hdf( data_subfolder + \"BESnon_numeric.hdf\", \"BESnon_numeric\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BES_numeric.to_hdf( data_subfolder + \"BESnumeric.hdf\", \"BESnumeric\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "var_type.to_hdf( data_subfolder + \"var_type.hdf\", \"var_type\")\n",
    "# don't think the performance warning will be relevant on such a small dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fname = BES_data_folder+\"cat_dictionary\"+\".pkl\"\n",
    "# with open(fname, \"wb\") as f:\n",
    "#     pickle.dump( cat_dictionary, f )\n",
    "    \n",
    "# BES_non_numeric = BES_Panel[non_num_cols].copy()\n",
    "# BES_non_numeric.to_hdf( BES_data_folder+\"BESW8non_numeric.hdf\", \"BESW8non_numeric\" )\n",
    "\n",
    "# BES_numeric.to_hdf( BES_data_folder+\"BESW8numeric.hdf\", \"BESW8numeric\" )\n",
    "\n",
    "# var_type.to_hdf( BES_data_folder+\"var_type.hdf\", \"var_type\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "var_type[\"type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import sys\n",
    "# for var, obj in locals().items():\n",
    "#     if sys.getsizeof(obj) >100000:\n",
    "#         print(var, sys.getsizeof(obj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TEST CODE\n",
    "# Checking to see if different column names have same question set but are assigned different types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test to see if pruning \"_wave\" leads to differing variable categories\n",
    "for key in var_cat_dict_pruned.keys():\n",
    "    for val in var_cat_dict_pruned[key]:\n",
    "        for other_key in var_cat_dict_pruned.keys():\n",
    "            if key==other_key: # don't check same category\n",
    "                continue\n",
    "            if val in var_cat_dict_pruned[other_key]:\n",
    "                print(\"problem: {0} {1} {2}\".format(key, val, other_key) )\n",
    "            \n",
    "# mixing 1 and 5 is fine, because 5 (mis-ordered ordinal) is turned into 1 (correctly ordered ordinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test to see if further pruning \"_num\" leads to differing variable categories\n",
    "for key in var_cat_dict_pruned_2.keys():\n",
    "    for val in var_cat_dict_pruned_2[key]:\n",
    "        for other_key in var_cat_dict_pruned_2.keys():\n",
    "            if key==other_key: # don't check same category\n",
    "                continue\n",
    "            if val in var_cat_dict_pruned_2[other_key]:\n",
    "                print(\"problem: {0} {1} {2}\".format(key, val, other_key) )\n",
    "            \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pano, mapNames\n",
    "# weights\n",
    "# personality\n",
    "# datetimes -> remove on type\n",
    "# text -> remove on type\n",
    "\n",
    "# weights, datetimes, text -> saved separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (BES_Panel[ 'CampaignDayW5' ]-19).abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# W5_cats_df.corrwith( (BES_Panel[ 'CampaignDayW5' ]-19).abs() ).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# corr_df[\"absolute corr\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sample_size = W5_cats_df.notnull().apply(lambda x: x& BES_Panel[ 'CampaignDayW5' ].notnull()).sum()\n",
    "# corr = W5_cats_df.corrwith(BES_Panel[ 'CampaignDayW5' ])\n",
    "\n",
    "\n",
    "# corr_df = pd.DataFrame(corr, columns= [\"corr\"])\n",
    "# corr_df[\"sample_size\"] = sample_size\n",
    "# corr_df[\"absolute corr\"] = corr.abs()\n",
    "# corr_df[corr_df[\"sample_size\"]>2000].sort_values(by=\"absolute corr\", ascending=False).head(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # BES_Panel[ 'CampaignDayW5' ].corr(W5_cats_df)\n",
    "# W5_cats_df.corrwith(BES_Panel[ 'CampaignDayW5' ]).sort_values().hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # 283 with \"W5\" in\n",
    "# # 248 with \"W5\" in AND category\n",
    "\n",
    "# W5cats = [x for x in BES_Panel.columns if (\"W5\" in x) & (BES_Panel[x].dtype.name =='category')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# W5_cats_df = BES_Panel[W5cats].apply(lambda x : x.cat.codes).replace(-1,np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# BES_Panel[\"selfNumEmployeesLastW6W7W8W9\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# BES_Panel[\"londonTurnoutW7\"].cat.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:BES_analysis]",
   "language": "python",
   "name": "conda-env-BES_analysis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
