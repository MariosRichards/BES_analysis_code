{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "import re\n",
    "\n",
    "from itertools import cycle\n",
    "from IPython.display import display\n",
    "import pickle, os\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from IPython.core.debugger import set_trace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you should clone this git to this subdirectory (in some directory - I call it BES_analysis - doesn't matter though)\n",
    "\n",
    "if os.getcwd().split(os.sep)[-1] != 'BES_analysis_code':\n",
    "    raise Exception(\"Stop! You're in the wrong directory - should be in 'BES_analysis_code'\")\n",
    "\n",
    "BES_code_folder   = \"../BES_analysis_code/\" # we should be here!\n",
    "BES_small_data_files = BES_code_folder + \"small data files\" + os.sep\n",
    "if not os.path.exists( BES_small_data_files ):\n",
    "    os.makedirs( BES_small_data_files )\n",
    "\n",
    "# we should create these if they don't already exist\n",
    "BES_data_folder   = \"../BES_analysis_data/\"\n",
    "if not os.path.exists( BES_data_folder ):\n",
    "    os.makedirs( BES_data_folder )\n",
    "\n",
    "BES_output_folder = \"../BES_analysis_output/\"\n",
    "if not os.path.exists( BES_output_folder ):\n",
    "    os.makedirs( BES_output_folder )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Jupyter_module_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = \"ISO-8859-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## HELPER FUNCTIONS / REPLACEMENT VALUE DICTIONARIES\n",
    "\n",
    "# Rename -> Reorder\n",
    "\n",
    "# changing the order of some sets of categories\n",
    "change_cat_dict = {\"Bad time to buy|Good time to buy|Neither good nor bad time to buy|Don't know\": [\"Bad time to buy\",\n",
    "                                                                                                    \"Neither good nor bad time to buy\",\n",
    "                                                                                                    \"Good time to buy\",\n",
    "                                                                                                    \"Don't know\"],\n",
    "                   \"Larger|Smaller|About the same|Don't know\": [\"Larger\", \"About the same\", \"Smaller\",\"Don't know\"],\n",
    "                   \"Yes|No|99.0\":       ['No', 'Yes', '99.0'],\n",
    "                   \"Yes|No|Don't know\": ['No', 'Yes', \"Don't know\"],\n",
    "                   \"Yes|No\" :           ['No', 'Yes'],                   \n",
    "                   \"Yes|No|Did not vote|Don't know\" : [\"No\",\"Yes\",\"Did not vote\",\"Don't know\"],\n",
    "                   \"Yes, voted|No, did not vote|Don't know\" : [\"No, did not vote\", \"Yes, voted\", \"Don't know\"],\n",
    "                   \"I would/will not vote|Leave the EU|Stay in the EU|Don't know\":\n",
    "                       ['Stay in the EU', 'Leave the EU', 'I would/will not vote', \"Don't know\"],\n",
    "                   \"Mainly leave|Mainly remain|Fairly evenly divided|Don't know\": [\"Mainly remain\",\n",
    "                                                                                   \"Fairly evenly divided\", \"Mainly leave\", \"Don't know\"],\n",
    "                   \"An individual share in a company|A portfolio of different company shares|The risk is the same|Don't know|Prefer not to say\":\n",
    "                       ['An individual share in a company', 'The risk is the same', 'A portfolio of different company shares',\"Prefer not to say\",\"Don't know\"],\n",
    "                   \"No, I have never been a member|Yes, I am a member of a party|I am not a member now but I used to be|Don't know\":\n",
    "                       ['No, I have never been a member', 'I am not a member now but I used to be', 'Yes, I am a member of a party', \"Don't know\"],\n",
    "                   \"Never or practically never|Less often than once a year|Less often but at least once a year|Less often but at least twice a year|Less often but at least once a month|Less often but at least once in two weeks|Once a week or more|Varies too much to say|I am not religious|Don't know\":\n",
    "                       ['I am not religious', 'Never or practically never', 'Less often than once a year',\n",
    "                        'Less often but at least once a year', 'Less often but at least twice a year',\n",
    "                        'Less often but at least once a month', 'Less often but at least once in two weeks',\n",
    "                        'Once a week or more', \"Varies too much to say\",\"Don't know\"],\n",
    "                   \"under £5,000 per year|£5,000 to £9,999 per year|£10,000 to £14,999 per year|£15,000 to £19,999 per year|£20,000 to £24,999 per year|£25,000 to £29,999 per year|£30,000 to £34,999 per year|£35,000 to £39,999 per year|£40,000 to £44,999 per year|£45,000 to £49,999 per year|£50,000 to £59,999 per year|£60,000 to £69,999 per year|£70,000 to £99,999 per year|£100,000 to £149,999 per year|£150,000 and over|Don't know|Prefer not to answer\":\n",
    "                       [ 'under £5,000 per year',\n",
    "                         '£5,000 to £9,999 per year',\n",
    "                         '£10,000 to £14,999 per year',\n",
    "                         '£15,000 to £19,999 per year',\n",
    "                         '£20,000 to £24,999 per year',\n",
    "                         '£25,000 to £29,999 per year',\n",
    "                         '£30,000 to £34,999 per year',\n",
    "                         '£35,000 to £39,999 per year',\n",
    "                         '£40,000 to £44,999 per year',\n",
    "                         '£45,000 to £49,999 per year',\n",
    "                         '£50,000 to £59,999 per year',\n",
    "                         '£60,000 to £69,999 per year',\n",
    "                         '£70,000 to £99,999 per year',\n",
    "                         '£100,000 to £149,999 per year',\n",
    "                         '£150,000 and over',                         \n",
    "                         'Prefer not to answer',\n",
    "                         \"Don't know\",], # change order of \"don't know\" and \"prefer not to answer\" to keep don't knows last\n",
    "                   \"1|2|3|4|5|6|7|8 or more|Don't know|Prefer not to say\":\n",
    "                       [\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8 or more\",\"Prefer not to say\",\"Don't know\"],\n",
    "                   \"The Yes side|The No side|Neither|Don't know\":\n",
    "                       [\"The Yes side\",\"Neither\",\"The No side\",\"Don't know\"], # is this ordinal - meh?\n",
    "                   \"1|2|3|4|5|6|7|8|9|Right  10|Don't know|Left  0\":\n",
    "                       [\"Left  0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"Right  10\",\"Don't know\"], # lrMayW12\n",
    "                   \"No|Yes, received a dose|Yes, booked an appointment|Don't know\":\n",
    "                       [\"No\",\"Yes, booked an appointment\",\"Yes, received a dose\",\"Don't know\"],#\n",
    "\n",
    "                   \n",
    "                  }\n",
    "\n",
    "reorder_variable_dict = pd.DataFrame.from_dict({k : \"|\".join(v) for k, v in change_cat_dict.items()},orient='index').reset_index()\n",
    "reorder_variable_dict.columns = [\"original_cat_list\",\"reordered_cat_list\"]\n",
    "reorder_variable_dict.to_csv( BES_small_data_files + \"reorder_variable_dict.csv\" )\n",
    "\n",
    "# reorder categories\n",
    "def re_order(ques):\n",
    "    if ques in change_cat_dict.keys():\n",
    "        return \"|\".join( change_cat_dict[ques] )\n",
    "    else:\n",
    "        return ques\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## typos - more directly useful for the BES!\n",
    "# typos = set(['Do\\x92t know', 'Dont know', 'Donât know', 'Don??t know','DonaÂ€Â™t know'])# ,\n",
    "#          \"9999.0\", \"997.0\", \"222.0\", \"99.0\", \"0.0\", \"1.0\", \"2.0\"   ]) # problem here, is this picks up numeric sequences ...\n",
    "\n",
    "\n",
    "\n",
    "# Big set of actual answers **I interpet** as non-answers (and set to NaN)\n",
    "# REALLY MERITS RECHECKING WHAT THE IMPACT OF THIS IS!\n",
    "Weasel_answers = [\"Don't know\",\"Donâ€™t know\",\n",
    "                  \"Prefer not to say\", \"Prefer not to answer\", \"Refused\", \"Unknown\",\n",
    "                  \"Neither\", \"Other\", \"I would/will not vote\", \"Will not vote\",\n",
    "                  \"I would not vote\", \"It depends\", \"Other\",\n",
    "                  \"Don't follow politics on twitter\",\n",
    "                  \"Yes, other\", \"Haven't thought about it\",\n",
    "                  \"There wasn't a local election in my area\", \"No, haven't received it\",\n",
    "                  \"I don't know what was negotiated\", \"I never received a response\",\n",
    "                  \"There are not local elections in my area\", \"Can't remember\",\n",
    "                  \"Varies too much to say\", \"Will not state a choice\",\n",
    "                  \"All leaders equally good\", \"They are not eligible to vote\",\n",
    "                  \"There are not local elections in my area\", \"Both/neither\",\n",
    "                  \"Did not vote\",\"Can't remember\",\n",
    "                  \"Not sure\",\"Did not choose a candidate\",\"There wasn't a Mayoral Election in my area\",\n",
    "                  \"NA\",\"They did not vote\",\"They were not eligible to vote\",\n",
    "]\n",
    "\n",
    "# BES codes for NaN/other/misc/none of the above\n",
    "Weasel_number_answers = [ \"9999.0\", \"997.0\", \"222.0\", \"99.0\", \"0.0\", \"9999\", \"98.0\" ]\n",
    "\n",
    "# non-answer answers\n",
    "Weasel_set = set(Weasel_answers) # gets rid of duplicates!\n",
    "\n",
    "\n",
    "## define 'de_Weasel' function to remove Weasel Words from lists of options\n",
    "## ie. \"Yes|No|Don't know\" -> \"Yes|No\"\n",
    "\n",
    "# Weasel_answers = [\"Don't know\", 'Don?t know', 'Donâ??t know', 'Do\\x92t know', 'Dont know', 'Donât know',\n",
    "#                   \"Prefer not to say\", \"Prefer not to answer\", \"Refused\", \"Unknown\", \"Neither\", \"Other\",\n",
    "#                   \"I would/will not vote\", \"Will not vote\", \"No - not decided\", \"I would not vote\", \"It depends\",\n",
    "#                   \"Other\", \"Don’t follow politics on Facebook\", \"Don't follow politics on twitter\", \"9999.0\", \"997.0\",\n",
    "#                   \"222.0\", \"Yes, other\", \"Haven't thought about it\", \"There wasn't a local election in my area\",\n",
    "#                   \"No, haven't received it\", \"I don't know what was negotiated\", \"I never received a response\",\n",
    "#                   \"There are not local elections in my area\", \"Can't remember\", \"Varies too much to say\" ]\n",
    "\n",
    "# # non-answer answers\n",
    "# Weasel_set = set(Weasel_answers) # gets rid of duplicates!\n",
    "\n",
    "# remove weasel phrases\n",
    "def de_weasel(ques): \n",
    "    return \"|\".join( [x for x in ques.split(\"|\") if x not in Weasel_answers] )\n",
    "\n",
    "def de_num_el(el):\n",
    "    if el.isdigit():\n",
    "        el = \"%.1f\" % int( el )\n",
    "    return el\n",
    "\n",
    "def de_number(ques):\n",
    "    return \"|\".join( [de_num_el(x) for x in ques.split(\"|\")] )\n",
    "\n",
    "def de_num(ques):\n",
    "    return [de_num_el(x) for x in ques]\n",
    "\n",
    "def floatable(flt):\n",
    "    try:\n",
    "        float(flt)\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "# Weasel_number_answers\n",
    "# Remove 'weasel' numbers\n",
    "# but only if they are the last element\n",
    "# or not the last element, but the next is not a number\n",
    "# to avoid catching parts of sequential numerical categories\n",
    "def de_weasel_numbers(ques):\n",
    "    el_list = ques.split(\"|\")\n",
    "    el_list_len = len(el_list)\n",
    "    remove_list = []\n",
    "    for el_pos in range( 0, el_list_len ):\n",
    "        if el_list[el_pos] in Weasel_number_answers:\n",
    "            # last element, or not last element but next element is a not a number\n",
    "            if el_pos==(el_list_len-1) or not floatable(el_list[el_pos+1]):\n",
    "                remove_list.append(el_list[el_pos])\n",
    "\n",
    "    return \"|\".join( [x for x in el_list if x not in remove_list] )\n",
    "\n",
    "\n",
    "# version to act directly on cat.categories array\n",
    "def de_weasel_nums(el_list):\n",
    "\n",
    "    el_list_len = len(el_list)\n",
    "    remove_list = []\n",
    "    for el_pos in range( 0, el_list_len ):\n",
    "        if el_list[el_pos] in Weasel_number_answers:\n",
    "            # last element, or not last element but next element is a not a number\n",
    "            if el_pos==(el_list_len-1) or not floatable(el_list[el_pos+1]):\n",
    "                remove_list.append(el_list[el_pos])\n",
    "\n",
    "    return remove_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s.cat.rename_categories([1,2,3])\n",
    "# EUContactRemainConW8|EUContactRemainLabW8|EUContactRemainLDW8|\n",
    "# EUContactRemainSNPW8|EUContactRemainPCW8|EUContactRemainUKIPW8|\n",
    "# EUContactRemainGreenW8|EUContactRemainOthW8|EUContactRemainNoneW8|\n",
    "# EUContactRemainDKW8|EUContactLeaveConW8|EUContactLeaveLabW8|\n",
    "# EUContactLeaveLDW8|EUContactLeaveSNPW8|EUContactLeavePCW8|\n",
    "# EUContactLeaveUKIPW8|EUContactLeaveGreenW8|EUContactLeaveOthW8|\n",
    "# EUContactLeaveNoneW8|EUContactLeaveDKW8\n",
    "\n",
    "# pattern match \"EUContact*****W8\"\n",
    "# debateOneWatchW8|debateTwoWatchW8\n",
    "\n",
    "# \"1.0|2.0|99.0\" -> \n",
    "\n",
    "# euRefVoteSqueezeW7 \"Will not vote|Yes - Leave|Yes - Remain|No - not decided\"\n",
    "#    -> Stay/remain in the EU|Leave the EU|I would/will not vote|Don't know\n",
    "#    HMM - RENAME AND REORDER!\n",
    "\n",
    "# miieuW7\n",
    "# \"Issue stated|Nothing|Don't know\" -> \"Issue stated|None|Don't know\"\n",
    "# MIIEUW8\n",
    "# \"1.0|Nothing|Don't know\" -> \"Issue stated|None|Don't know\"\n",
    "# partyIdEUW7|partyIdEUW8\n",
    "# \"Mainly leave|Mainly remain|Fairly evenly split|Don't know\" -> \"Mainly remain|Fairly evenly divided|Mainly leave|Don't know\"\n",
    "#    HMM - RENAME AND REORDER!\n",
    "\n",
    "# 1. campaignVisionYesW3|campaignVisionNoW3, govtNatSecuritySuccessW4\n",
    "# Very unsuccessful|Fairly unsuccessful|Neither successful nor unsuccessful|Fairly successful|Very successful|Don't know\n",
    "# Very unsuccessful|Somewhat unsuccessful|Neither successful or unsuccessful|Somewhat successful|Very successful|Don't know\n",
    "\n",
    "# Fairly <-> Somewhat\n",
    "\n",
    "# 2. euroTurnoutW1, scotReferendumTurnoutW1|scotReferendumTurnoutW2|welshTurnoutW7|scotTurnoutW7, turnoutUKGeneralW1|turnoutUKGeneralW2|turnoutUKGeneralW3|turnoutUKGeneralW4|turnoutUKGeneralW5|euRefTurnoutW7|euRefTurnoutW8\n",
    "# Very unlikely that I vote|Fairly unlikely|Neither likely nor unlikely|Fairly likely|Very likely that I vote|Don't know\n",
    "# Very unlikely that I would vote|Fairly unlikely|Neither likely nor unlikely|Fairly likely|Very likely that I would vote|Don't know\n",
    "# There are not local elections in my area\n",
    "    #|Very unlikely that I will vote|Fairly unlikely|Neither likely nor unlikely|Fairly likely|Very likely that I will vote|Don't know\n",
    "# Very unlikely that I will vote|Fairly unlikely|Neither likely nor unlikely|Fairly likely|Very likely that I will vote|Don't know\n",
    "\n",
    "# \"Very unlikely that I vote\", \"Very unlikely that I would vote\" ->  \"Very unlikely that I will vote\" \n",
    "\n",
    "rename_cat_dict = {\"North East|North West\": [ \"No\", \"Yes\" ],\n",
    "                   \"1.0|2.0|99.0\": [\"No\", \"Yes\", \"99.0\"],\n",
    "                   \"Will not vote|Yes - Leave|Yes - Remain|No - not decided\":\n",
    "                       ['I would/will not vote', 'Leave the EU','Stay in the EU', \"Don't know\"], \n",
    "                   \"Stay/remain in the EU|Leave the EU|I would/will not vote|Don't know\":\n",
    "                       ['Stay in the EU','Leave the EU',  'I would/will not vote', \"Don't know\"],   # euRefVote    \n",
    "                   \"Stay/remain in the EU|Leave the EU|Don't know\":\n",
    "                       ['Stay in the EU','Leave the EU', \"Don't know\"],   # profile_eurefvote                    \n",
    "                   \"Issue stated|Nothing|Don't know\":  ['Issue stated', 'None', \"Don't know\"],\n",
    "                   \"1.0|Nothing|Don't know\":           ['Issue stated', 'None', \"Don't know\"],\n",
    "                   \"a|b|C1|C2|d|e|Refused|Unknown\" : ['A', 'B', 'C1', 'C2', 'D', 'E', 'Refused', 'Unknown'],\n",
    "                   \"Mainly leave|Mainly remain|Fairly evenly split|Don't know\":\n",
    "                       ['Mainly leave','Mainly remain', 'Fairly evenly divided', \"Don't know\"],\n",
    "                   \"Very unsuccessful|Somewhat unsuccessful|Neither successful or unsuccessful|Somewhat successful|Very successful|Don't know\":\n",
    "                       ['Very unsuccessful', 'Fairly unsuccessful', 'Neither successful nor unsuccessful',\n",
    "                        'Fairly successful', 'Very successful', \"Don't know\"],\n",
    "                   \"Very unlikely that I vote|Fairly unlikely|Neither likely nor unlikely|Fairly likely|Very likely that I vote|Don't know\":\n",
    "                       ['Very unlikely that I will vote', 'Fairly unlikely', 'Neither likely nor unlikely',\n",
    "                        'Fairly likely', 'Very likely that I will vote', \"Don't know\"],\n",
    "                   \"Very unlikely that I would vote|Fairly unlikely|Neither likely nor unlikely|Fairly likely|Very likely that I would vote|Don't know\":\n",
    "                       ['Very unlikely that I will vote', 'Fairly unlikely', 'Neither likely nor unlikely',\n",
    "                        'Fairly likely', 'Very likely that I will vote', \"Don't know\"],\n",
    "                   \"No, did not vote|Yes, voted|3.0|4.0|5.0|Don't know\":   \n",
    "                       [\"Very unlikely that I will vote\", \"Fairly unlikely\", 'Neither likely nor unlikely',\n",
    "                        \"Fairly likely\", \"Very likely that I will vote\", \"Don't know\"], #londonTurnoutW7\n",
    "                   'No, I do not regard myself as belonging to any particular religion.|Yes - Church of England/Anglican/Episcopal|Yes - Roman Catholic|Yes - Presbyterian/Church of Scotland|Yes - Methodist|Yes - Baptist|Yes - United Reformed Church|Yes - Free Presbyterian|Yes - Brethren|Yes - Judaism|Yes - Hinduism|Yes - Islam|Yes - Sikhism|Yes - Buddhism|Yes - Other|Prefer not to say|Yes Orthodox Christian|Yes - Pentecostal (e.g. Assemblies of God, Elim Pentecostal Church, New Testament Church of God, Redeemed Christian Chur|Yes - Evangelical independent/non-denominational (e.g. FIEC, Pioneer, Vineyard, Newfrontiers)':\n",
    "                       [\"No, I do not regard myself as belonging to any particular religion.\",\"Yes - Church of England/Anglican/Episcopal\",\n",
    "                        \"Yes - Roman Catholic\",\"Yes - Presbyterian/Church of Scotland\",\"Yes - Methodist\",\"Yes - Baptist\",\n",
    "                        \"Yes - United Reformed Church\",\"Yes - Free Presbyterian\",\"Yes - Brethren\",\"Yes - Judaism\",\"Yes - Hinduism\",\n",
    "                        \"Yes - Islam\",\"Yes - Sikhism\",\"Yes - Buddhism\",\"Yes - Other\",\"Prefer not to say\",\"Yes - Orthodox Christian\",\n",
    "                        \"Yes - Pentecostal\",\"Yes - Evangelical /independent/non-denominational\"], #xprofile_religionW10\n",
    "                   'No, I do not regard myself as belonging to any particular religion.|Yes - Church of England/Anglican/Episcopal|Yes - Roman Catholic|Yes - Presbyterian/Church of Scotland|Yes - Methodist|Yes - Baptist|Yes - United Reformed Church|Yes - Free Presbyterian|Yes - Brethren|Yes - Judaism|Yes - Hinduism|Yes - Islam|Yes - Sikhism|Yes - Buddhism|Yes - Other|Prefer not to say|Yes - Orthodox Christian|Yes - Pentecostal (e.g. Assemblies of God, Elim Pentecostal Church, New Testament Church of God, Redeemed Christian Chur|Yes - Evangelical - independent/non-denominational (e.g. FIEC, Pioneer, Vineyard, Newfrontiers)':\n",
    "                       [\"No, I do not regard myself as belonging to any particular religion.\",\"Yes - Church of England/Anglican/Episcopal\",\n",
    "                        \"Yes - Roman Catholic\",\"Yes - Presbyterian/Church of Scotland\",\"Yes - Methodist\",\"Yes - Baptist\",\n",
    "                        \"Yes - United Reformed Church\",\"Yes - Free Presbyterian\",\"Yes - Brethren\",\"Yes - Judaism\",\"Yes - Hinduism\",\n",
    "                        \"Yes - Islam\",\"Yes - Sikhism\",\"Yes - Buddhism\",\"Yes - Other\",\"Prefer not to say\",\"Yes - Orthodox Christian\",\n",
    "                        \"Yes - Pentecostal\",\"Yes - Evangelical /independent/non-denominational\"], #xprofile_religionW10                   \n",
    "                   'Own - outright|Own - with a mortgage|Own (part-own) - through shared ownership scheme (i.e. pay part mortgage, part rent)|Rent - from a private landlord|Rent - from my local authority|Rent - from a housing association|Neither - I live with my parents, family or friends but pay some rent to them|Neither - I live rent-free with my parents, family or friends|Other|9999':\n",
    "                       [ 'Own outright',\n",
    "                         'Own with a mortgage',\n",
    "                         'Own (part-own) through shared ownership scheme (i.e. pay part mortgage, part rent)',\n",
    "                         'Rent from a private landlord',\n",
    "                         'Rent from my local authority',\n",
    "                         'Rent from a housing association',\n",
    "                         'Neither I live with my parents, family or friends but pay some rent to them',\n",
    "                         'Neither I live rent-free with my parents, family or friends',\n",
    "                         'Other',\n",
    "                         '9999'], #profile_house_tenureW11|profile_house_tenureW12|profile_house_tenureW13\n",
    "                   \"I voted 'No' (Scotland should not be an independent country)|I voted 'Yes' (Scotland should be an independent country)|111.0|Don't know\":\n",
    "                       [\"No\",\"Yes\",\"Did not vote\",\"Don't know\"], # referendumrecall\n",
    "                   \"Voted Yes|Voted No|Did not vote|Can't remember\":\n",
    "                       [\"Yes\",\"No\",\"Did not vote\",\"Don't know\"], # scotRefVoteW4_\n",
    "                   \"No|Yes|3.0|Don't know\":\n",
    "                       [\"No\",\"Yes\",\"Did not vote\",\"Don't know\"], # regretsIHaveAFewEUW10|regretsIHaveAFewEUW11   \n",
    "                   \"No|Yes|3|Don't know\":\n",
    "                       [\"No\",\"Yes\",\"Did not vote\",\"Don't know\"], # regretsIHaveAFewEU W11_only|regretsIHaveAFew W10_only \n",
    "                   \"Professional or higher technical work - work that requires at least degree-level qualifications (e.g. doctor, accountant|Manager or Senior Administrator (e.g. company director, finance manager, personnel manager, senior sales manager, senior|Clerical (e.g. clerk, secretary)|Sales or Services (e.g. commercial traveller, shop assistant, nursery nurse, care assistant, paramedic)|Foreman or Supervisor of Other Workers (e.g building site foreman, supervisor of cleaning workers)|Skilled Manual Work (e.g. plumber, electrician, fitter)|Semi-Skilled or Unskilled Manual Work (e.g. machine operator, assembler, postman, waitress, cleaner, labourer, driver, b|Other|Have never worked\":\n",
    "                       ['Professional or higher technical work / higher managerial - work that requires at least degree-level qualifications (e.g',\n",
    "                        'Manager or Senior Administrator / intermediate managerial / professional (e.g. company director, finance manager, person',\n",
    "                        'Clerical/junior managerial/professional/administrator (e.g. office worker, student doctor, sales person, clerk, secretar',\n",
    "                        'Sales or Services (e.g. commercial traveller, shop assistant, nursery nurse, care assistant, paramedic)',\n",
    "                        'Foreman or Supervisor of Other Workers (e.g. building site foreman, supervisor of cleaning workers)',\n",
    "                        'Skilled Manual Work (e.g. plumber, electrician, fitter)',\n",
    "                        'Semi-Skilled or Unskilled Manual Work (e.g. machine operator, assembler, postman, waitress, cleaner, labourer, driver, b',\n",
    "                        'Other',\n",
    "                        'Have never worked'], # work_type -> profile_work_typeW7\n",
    "                   \"No formal qualifications|Youth training certificate/skillseekers|Recognised trade apprenticeship completed|Clerical and commercial|City & Guilds certificate|City & Guilds certificate - advanced|onc|CSE grades 2-5|CSE grade 1, GCE O level, GCSE, School Certificate|Scottish Ordinary/ Lower Certificate|GCE A level or Higher Certificate|Scottish Higher Certificate|Nursing qualification (eg SEN, SRN, SCM, RGN)|Teaching qualification (not degree)|University diploma|University or CNAA first degree (eg BA, B.Sc, B.Ed)|University or CNAA higher degree (eg M.Sc, Ph.D)|Other technical, professional or higher qualification|Don't know|Prefer not to say\":\n",
    "                       ['No formal qualifications','Youth training certificate/skillseekers','Recognised trade apprenticeship completed',\n",
    "                        'Clerical and commercial','City and Guild certificate','City and Guild certificate - advanced','onc','CSE grades 2-5',\n",
    "                        'CSE grade 1, GCE O level, GCSE, School Certificate','Scottish Ordinary/ Lower Certificate','GCE A level or Higher Certificate',\n",
    "                        'Scottish Higher Certificate','Nursing qualification (eg SEN, SRN, SCM, RGN)','Teaching qualification (not degree)',\n",
    "                        'University diploma','University or CNAA first degree (eg BA, B.Sc, B.Ed)','University or CNAA higher degree (eg M.Sc, Ph.D)',\n",
    "                        'Other technical, professional or higher qualification',\"Don't know\",'Prefer not to say'], # W6_comb: qeducationW6\n",
    "                   \"Strongly disapprove|Disapprove|Don't know\":\n",
    "                       [\"Approve\",\"Disapprove\",\"Don't know\"], # approveEUW2 # W7_comb, W10_comb, W13_comb, W8_comb, W9_comb\n",
    "                   '1 to 24 employees|25 to 499 employees|500 or more employees|':\n",
    "                       ['1 to 24 employees','25 to 499 employees','500 or more employees',\"Don't know\"], #fatherNumEmployees,motherNumEmployees #W6_comb,W5_comb,W5_only,W3_comb\n",
    "                   \"Yes, voted|No, did not vote|Don't know\":\n",
    "                       ['Yes',\"No\",\"Don't know\"],\n",
    "                   \"No, did not vote|Yes, voted|Don't know\":\n",
    "                       ['No','Yes',\"Don't know\"],\n",
    "                   \"No, did not vote|Yes, voted|2.0\":\n",
    "                       ['No','Yes',\"Don't know\"],\n",
    "                   \"Strongly disagree|Disagree|Neither nor disagree|Agree|Strongly agree|Don't know\":\n",
    "                       [\"Strongly disagree\",\"Disagree\",\"Neither agree nor disagree\",\"Agree\",\"Strongly agree\",\"Don't know\"],# euFinancialHelpW2 W3-6_comb\n",
    "                   \"I am very unsure what will happen|I am quite unsure what will happen|I am quite sure what will happen|I am very sure what will happen|Don't know\":\n",
    "                       [\"I am very unsure what would happen\",\"I am quite unsure what would happen\",\"I am quite sure what would happen\",\"I am very sure what would happen\",\"Don't know\"], # certaintyScotUnionW3 W3-5_comb\n",
    "                   \"0.0|1.0|2.0|3.0|4.0|5.0|6.0|7.0|997.0\":\n",
    "                       [\"0 days\",\"1 day\",\"2 days\",\"3 days\",\"4 days\",\"5 days\",\"6 days\",\"7 days\",\"Don't know\"], # discussPolDaysW5\tW5_comb\n",
    "                   \"A major transfer of powers from Westminster to the Scottish Parliament (\\\"devo-max\\\")|Some powers will be transferred but well short of \\\"devo-max\\\"|No change to the relationship between Westminster and the Scottish Parliament\":\n",
    "                       [\"A major transfer of powers from Westminster to the Scottish Parliament (devo-max)\",\"Some powers will be transferred but well short of devo-max\",\"No change to the relationship between Westminster and the Scottish Parliament\"], # expectationManipCheckW1 # W13,10,9,8,7 vs W6-3_comb\n",
    "                   \"No, I did not vote|Yes, I voted|There wasn't a local election in my area|Don't know\":\n",
    "                       [\"No, did not vote\",\"Yes, voted\",\"There wasn't a local election in my area\",\"Don't know\"], # localTurnoutRetroW2 W3-6_comb\n",
    "                   \"Focuses mainly on criticising other parties|2.0|3.0|4.0|Focuses mainly on putting forward their own policies and personalities|Don't know\":\n",
    "                       [\"1 - Focused mainly on criticising other parties\",\"2.0\",\"3.0\",\"4.0\",\"5 - Focused mainly on putting forward their own policies and personalities\",\"Don't know\"], # <party>ToneW5 # W5-6_comb, W5_only\n",
    "                   \"Environmental Policy|Defence|Education|Pensions\":\n",
    "                       [\"No, I think they *will not* vote\",\"Yes, I think they *will* vote\",\"They are not eligible to vote\",\"Don't know\"], # discussantturnoutName1-3W4 # W4-5_comb\n",
    "                   \"Employers in large organisations and higher managerial|Higher professional occupations|Lower professional and managerial and higher supervisory|Intermediate occupations|Employers in small organisations and own account workers|Lower suprivsory and technical occupations|Semi-routine occupations|Routine occupations\":\n",
    "                       ['Employers in large organisations and higher managerial', 'Higher professional occupations',\n",
    "                        'Lower professional and managerial and higher supervisory', 'Intermediate occupations',\n",
    "                        'Employers in small organisations and own account workers', 'Lower supervisory and technical occupations',\n",
    "                        'Semi-routine occupations', 'Routine occupations'], # ns_sec_analytic\t W5_only, W3-6_comb                   \n",
    "                   \"Employers in large organisations and higher managerial|Higher professional occupations|Lower professional and managerail and higher supervisory|Intermediate occupations|Employers in small organisations and own account workers|Lower suprivsory and technical occupations|Semi-routine occupations|Routine occupations\":\n",
    "                       ['Employers in large organisations and higher managerial', 'Higher professional occupations',\n",
    "                        'Lower professional and managerial and higher supervisory', 'Intermediate occupations',\n",
    "                        'Employers in small organisations and own account workers', 'Lower supervisory and technical occupations',\n",
    "                        'Semi-routine occupations', 'Routine occupations'], # ns_sec_analytic\t W5_only, W3-6_comb    # v slight typo!\n",
    "                   \"A major transfer of powers from Westminster to the Scottish Parliament (\\\"devo-max\\\")|Some powers will be transferred but well short of \\\"devo-max\\\"|No change to the relationship between Westminster and the Scottish Parliament|Don't know\":\n",
    "                       ['A major transfer of powers from Westminster to the Scottish Parliament (devo-max)',\n",
    "                        'Some powers will be transferred but well short of devo-max',\n",
    "                        'No change to the relationship between Westminster and the Scottish Parliament',\"Don't know\"], # expectationManipCheckW1 W3-6_comb\n",
    "                   \"Employers in large establishments|Higher managerial and administrative occupations|L3.1 'Traditional' employees|L3.2 'New' employees|L3.3 'Traditional' self-employed|L3.4 'New' self-employed|L4.1 'Traditional' employees|L4.2 'New' employees|L4.3 'Traditional' self-employed|L4.4 'New' self-employed|Lower managerial and administrative occupations|Higher supervisory occupations|L7.1 Intermediate clerical and administrative occupations|L7.2 Intermediate sales and service occupations|L7.3 Intermediate technical and auxiliary occupations|L7.4 Intermediate engineering occupations|L8.1 Employers in small establishments in industry, commerce, services etc.|L8.2 Employers in small establishments in agriculture|L9.1 Own account workers (non-professional)|L9.2 Own account workers (agriculture)|Lower supervisory occupations|L11.1 Lower technical craft occupations|L11.2 Lower technical process operative occupations|L12.1 Semi-routine sales occupations|L12.2 Semi-routine service occupations|L12.3 Semi-routine technical occupations|L12.4 Semi-routine operative occupations|L12.5 Semi-routine agricultural occupations|L12.6 Semi-routine clerical occupations|L12.7 Semi routine childcare occupations|L13.1 Routine sales and service occupations|L13.2 Routine production occupations|L13.3 Routine technical occupations|L13.4 Routine operative occupations|L13.5 Routine agricultural occupations\":\n",
    "                       ['Employers in large establishments', 'Higher managerial and administrative occupations',\n",
    "                        'L3.1 Traditional employees', 'L3.2 New employees', 'L3.3 Traditional self-employed',\n",
    "                        'L3.4 New self-employed', 'L4.1 Traditional employees', 'L4.2 New employees',\n",
    "                        'L4.3 Traditional self-employed', 'L4.4 New self-employed', 'Lower managerial and administrative occupations',\n",
    "                        'Higher supervisory occupations', 'L7.1 Intermediate clerical and administrative occupations',\n",
    "                        'L7.2 Intermediate sales and service occupations', 'L7.3 Intermediate technical and auxiliary occupations',\n",
    "                        'L7.4 Intermediate engineering occupations', 'L8.1 Employers in small establishments in industry, commerce, services etc.',\n",
    "                        'L8.2 Employers in small establishments in agriculture', 'L9.1 Own account workers (non-professional)',\n",
    "                        'L9.2 Own account workers (agriculture)', 'Lower supervisory occupations', 'L11.1 Lower technical craft occupations',\n",
    "                        'L11.2 Lower technical process operative occupations', 'L12.1 Semi-routine sales occupations',\n",
    "                        'L12.2 Semi-routine service occupations', 'L12.3 Semi-routine technical occupations', 'L12.4 Semi-routine operative occupations',\n",
    "                        'L12.5 Semi-routine agricultural occupations', 'L12.6 Semi-routine clerical occupations', 'L12.7 Semi routine childcare occupations',\n",
    "                        'L13.1 Routine sales and service occupations', 'L13.2 Routine production occupations', 'L13.3 Routine technical occupations',\n",
    "                        'L13.4 Routine operative occupations', 'L13.5 Routine agricultural occupations'],\n",
    "                   \"Employers in large establishments|Higher managerial and administrative occupations|L3.1 ?Traditional? employees|L3.2 ?New? employees|L3.3 ?Traditional? self-employed|L3.4 ?New? self-employed|L4.1 ?Traditional? employees|L4.2 ?New? employees|L4.3 ?Traditional? self-employed|L4.4 ?New? self-employed|Lower managerial and administrative occupations|Higher supervisory occupations|L7.1 Intermediate clerical and administrative occupations|L7.2 Intermediate sales and service occupations|L7.3 Intermediate technical and auxiliary occupations|L7.4 Intermediate engineering occupations|L8.1 Employers in small establishments in industry, commerce, services etc.|L8.2 Employers in small establishments in agriculture|L9.1 Own account workers (non-professional)|L9.2 Own account workers (agriculture)|Lower supervisory occupations|L11.1 Lower technical craft occupations|L11.2 Lower technical process operative occupations|L12.1 Semi-routine sales occupations|L12.2 Semi-routine service occupations|L12.3 Semi-routine technical occupations|L12.4 Semi-routine operative occupations|L12.5 Semi-routine agricultural occupations|L12.6 Semi-routine clerical occupations|L12.7 Semi routine childcare occupations|L13.1 Routine sales and service occupations|L13.2 Routine production occupations|L13.3 Routine technical occupations|L13.4 Routine operative occupations|L13.5 Routine agricultural occupations\":\n",
    "                       ['Employers in large establishments', 'Higher managerial and administrative occupations',\n",
    "                        'L3.1 Traditional employees', 'L3.2 New employees', 'L3.3 Traditional self-employed',\n",
    "                        'L3.4 New self-employed', 'L4.1 Traditional employees', 'L4.2 New employees',\n",
    "                        'L4.3 Traditional self-employed', 'L4.4 New self-employed', 'Lower managerial and administrative occupations',\n",
    "                        'Higher supervisory occupations', 'L7.1 Intermediate clerical and administrative occupations',\n",
    "                        'L7.2 Intermediate sales and service occupations', 'L7.3 Intermediate technical and auxiliary occupations',\n",
    "                        'L7.4 Intermediate engineering occupations', 'L8.1 Employers in small establishments in industry, commerce, services etc.',\n",
    "                        'L8.2 Employers in small establishments in agriculture', 'L9.1 Own account workers (non-professional)',\n",
    "                        'L9.2 Own account workers (agriculture)', 'Lower supervisory occupations', 'L11.1 Lower technical craft occupations',\n",
    "                        'L11.2 Lower technical process operative occupations', 'L12.1 Semi-routine sales occupations',\n",
    "                        'L12.2 Semi-routine service occupations', 'L12.3 Semi-routine technical occupations', 'L12.4 Semi-routine operative occupations',\n",
    "                        'L12.5 Semi-routine agricultural occupations', 'L12.6 Semi-routine clerical occupations', 'L12.7 Semi routine childcare occupations',\n",
    "                        'L13.1 Routine sales and service occupations', 'L13.2 Routine production occupations', 'L13.3 Routine technical occupations',\n",
    "                        'L13.4 Routine operative occupations', 'L13.5 Routine agricultural occupations'],\n",
    "                   \"1|2\":\n",
    "                       [\"No\",\"Yes\"], # tryReduceImmigDKW4, achieveReduceImmigUKIPW4, achieveReduceImmigGrnW4, achieveReduceImmigDKW4, tryReduceInequalityDKW4, successReduceInequalityDKW4 # W4-5_comb # sharedContentOnline_1-5W4 W5_comb # voteMethodEurope_dkW2, discussantsAskedYouToVote_DKW2 ,discussantsAccompaniedVote_dkW2, referendumContact_dkW2 # W3_comb\n",
    "                   \"1.0|2.0\":\n",
    "                       [\"No\",\"Yes\"], # tryReduceImmigDKW4, achieveReduceImmigUKIPW4, achieveReduceImmigGrnW4, achieveReduceImmigDKW4, tryReduceInequalityDKW4, successReduceInequalityDKW4 # W4-5_comb # sharedContentOnline_1-5W4 W5_comb # voteMethodEurope_dkW2, discussantsAskedYouToVote_DKW2 ,discussantsAccompaniedVote_dkW2, referendumContact_dkW2 # W3_comb\n",
    "                   \"Should definitely be illegal|Should probably be illegal|Should probably be legal|Should definitely be legal|5.0\":\n",
    "                       [\"Should definitely be illegal\",\"Should probably be illegal\",\"Should probably be legal\",\"Should definitely be legal\",\"Don't know\"], # zeroHourContractW6\n",
    "                  }\n",
    "\n",
    "\n",
    "rename_variable_dict = pd.DataFrame.from_dict( {k : \"|\".join(v) for k, v in rename_cat_dict.items()} , orient='index' ).reset_index()\n",
    "rename_variable_dict.columns = [\"original_cat_list\",\"renameed_cat_list\"]\n",
    "rename_variable_dict.to_csv( BES_small_data_files + \"rename_variable_dict.csv\" )\n",
    "\n",
    "def re_name(ques):\n",
    "    if ques in rename_cat_dict.keys():\n",
    "        return \"|\".join( rename_cat_dict[ques] )\n",
    "    else:\n",
    "        return ques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## COLUMNS THAT EITHER LACK ALL DATA OR HAVE ACTUAL ERRORS\n",
    "# check back on these periodically - one assumes they will get fixed!\n",
    "# maybe tell them about them so that they can?\n",
    "\n",
    "# {'changeIssue1W9', 'conLeaderLikeW9'}\n",
    "# these variables appear to have disappeared! Fixed in an updated version?\n",
    "\n",
    "ignore_list = ['whichPartiesHelped_99W6',\n",
    "               'partyContactGrnW1',\n",
    "               'partyContactGrnW2',\n",
    "               'partyContactGrnW3',\n",
    "               'reasonNotRegistered_noneW2',               \n",
    "               'reasonNotRegistered_noneW3',\n",
    "               'reasonNotRegistered_noneW4',\n",
    "               'reasonNotRegistered_noneW6',\n",
    "               'reasonNotRegistered_noneW7',\n",
    "               'reasonNotRegistered_noneW8',\n",
    "               'reasonNotRegistered_none',\n",
    "               'partyContactSNPW1',\n",
    "               'partyContactSNPW2',\n",
    "               \"locusControlW9\",\n",
    "               \"generalElecCertaintyW1\", # wave 10 forwards\n",
    "               \"generalElecCertaintyW2\",\n",
    "               \"generalElecCertaintyW3\",\n",
    "               \"londonMayorVoteW7\",\n",
    "               \"fatherNumEmployeesW4\",\n",
    "               \"motherNumEmployeesW4\",\n",
    "               \"profile_pcon_2010_newW3\", # W3_comb: this is parl. constit. ... but by number!\n",
    "               \"euroElectionVoteYoungW2\", # W3_comb: all NaNs!\n",
    "               \"profile_GOR_pdlW4\", # W4_comb: misnamed selection, probably fixable \n",
    "               \"participation_111W5\", ### -->\n",
    "               \"sharedContentOnline_111W5\",\n",
    "               \"sharedContentOnline_99W5\", ### <-- W5_comb \"Got a lot worse|Got a little worse\" doesn't look right (indicator vars?)\n",
    "               \"csplScotRefW3\", ### W5_comb: \"North East\" - just broken!\n",
    "              ]\n",
    "\n",
    "#- approveEUW2 'Strongly disapprove|Disapprove|Don't know' - should be \"approve|disapprove|don't know\"??? NOT SURE (distribution weird)\n",
    "#- whichPartiesHelped_99W6 - answer set = [\"No\"]\n",
    "#- partyContactGrnW1 ... reasonNotRegistered_noneW8 answer set = [\"No\", \"Don't know\"]\n",
    "# -partyContactSNPW1, partyContactSNPW2 - answer set = [\"Don't know\"]\n",
    "# -changeIssue1W9|conLeaderLikeW9|locusControlW9 - answer set = [\"No formal qualifications\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define 'prune' function to prune wave indicators and return question stubs\n",
    "## ie. \"ptvConW1|ptvLabW1\" -> \"ptvCon|ptvLab\"\n",
    "\n",
    "def prune(x):\n",
    "    \n",
    "    y= []\n",
    "    for el in x.split(\"|\"):\n",
    "        match_attempt = re.match('(\\w*?)_?(W[0-9]+)+' , el )   \n",
    "        if match_attempt:\n",
    "            el = match_attempt.groups()[0]\n",
    "        y.append(el)\n",
    "    # should we ditch identical repeats?\n",
    "    # return \"|\".join(set(y)) NEEDS TO BE TESTED\n",
    "    return \"|\".join(y)\n",
    "\n",
    "               \n",
    "def prune2(x):\n",
    "    \n",
    "    y= []\n",
    "    for el in x.split(\"|\"):\n",
    "        # fgdfhfghg_5, fgdfhfghg_4, fgdfhfghg_3 -> fgdfhfghg\n",
    "        # problem - indicator variables fgdfhfghg_99, fgdfhfghg_111 really are different!\n",
    "        # solution - leave them distinct\n",
    "        indicator_variable = re.match('(\\w*?)_?(99|111)' , el )       \n",
    "        match_attempt = re.match('(\\w*?)_?[0-9]+' , el )   \n",
    "        if (not indicator_variable) and (match_attempt):\n",
    "            el = match_attempt.groups()[0]\n",
    "        y.append(el)\n",
    "    # should we ditch identical repeats?\n",
    "    # return \"|\".join(set(y)) NEEDS TO BE TESTED\n",
    "    return \"|\".join(y)\n",
    "\n",
    "\n",
    "def hardcoded_fix(col,cat_list):\n",
    "    \n",
    "    var_type.loc[ col , \"dtype\" ]           = BES_Panel[col].dtype.name\n",
    "    if (var_type.loc[ col , \"dtype\" ] == 'category'):\n",
    "        var_type.loc[ col , \"cat_all_strings\" ] = np.all([isinstance(x,str) for x in BES_Panel[ col ].cat.categories])\n",
    "        \n",
    "    BES_Panel[col] = \\\n",
    "        BES_Panel[col].astype(\"category\").cat.rename_categories( cat_list.split(\"|\") )\n",
    "        \n",
    "    var_type.loc[ col , \"dataset_specific_hardcoded_fix\" ] = \"|\".join( BES_Panel[col].cat.categories.values )\n",
    "    \n",
    "# \"Â–\" -> \"-\"\n",
    "# \"Â£\" -> \"£\"\n",
    "\n",
    "# \" â€“ \" -> \" \"\n",
    "# \" Â‘\" -> \" \"\n",
    "# \"Â’ \" -> \" \"\n",
    "\n",
    "# \"Â‘\" -> \"'\"\n",
    "# \"Â’\" -> \"'\"\n",
    "# \"Â€Â™\" -> \"'\"\n",
    "# \"â??\" -> \"'\"\n",
    "# \"â€™\" -> \"'\"    \n",
    "\n",
    "# detect any matching pattern of weird Â stuff in cat1|cat2|cat3... string\n",
    "# return the fixed version of string if present\n",
    "# return None if not\n",
    "def fix_a_hat_chars(cat_string):\n",
    "    cat_array = cat_string.split(\"|\")\n",
    "    a_hat_present = False\n",
    "    for el_no in range( 0, len(cat_array) ):\n",
    "        el = cat_array[el_no]\n",
    "        el = re.sub( \"SiÃƒÂ¢n C. Jame|SiÃ¢n C. James|SiÃ¢n C. Jame|Siân C. James\", \"Sian C. James\", el)\n",
    "        el = re.sub( \"ThÃ©rÃ¨se  Coff|Thérèse  Coffey\", \"Therese  Coffey\", el)\n",
    "        el = re.sub( \"RA©union|RÃ©union|RAÂ©union|RÃƒÂ©union\", \"Reunion\", el)\n",
    "        el = re.sub( \"\\xa0Lower supervisory occupations\", \"Lower supervisory occupations\", el)\n",
    "        el = re.sub( \"Don‘t know|Don?t know|Dona??t know|Dona€™t know|Donâ€™t know|Don’t know|Don‘t know|Don\\x91t know|Don\\x92t know|Dona\\x80\\x99t know|Do\\x92t know\",\"Don't know\", el  )\n",
    "        el = re.sub( \"Â–|\\x96|–\", \"-\", el )\n",
    "        el = re.sub( \"Â£|\\xc2£\", \"£\", el )\n",
    "        el = re.sub( \"\\xa0|\\sâ€“\\s|\\s\\xe2\\x80\\x93\\s|\\sÂ‘|Â’\\s\" , \" \", el )\n",
    "        el = re.sub( \"Â‘|Â’|Â€Â™|â\\?\\?|\\x80\\x99|â€™|\\xe2\\x80\\x99|â|â\\x80\\x99|\\?\\?|\\x92|‘|\\x91|’\", \"'\", el )\n",
    "        el = re.sub( \"'\\u2013'\", \"-\", el )\n",
    "        \n",
    "        \n",
    "        \n",
    "        if el != cat_array[el_no]:\n",
    "            a_hat_present = True\n",
    "            cat_array[el_no] = el\n",
    "            \n",
    "    if a_hat_present:\n",
    "        return cat_array\n",
    "    else:\n",
    "        return None\n",
    "        \n",
    "## typos - more directly useful for the BES!\n",
    "# typos = set(['Do\\x92t know', 'Dont know', 'Donât know', 'Don??t know','DonaÂ€Â™t know'])# ,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_var_list( variable_categories ):\n",
    "    # load question_categories_correct (it could have been updated)\n",
    "    # input: \n",
    "    # output:\n",
    "    # var_cat_dict_pruned, var_cat_dict_pruned_2\n",
    "\n",
    "    # flipping list\n",
    "    var_cat_dict = dict()\n",
    "    # range defined by types that exist in question_categories_correct.csv\n",
    "    type_range = set(variable_categories[\"type\"].values)\n",
    "\n",
    "    for typ in type_range:\n",
    "\n",
    "        e = variable_categories[variable_categories.type==typ][\"column_name\"].values\n",
    "        var_cat_dict[typ] = [item for sublist in [i.split(\"|\") for i in e] for item in sublist]\n",
    "        var_cat_dict[typ] = [item for item in var_cat_dict[typ] if item not in ignore_list]\n",
    "\n",
    "    # dictionary comprehension to prune column-names to wave non-specific stubs\n",
    "    # list(set()) gets rid of repetitions\n",
    "    var_cat_dict_pruned   = {k: list(set([prune(x)  for x in v])) for k, v in var_cat_dict.items()}\n",
    "    var_cat_dict_pruned_2 = {k: list(set([prune2(x) for x in v])) for k, v in var_cat_dict_pruned.items()}\n",
    "    \n",
    "    return ( var_cat_dict_pruned , var_cat_dict_pruned_2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def careful_isnan(x):\n",
    "    return ( (not isinstance(x,str)) and np.isnan(x) )\n",
    "\n",
    "def careful_replace( col,replace_dict ):\n",
    "    var_type.loc[col,\"dtype\"] = BES_Panel[col].dtype.name\n",
    "    if (var_type.loc[ col , \"dtype\" ] == 'category'):\n",
    "        var_type.loc[ col , \"cat_all_strings\" ] = np.all([isinstance(x,str) for x in BES_Panel[ col ].cat.categories])     \n",
    "    \n",
    "    BES_Panel[col] = BES_Panel[col]\\\n",
    "        .apply(lambda x: x if careful_isnan(x) else replace_dict[x] )\\\n",
    "        .astype('category').cat.set_categories( replace_dict.values() , ordered = True)\n",
    "        \n",
    "    var_type.loc[ col , \"dataset_specific_hardcoded_fix\" ] = \"|\".join( BES_Panel[col].cat.categories.values )\n",
    "\n",
    "def careful_replace_and_set_cats( col, replace_dict, final_cats ):\n",
    "    var_type.loc[col,\"dtype\"] = BES_Panel[col].dtype.name\n",
    "    if (var_type.loc[ col , \"dtype\" ] == 'category'):\n",
    "        var_type.loc[ col , \"cat_all_strings\" ] = np.all([isinstance(x,str) for x in BES_Panel[ col ].cat.categories])     \n",
    "    \n",
    "    BES_Panel[col] = BES_Panel[col]\\\n",
    "        .apply(lambda x: x if x not in replace_dict.keys() else replace_dict[x] )\\\n",
    "        .astype('category').cat.set_categories( final_cats , ordered = True)\n",
    "        \n",
    "    var_type.loc[ col , \"dataset_specific_hardcoded_fix\" ] = \"|\".join( BES_Panel[col].cat.categories.values )    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset_name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ( \u001b[43mdataset_name\u001b[49m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW25_comb\u001b[39m\u001b[38;5;124m\"\u001b[39m] ):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m!!!!!!!!!!!!!!!!!!!!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m     col \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mriskScaleW8\u001b[39m\u001b[38;5;124m'\u001b[39m \n",
      "\u001b[1;31mNameError\u001b[0m: name 'dataset_name' is not defined"
     ]
    }
   ],
   "source": [
    "if ( dataset_name in [\"W25_comb\"] ):\n",
    "    print(\"!!!!!!!!!!!!!!!!!!!!\")\n",
    "    col = 'riskScaleW8' \n",
    "    replace_dict = {'Most risk averse':0, '2':1,'3':2 ,'4':3,\n",
    "                    '5':4,'6':5,'7':6,'8':7,'9':8,'10':9,'11':10,'12':11,\n",
    "                    '13':12,'14':13,'15':14, 'Most risk inclined':15}\n",
    "\n",
    "BES_Panel[col].replace(replace_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hard_coded_fixes( dataset_name ):\n",
    "\n",
    "    ## dataset specific issues\n",
    "    # (i.e. probably what I should have done all along!)\n",
    "    \n",
    "    col = \"age\"\n",
    "    if dataset_name==\"W22_only\":\n",
    "        BES_Panel[col]= BES_Panel[col].astype('category')\n",
    "        \n",
    "    if ( dataset_name in [\"W25_comb\"] ):\n",
    "        print(\"!!!!!!!!!!!!!!!!!!!!\")\n",
    "        col = 'riskScaleW8' \n",
    "        replace_dict = {'Most risk averse':0, '2':1,'3':2 ,'4':3,\n",
    "                        '5':4,'6':5,'7':6,'8':7,'9':8,'10':9,'11':10,'12':11,\n",
    "                        '13':12,'14':13,'15':14, 'Most risk inclined':15}\n",
    "    \n",
    "        BES_Panel[col] = BES_Panel[col].replace(replace_dict)\n",
    "        col = 'riskScaleW20' \n",
    "        replace_dict = {'Most risk averse':0, '2':1,'3':2 ,'4':3,\n",
    "                        '5':4,'6':5,'7':6,'8':7,'9':8,'10':9,'11':10,'12':11,\n",
    "                        '13':12,'14':13,'15':14, 'Most risk inclined':15}\n",
    "    \n",
    "        BES_Panel[col] = BES_Panel[col].replace(replace_dict)        \n",
    "\n",
    "    if ( dataset_name in [\"W23_only\"] ):\n",
    "        col = 'preschoolKidsInHouseW21_'\n",
    "        replace = {0.0:\"No\",1.0:\"Yes\",9.0:\"Don't know\"}\n",
    "        final_cats = [\"No\", \"Yes\", \"Don't know\"]\n",
    "        careful_replace_and_set_cats( col, replace, final_cats )        \n",
    "        BES_Panel[col] = BES_Panel[col].astype('category')\n",
    "\n",
    "    if ( dataset_name in [\"W23_only\"] ):\n",
    "        col = 'schoolKidsInHouseW21_'\n",
    "        replace = {0.0:\"No\",1.0:\"Yes\",9.0:\"Don't know\"}\n",
    "        final_cats = [\"No\", \"Yes\", \"Don't know\"]\n",
    "        careful_replace_and_set_cats( col, replace, final_cats )        \n",
    "        BES_Panel[col] = BES_Panel[col].astype('category')        \n",
    "        \n",
    "    if ( dataset_name in [\"W23_only\"] ):\n",
    "        col = 'sickElderlyInHouseW21_'\n",
    "        replace = {0.0:\"No\",1.0:\"Yes\",9.0:\"Don't know\"}\n",
    "        final_cats = [\"No\", \"Yes\", \"Don't know\"]\n",
    "        careful_replace_and_set_cats( col, replace, final_cats )        \n",
    "        BES_Panel[col] = BES_Panel[col].astype('category')           \n",
    "        \n",
    "    if ( dataset_name in [\"W23_only\"] ):\n",
    "        col = 'noDependentsInHouseW21_'\n",
    "        replace = {0.0:\"No\",1.0:\"Yes\",9.0:\"Don't know\"}\n",
    "        final_cats = [\"No\",  \"Yes\", \"Don't know\"]\n",
    "        careful_replace_and_set_cats( col, replace, final_cats )        \n",
    "        BES_Panel[col] = BES_Panel[col].astype('category')           \n",
    "        \n",
    "    if ( dataset_name in [\"W23_only\"] ):\n",
    "        col = 'privPrimSchlW1_'\n",
    "        replace = {0.0:\"No\",1.0:\"Yes\",9.0:\"Don't know\"}\n",
    "        final_cats = [\"No\",  \"Yes\", \"Don't know\"]\n",
    "        careful_replace_and_set_cats( col, replace, final_cats )        \n",
    "        BES_Panel[col] = BES_Panel[col].astype('category')           \n",
    "        \n",
    "    if ( dataset_name in [\"W23_only\"] ):\n",
    "        col = 'privScndSchlW1_'\n",
    "        replace = {0.0:\"No\",1.0:\"Yes\",9.0:\"Don't know\"}\n",
    "        final_cats = [\"No\",  \"Yes\", \"Don't know\"]\n",
    "        careful_replace_and_set_cats( col, replace, final_cats )        \n",
    "        BES_Panel[col] = BES_Panel[col].astype('category')         \n",
    "        \n",
    "    if ( dataset_name in [\"W23_only\"] ):\n",
    "        col = 'privScndSchlW1_'\n",
    "        replace = {0.0:\"No\",1.0:\"Yes\",9.0:\"Don't know\"}\n",
    "        final_cats = [\"No\",  \"Yes\", \"Don't know\"]\n",
    "        careful_replace_and_set_cats( col, replace, final_cats )        \n",
    "        BES_Panel[col] = BES_Panel[col].astype('category')   \n",
    "        \n",
    "    if ( dataset_name in [\"W23_only\"] ):\n",
    "        col = 'privScndSchlW1_'\n",
    "        replace = {0.0:\"No\",1.0:\"Yes\",9.0:\"Don't know\"}\n",
    "        final_cats = [\"No\",  \"Yes\", \"Don't know\"]\n",
    "        careful_replace_and_set_cats( col, replace, final_cats )        \n",
    "        BES_Panel[col] = BES_Panel[col].astype('category')   \n",
    "\n",
    "    if ( dataset_name in [\"W23_only\"] ):\n",
    "        col = 'neverPrivSchlW1_'\n",
    "        replace = {0.0:\"No\",1.0:\"Yes\",9.0:\"Don't know\",9999.0:\"Don't know\"}\n",
    "        final_cats = [\"No\", \"Yes\", \"Don't know\"]\n",
    "        careful_replace_and_set_cats( col, replace, final_cats )        \n",
    "        BES_Panel[col] = BES_Panel[col].astype('category')         \n",
    "                \n",
    "    if ( dataset_name in [\"W23_only\"] ):\n",
    "        col = 'speakWelshW1_'\n",
    "        replace = {0.0:\"No\",1.0:\"Yes, but not fluently\",2.0:\"Yes, fluently\",9999.0:\"Don't know\"}\n",
    "        final_cats = [\"No\", \"Yes\", \"Don't know\"]\n",
    "        careful_replace_and_set_cats( col, replace, final_cats )        \n",
    "        BES_Panel[col] = BES_Panel[col].astype('category')         \n",
    "\n",
    "        \n",
    "        \n",
    "    # \"BES2017_W13_v1.0.dta\"\n",
    "\n",
    "    ## Should I make this *filename specific* or *wave specific*?\n",
    "    ## Comes down to a question of whether it's safer to assume that things get fixed\n",
    "    ## or that they probably won't get fixed\n",
    "\n",
    "\n",
    "    # gor W3_only, W2_only (3->-4, category -> object)\n",
    "    # # grr - some point BES switched from ONS codes to text names\n",
    "    # # I feel like percolating the change backwards would have been a good idea\n",
    "    # ONS codes available here:\n",
    "    # http://webarchive.nationalarchives.gov.uk/20160128190831/http://www.ons.gov.uk/ons/guide-method/geography/beginner-s-guide/administrative/england/government-office-regions/index.html\n",
    "\n",
    "    # variable name collision (BES 'disability' (wave 6 variable) and yougov profile 'disability)\n",
    "    if (\"disability\" in BES_Panel.columns) and (dataset_name != \"W6_only\"):\n",
    "        BES_Panel.rename(columns={\"disability\":\"profile_disability\"}, inplace=True)\n",
    "    # similar collision \n",
    "#     if (\"housing\" in BES_Panel.columns) and (dataset_name == \"W13_only\"):\n",
    "#         BES_Panel.rename(columns={\"housing\":\"profile_house_tenure\"}, inplace=True)  \n",
    "\n",
    "    # whole column is NaN!\n",
    "    col = \"profile_socialgrade_cie\"\n",
    "    if (col in BES_Panel.columns) and (dataset_name in [ \"W6_only\", \"W4_only\", \"W3_only\", \"W2_only\", \"W1_only\" ]):\n",
    "        var_type.loc[col,\"type\"] = -2 # set to ignore\n",
    "\n",
    "    # whole column is NaN!\n",
    "    col = 'discussPolDays'\n",
    "    if (col in BES_Panel.columns) and (dataset_name in [ \"W3_only\" ]):\n",
    "        var_type.loc[col,\"type\"] = -2 # set to ignore\n",
    "        \n",
    "    # whole column is NaN!\n",
    "    col = 'partyContactSNP'\n",
    "    if (col in BES_Panel.columns) and (dataset_name in [ \"W2_only\",\"W1_only\" ]):\n",
    "        var_type.loc[col,\"type\"] = -2 # set to ignore        \n",
    "\n",
    "        \n",
    "        \n",
    "    # now we have actual categories that don't match different versions *of that exact same variable*\n",
    "    # and can't even be attributed to weasel terms (e.g. 99 -> Don't know, 98 -> Other)\n",
    "    # so, I'll try just replacing them with NaNs\n",
    "    \n",
    "    if ( dataset_name in [\"W13_comb\"] ):\n",
    "        col = 'scotRefVoteW4_W13'\n",
    "        replace = {99.0:\"Don't know\",111.0:\"Don't know\"}\n",
    "        final_cats = ['Not at all certain', 'Somewhat certain', 'Very certain', \"Don't know\"]\n",
    "        careful_replace_and_set_cats( col,  replace, final_cats )        \n",
    "    \n",
    "\n",
    "    if ( dataset_name in [\"W13_comb\",\"W10_comb\"] ):\n",
    "        col = \"profile_turnout_2015\"\n",
    "        \n",
    "        replace = {}\n",
    "        final_cats = ['No, did not vote',\n",
    "                      'Yes, voted',\n",
    "                      \"Don't know\"]\n",
    "        careful_replace_and_set_cats( col,  replace, final_cats )\n",
    "\n",
    "\n",
    "    if ( dataset_name in [\"W6_comb\"] ):\n",
    "        col = \"zeroHourContractW6\"\n",
    "        \n",
    "        replace = {}\n",
    "        final_cats = ['Should definitely be illegal',\n",
    "                     'Should probably be illegal',\n",
    "                     'Should probably be legal',\n",
    "                     'Should definitely be legal',\n",
    "                     \"Don't know\"]\n",
    "        careful_replace_and_set_cats( col,  replace, final_cats )\n",
    "\n",
    "    if ( dataset_name in [\"W6_comb\",\"W5_comb\",\"W4_comb\",\"W3_comb\"] ):\n",
    "        col = \"certaintyEUGreenW2\"\n",
    "        \n",
    "        replace = {99.0:\"Don't know\"}\n",
    "        final_cats = ['Not at all certain', 'Somewhat certain', 'Very certain', \"Don't know\"]\n",
    "        careful_replace_and_set_cats( col,  replace, final_cats )\n",
    "        \n",
    "    if ( dataset_name in [\"W6_comb\"] ):\n",
    "        col = \"certaintyEUGreenW4\"\n",
    "        \n",
    "        replace = {99.0:\"Don't know\"}\n",
    "        final_cats = ['Not at all certain', 'Somewhat certain', 'Very certain', \"Don't know\"]\n",
    "        careful_replace_and_set_cats( col,  replace, final_cats )\n",
    "        \n",
    "        col = \"certaintyEUGreenW6\"\n",
    "        \n",
    "        replace = {99.0:\"Don't know\"}\n",
    "        final_cats = ['Not at all certain', 'Somewhat certain', 'Very certain', \"Don't know\"]\n",
    "        careful_replace_and_set_cats( col,  replace, final_cats )        \n",
    "\n",
    "        \n",
    "    if ( dataset_name in [\"W10_only\"] ):\n",
    "        col = \"econPersonalProsp\"\n",
    "        \n",
    "        replace = {}\n",
    "        final_cats = ['Get a lot worse',\n",
    "                     'Get a little worse',\n",
    "                     'Stay the same',\n",
    "                     'Get a little better',\n",
    "                     'Get a lot better',\n",
    "                     \"Don't know\"]\n",
    "        careful_replace_and_set_cats( col,  replace, final_cats )        \n",
    "\n",
    "    if ( dataset_name in [\"W13_comb\",\"W10_comb\"] ):\n",
    "        col = \"econPersonalProspW10\"\n",
    "        \n",
    "        replace = {}\n",
    "        final_cats = ['Get a lot worse',\n",
    "                     'Get a little worse',\n",
    "                     'Stay the same',\n",
    "                     'Get a little better',\n",
    "                     'Get a lot better',\n",
    "                     \"Don't know\"]\n",
    "        careful_replace_and_set_cats( col,  replace, final_cats )\n",
    "\n",
    "    if ( dataset_name in [\"W6_comb\",\"W5_only\"] ):\n",
    "        col = \"noDependentsInHousehold\"\n",
    "        \n",
    "        replace = {}\n",
    "        final_cats = ['No',\n",
    "                     'Yes']\n",
    "        careful_replace_and_set_cats( col,  replace, final_cats )            \n",
    "        \n",
    "        \n",
    "    if ( dataset_name in [\"W2_only\"] ):\n",
    "        col = \"gor\"\n",
    "\n",
    "        ons_gor_dict = {\"E12000001\":\"North East\",\n",
    "                        \"E12000002\":\"North West\",\n",
    "                        \"E12000003\":\"Yorkshire and The Humber\",\n",
    "                        \"E12000004\":\"East Midlands\",\n",
    "                        \"E12000005\":\"West Midlands\",\n",
    "                        \"E12000006\":\"East of England\",\n",
    "                        \"E12000007\":\"London\",\n",
    "                        \"E12000008\":\"South East\",\n",
    "                        \"E12000009\":\"South West\",\n",
    "                        \"N99999999\":\"Northern Ireland\",\n",
    "                        \"S99999999\":\"Scotland\",\n",
    "                        \"W99999999\":\"Wales\",\n",
    "                        \"\":\"Non UK & Invalid\"}\n",
    "\n",
    "        careful_replace(  col , ons_gor_dict )\n",
    "        \n",
    "    if ( dataset_name in [\"W21_only\"] ):\n",
    "        col = \"gor\"\n",
    "        \n",
    "        ons_gor_dict = {1:\"North East\",\n",
    "                        2:\"North West\",\n",
    "                        3:\"Yorkshire and The Humber\",\n",
    "                        4:\"East Midlands\",\n",
    "                        5:\"West Midlands\",\n",
    "                        6:\"East of England\",\n",
    "                        7:\"London\",\n",
    "                        8:\"South East\",\n",
    "                        9:\"South West\",\n",
    "                        10:\"Wales\",\n",
    "                        11:\"Scotland\",\n",
    "                }\n",
    "\n",
    "        careful_replace(  col , ons_gor_dict )   \n",
    "        \n",
    "    if ( dataset_name in [\"W21_only\"] ):\n",
    "        col = \"p_country_birth\"\n",
    "        \n",
    "        ons_gor_dict = {1.0:\"UK\",\n",
    "                        2.0:\"Ireland\",\n",
    "                        3.0:\"EU: pre-2004\",\n",
    "                        4.0:\"EU: post-2004\",\n",
    "                        5.0:\"European outside EU\",\n",
    "                        6.0:\"Africa\",\n",
    "                        7.0:\"East Asia\",\n",
    "                        8.0:\"South-East/Central Asia\",\n",
    "                        9.0:\"South Asia\",\n",
    "                        10.0:\"North America\",\n",
    "                        11.0:\"Caribbean/Central America\",\n",
    "                        12.0:\"South America\",\n",
    "                        13.0:\"Oceania & Antarctica\",\n",
    "                        14.0:\"Middle East\",\n",
    "                        9999.0:\"Not coded\",\n",
    "                }\n",
    "\n",
    "        careful_replace(  col , ons_gor_dict )          \n",
    "\n",
    "    if ( dataset_name in [\"W3_comb\",\"W4_comb\",\"W5_comb\"] ):\n",
    "        col = \"mapNamesW3\"\n",
    "\n",
    "        BES_Panel[col] = \\\n",
    "            BES_Panel[col].astype('float64')\n",
    "        var_type.loc[col,\"dtype\"] = BES_Panel[col].dtype.name        \n",
    "        var_type.loc[ col , \"dataset_specific_hardcoded_fix\" ] = list(BES_Panel[col].unique())\n",
    "    \n",
    "\n",
    "    if ( dataset_name in [\"W12_only\",\"W11_only\",\"W3_only\",\"W2_only\",\"W1_only\"] ):\n",
    "        partyContact = {1.0:\"No\",\n",
    "                        2.0:\"Yes\",\n",
    "                        9999.0:\"Don't know\"}\n",
    "        col = \"partyContactGrn\"\n",
    "        careful_replace( col , {el:el for el in partyContact.values()} )     \n",
    "\n",
    "#                    'Own - outright|Own - with a mortgage|Own (part-own) - through shared ownership scheme (i.e. pay part mortgage, part rent)|Rent - from a private landlord|Rent - from my local authority|Rent - from a housing association|Neither - I live with my parents, family or friends but pay some rent to them|Neither - I live rent-free with my parents, family or friends|Other|9999':\n",
    "#                        [ 'Own outright',\n",
    "#                          'Own with a mortgage',\n",
    "#                          'Own (part-own) through shared ownership scheme (i.e. pay part mortgage, part rent)',\n",
    "#                          'Rent from a private landlord',\n",
    "#                          'Rent from my local authority',\n",
    "#                          'Rent from a housing association',\n",
    "#                          'Neither I live with my parents, family or friends but pay some rent to them',\n",
    "#                          'Neither I live rent-free with my parents, family or friends',\n",
    "#                          'Other',\n",
    "#                          '9999'], #profile_house_tenureW11|profile_house_tenureW12|profile_house_tenureW13\n",
    "        \n",
    "# housing\tW13_only\tW6_comb\tcategory\t3\thousing\tOwn the leasehold/freehold outright|Buying leasehold/freehold on a mortgage|Rented from local authority|Rented from private landlord|It belongs to a Housing Association\tOwn - outright|Own - with a mortgage|Own (part-own) - through shared ownership scheme (i.e. pay part mortgage, part rent)|Rent - from a private landlord|Rent - from my local authority|Neither - I live with my parents, family or friends but pay some rent to them|Neither - I live rent-free with my parents, family or friends\n",
    "\n",
    "        \n",
    "    if ( dataset_name in [\"W6_comb\"] ):\n",
    "        housing_replace = {'Own \\x96 outright': 'Own outright',\n",
    "                         'Own \\x96 with a mortgage': 'Own with a mortgage',\n",
    "                         'Own (part-own) \\x96 through shared ownership scheme (i.e. pay part mortgage, part rent)': 'Own (part-own) through shared ownership scheme (i.e. pay part mortgage, part rent)',\n",
    "                         'Rent \\x96 from a private landlord': 'Rent from a private landlord',\n",
    "                         'Rent \\x96 from my local authority': 'Rent from my local authority',\n",
    "                         'Neither \\x96 I live with my parents, family or friends but pay some rent to them': 'Neither I live with my parents, family or friends but pay some rent to them',\n",
    "                         'Neither \\x96 I live rent-free with my parents, family or friends': 'Neither I live rent-free with my parents, family or friends',\n",
    "                         'Other':'Other',\n",
    "                         '9999':'Rent from a housing association'}\n",
    "        \n",
    "        housing_final_cats = ['Own outright',\n",
    "                         'Own with a mortgage',\n",
    "                         'Own (part-own) through shared ownership scheme (i.e. pay part mortgage, part rent)',\n",
    "                         'Rent from a private landlord',\n",
    "                         'Rent from my local authority',\n",
    "                         'Rent from a housing association',\n",
    "                         'Neither I live with my parents, family or friends but pay some rent to them',\n",
    "                         'Neither I live rent-free with my parents, family or friends',\n",
    "                         'Other']\n",
    "        \n",
    "        col = \"housing\" \n",
    "        careful_replace_and_set_cats( col,  housing_replace, housing_final_cats )\n",
    "        \n",
    "# None/ No leader|David Cameron|Ed Miliband|Nick Clegg|Nicola Sturgeon|Leanne Wood|Nigel Farage|Natalie Bennett|222.0|Don't know\n",
    "# None/ No leader|David Cameron|Ed Miliband|Nick Clegg|Nicola Sturgeon|Leanne Wood|Nigel Farage|Natalie Bennett|222|Don't know\n",
    "# bestLeaderCampaign\tW6_only\n",
    "# worstLeaderCampaign\tW6_only\n",
    "        \n",
    "        \n",
    "\n",
    "    BestWorstLeader_replace = {\"None/ No leader\":\"None/No leader\",\n",
    "                               10.0:\"All leaders equally bad\",\n",
    "                               222.0:\"All leaders equally bad\",\n",
    "                               222:\"All leaders equally bad\"}\n",
    "    BestWorstLeader_final_cats = [\"None/No leader\",\"David Cameron\",\"Ed Miliband\",\"Nick Clegg\",\"Nicola Sturgeon\",\n",
    "                                  \"Leanne Wood\",\"Nigel Farage\",\"Natalie Bennett\",\"All leaders equally bad\"]\n",
    "    # run on all datasets - wait - only ones in which it exists\n",
    "    \n",
    "#     if ( dataset_name in [\"W6_comb\",\"W5_comb\"] ):\n",
    "    col = \"bestLeaderCampaignW5\"\n",
    "    if ( col in BES_Panel.columns ):\n",
    "        careful_replace_and_set_cats( col,  BestWorstLeader_replace, BestWorstLeader_final_cats )\n",
    "    col = \"worstLeaderCampaignW5\"        \n",
    "    if ( col in BES_Panel.columns ):  \n",
    "        careful_replace_and_set_cats( col, BestWorstLeader_replace, BestWorstLeader_final_cats )\n",
    "\n",
    "#     if ( dataset_name in [\"W5_only\",\"W6_only\"] ):\n",
    "    col = \"bestLeaderCampaign\"\n",
    "    if ( col in BES_Panel.columns ):\n",
    "        careful_replace_and_set_cats( col,  BestWorstLeader_replace, BestWorstLeader_final_cats )\n",
    "        \n",
    "    col = \"worstLeaderCampaign\"\n",
    "    if ( col in BES_Panel.columns ):\n",
    "        careful_replace_and_set_cats( col,  BestWorstLeader_replace, BestWorstLeader_final_cats )        \n",
    "      \n",
    "\n",
    "    scotReferendumIntention_replace = {'Scotland should become an independent country':\"Will vote 'Yes'\",\n",
    "                                       111.0:'Will vote no',\n",
    "                                       99.0:\"Don't know\",\n",
    "                                       2.0:\"Will not vote\",}\n",
    "    scotReferendumIntention_final_cats = ['Will vote no', \"Will vote 'Yes'\", 'Will not vote', \"Don't know\"]\n",
    "        \n",
    "    if ( dataset_name in [\"W6_comb\"] ):\n",
    "        careful_replace_and_set_cats( \"scotReferendumIntentionW6\",  scotReferendumIntention_replace, scotReferendumIntention_final_cats )\n",
    "\n",
    "        \n",
    "    \n",
    "    Religion = {'No, I do not regard myself as belonging to any particular religion.': 'No, I do not regard myself as belonging to any particular religion.',\n",
    "         'Yes - Church of England/Anglican/Episcopal': 'Yes - Church of England/Anglican/Episcopal',\n",
    "         'Yes - Roman Catholic': 'Yes - Roman Catholic',\n",
    "         'Yes - Presbyterian/Church of Scotland': 'Yes - Presbyterian/Church of Scotland',\n",
    "         'Yes - Methodist': 'Yes - Methodist',\n",
    "         'Yes - Baptist': 'Yes - Baptist',\n",
    "         'Yes - United Reformed Church': 'Yes - United Reformed Church',\n",
    "         'Yes - Free Presbyterian': 'Yes - Free Presbyterian',\n",
    "         'Yes - Brethren': 'Yes - Brethren',\n",
    "         'Yes - Judaism': 'Yes - Judaism',\n",
    "         'Yes - Hinduism': 'Yes - Hinduism',\n",
    "         'Yes - Islam': 'Yes - Islam',\n",
    "         'Yes - Sikhism': 'Yes - Sikhism',\n",
    "         'Yes - Buddhism': 'Yes - Buddhism',\n",
    "         'Yes - Other': 'Yes - Other',\n",
    "         16.0: 'Prefer not to say',\n",
    "         17.0: 'Yes - Orthodox Christian',\n",
    "         18.0: 'Yes - Pentecostal',\n",
    "         19.0: 'Yes - Evangelical /independent/non-denominational'}\n",
    "\n",
    "    \n",
    "    if ( dataset_name in [\"W6_comb\",\"W5_comb\",\"W5_only\",\"W4_comb\",\"W3_comb\"] ):\n",
    "\n",
    "        col = \"profile_religion\"\n",
    "        careful_replace( col , Religion )        \n",
    "\n",
    "    if ( dataset_name in [\"W1_only\"] ):\n",
    "\n",
    "        col = \"profile_religion\"\n",
    "        careful_replace( col , {el:el for el in Religion.values()} )            \n",
    "        \n",
    "    if ( dataset_name in [\"W7_only\"] ):\n",
    "        col = \"ns_sec\"\n",
    "        ns_sec = \"Employers in large establishments|Higher managerial and administrative occupations|L3.1 Traditional employees|L3.2 New employees|L3.3 Traditional self-employed|L3.4 New self-employed|L4.1 Traditional employees|L4.2 New employees|L4.3 Traditional self-employed|L4.4 New self-employed|Lower managerial and administrative occupations|Higher supervisory occupations|L7.1 Intermediate clerical and administrative occupations|L7.2 Intermediate sales and service occupations|L7.3 Intermediate technical and auxiliary occupations|L7.4 Intermediate engineering occupations|L8.1 Employers in small establishments in industry, commerce, services etc.|L8.2 Employers in small establishments in agriculture|L9.1 Own account workers (non-professional)|L9.2 Own account workers (agriculture)|Lower supervisory occupations|L11.1 Lower technical craft occupations|L11.2 Lower technical process operative occupations|L12.1 Semi-routine sales occupations|L12.2 Semi-routine service occupations|L12.3 Semi-routine technical occupations|L12.4 Semi-routine operative occupations|L12.5 Semi-routine agricultural occupations|L12.6 Semi-routine clerical occupations|L12.7 Semi routine childcare occupations|L13.1 Routine sales and service occupations|L13.2 Routine production occupations|L13.3 Routine technical occupations|L13.4 Routine operative occupations|L13.5 Routine agricultural occupations\"\n",
    "        \n",
    "        careful_replace( col , {el:el for el in ns_sec.split(\"|\")} )\n",
    "#         BES_Panel[col].cat.set_categories(ns_sec.split(\"|\"),inplace=True)\n",
    "        \n",
    "        \n",
    "    if ( dataset_name in [\"W1_only\"] ):\n",
    "        ageGroup = {1.0:\"Under 18\",\n",
    "                    2.0:\"18-25\",\n",
    "                    3.0:\"26-35\",\n",
    "                    4.0:\"36-45\",\n",
    "                    5.0:\"46-55\",\n",
    "                    6.0:\"56-65\",\n",
    "                    7.0:\"66+\"}\n",
    "        col = \"ageGroup\"\n",
    "        careful_replace( col , {el:el for el in ageGroup.values()})      \n",
    "        \n",
    "        \n",
    "    if ( dataset_name in [ \"W13_comb\" , \"W11_only\" ] ):\n",
    "        \n",
    "        # None|Church of England/Anglican/Episcopal|Roman Catholic|Presbyterian/Church of Scotland|Methodist|Baptist\n",
    "        # A|B|C1|C2|D|E|Refused|Unknown\n",
    "        # DOUBLE CHECK DISTRIBUTION\n",
    "        SocialGrades = {\"None\":\"A\",\n",
    "                        \"Church of England/Anglican/Episcopal\":\"B\",\n",
    "                        \"Roman Catholic\":\"C1\",\n",
    "                        \"Presbyterian/Church of Scotland\":\"C2\",\n",
    "                        \"Methodist\":\"D\",\n",
    "                        \"Baptist\":\"E\",\n",
    "                        \"<placeholder1>\":\"Refused\",\n",
    "                        \"<placeholder2>\":\"Unknown\"}\n",
    "        col = \"profile_socialgrade_cie\"        \n",
    "        careful_replace( col , SocialGrades )\n",
    "        \n",
    "    NumEmployees = {1.0:\"1 to 24 employees\",\n",
    "                    2.0:\"25 to 499 employees\",\n",
    "                    3.0:\"500 or more employees\",\n",
    "                    9999.0:\"Don't know\"}\n",
    "\n",
    "    if ( dataset_name in [\"W1_only\",\"W2_only\",\"W3_only\",\"W4_only\",\"W11_only\",\"W12_only\",\"W13_only\",\"W13_comb\", \"W10_only\"] ):\n",
    "        # necessary because motherNumEmployees lacks some categories!\n",
    "\n",
    "        col = \"fatherNumEmployees\"\n",
    "        careful_replace( col , NumEmployees )\n",
    "\n",
    "        col = \"motherNumEmployees\"\n",
    "        careful_replace( col , NumEmployees )\n",
    "        \n",
    "    if ( dataset_name in [\"W9_only\"] ):        \n",
    "        \n",
    "        col = \"motherNumEmployees\"\n",
    "        careful_replace( col , {el:el for el in NumEmployees.values()} )        \n",
    "\n",
    "    if ( dataset_name in [\"W6_comb\"] ):\n",
    "        # not entirely necessary to implement it this way, it's just a bit clearer\n",
    "\n",
    "        churchAttendance = {111.0:\"Never or practically never\",\n",
    "                            \"Less often than once a year\":\"Less often than once a year\",\n",
    "                            \"Less often but at least once a year\":\"Less often but at least once a year\",\n",
    "                            \"Less often but at least twice a year\":\"Less often but at least twice a year\",\n",
    "                            \"Less often but at least once a month\":\"Less often but at least once a month\",\n",
    "                            \"Less often but at least once in two weeks\":\"Less often but at least once in two weeks\",\n",
    "                            \"Once a week or more\":\"Once a week or more\",\n",
    "                            222.0:\"Varies too much to say\",\n",
    "                            98.0:\"I am not religious\",\n",
    "                            99.0:\"Don't know\"}\n",
    "\n",
    "        col = \"churchAttendanceW6\"\n",
    "        careful_replace( col , churchAttendance )\n",
    "\n",
    "\n",
    "        partyMember =      {0.0:\"No, I have never been a member\",\n",
    "                            \"I am not a member now but I used to be\":\"I am not a member now but I used to be\",\n",
    "                            \"Yes, I am a member of a party\":\"Yes, I am a member of a party\",\n",
    "                            9999.0:\"Don't know\"}\n",
    "\n",
    "        col = \"partyMemberW6\"\n",
    "        careful_replace( col , partyMember )       \n",
    "\n",
    "\n",
    "    headHouseholdPast_cat_list = \"My father|My mother|Someone else|No one in my house worked|Don't know\"\n",
    "    if ( dataset_name in [ \"W3_only\",\"W4_only\",\"W11_only\",\"W12_only\",\"W13_only\", \"W13_comb\",\"W10_only\" ] ):\n",
    "        hardcoded_fix(\"headHouseholdPast\",\n",
    "                      headHouseholdPast_cat_list)\n",
    "\n",
    "    generalElectionCertainty_cat_list = \"Not at all certain|2|3|4|5|6|Completely certain|Don't know\"\n",
    "    if ( dataset_name in [\"W4_comb\",\"W5_comb\"] ):\n",
    "        # array of floats, should be a categorical\n",
    "        hardcoded_fix(\"generalElectionCertaintyW1\",\n",
    "                      generalElectionCertainty_cat_list)\n",
    "        hardcoded_fix(\"generalElectionCertaintyW2\",\n",
    "                      generalElectionCertainty_cat_list)\n",
    "\n",
    "    if ( dataset_name in [\"W5_comb\"] ):\n",
    "        # array of floats, should be a categorical\n",
    "        hardcoded_fix(\"generalElectionCertaintyW3\",\n",
    "                      generalElectionCertainty_cat_list)        \n",
    "\n",
    "\n",
    "    scotReferendumIntention_cat_list = \"Will vote no|Will vote 'Yes'|Will not vote|Don't know\"\n",
    "    if ( dataset_name in [\"W4_comb\",\"W5_comb\",\"W6_comb\"] ):\n",
    "        # array of floats, should be a categorical  \n",
    "        hardcoded_fix(\"scotReferendumIntentionW4\",\n",
    "                      scotReferendumIntention_cat_list)  \n",
    "\n",
    "    selfNumEmployees_cat_list = \"1 to 24 employees|25 to 499 employees|500 or more employees|Don't know\"\n",
    "#     selfNumEmployeesW6_W12, selfNumEmployeesLastW6_W12\n",
    "    if ( dataset_name in [ 'W13_comb' ] ):\n",
    "        hardcoded_fix(\"selfNumEmployeesW6_W12\",\n",
    "                      selfNumEmployees_cat_list )\n",
    "        hardcoded_fix(\"selfNumEmployeesLastW6_W12\",\n",
    "                      selfNumEmployees_cat_list )    \n",
    "\n",
    "    if ( dataset_name in [ 'W12_only' ] ):\n",
    "        hardcoded_fix(\"selfNumEmployeesW6_\",\n",
    "                      selfNumEmployees_cat_list )\n",
    "        hardcoded_fix(\"selfNumEmployeesLastW6_\",\n",
    "                      selfNumEmployees_cat_list )          \n",
    "    \n",
    "    if ( dataset_name in [ \"W7_comb\" ] ):  \n",
    "        hardcoded_fix(\"selfNumEmployeesW6W7\",\n",
    "                      selfNumEmployees_cat_list )           \n",
    "        hardcoded_fix(\"selfNumEmployeesLastW6W7\",\n",
    "                      selfNumEmployees_cat_list )          \n",
    "\n",
    "    if ( dataset_name in [ \"W8_comb\" ] ):\n",
    "        hardcoded_fix(\"selfNumEmployeesW6W7W8\",\n",
    "                      selfNumEmployees_cat_list )           \n",
    "        hardcoded_fix(\"selfNumEmployeesLastW6W7W8\",\n",
    "                      selfNumEmployees_cat_list )  \n",
    "\n",
    "    if ( dataset_name in [ \"W10_comb\", \"W9_comb\", \"W9_only\" ] ): #\"W13_comb\", \n",
    "        hardcoded_fix(\"selfNumEmployeesW6W7W8W9\",\n",
    "                      selfNumEmployees_cat_list )\n",
    "        \n",
    "    if ( dataset_name in [ \"W10_comb\", \"W9_comb\", \"W9_only\" ] ): #\"W13_comb\",         \n",
    "        hardcoded_fix(\"selfNumEmployeesLastW6W7W8W9\",\n",
    "                      selfNumEmployees_cat_list )\n",
    "        \n",
    "#     if ( dataset_name in [ \"W12_only\",\"W11_only\",\"W10_only\",\"W13_comb\" ] ):\n",
    "        \n",
    "# #         careful_replace( \"selfNumEmployees\" , {el:el for el in NumEmployees.values()} )  \n",
    "# #         careful_replace( \"selfNumEmployeesLast\" , {el:el for el in NumEmployees.values()} )\n",
    "        \n",
    "#         careful_replace_and_set_cats( \"selfNumEmployees\", {}, NumEmployees.values() )\n",
    "#         careful_replace_and_set_cats( \"selfNumEmployeesLast\", {}, NumEmployees.values() )        \n",
    "\n",
    "\n",
    "    #    \"knowf2f2\",\"knowf2f3\", #  floats (0.0, 1.0, 99.0)  that should be categories True|False|Don't know\n",
    "    knowf2_cat_list = \"True|False|Don't know\"\n",
    "    if ( dataset_name in [\"W12_only\"]):\n",
    "        hardcoded_fix(\"knowf2f2\",\n",
    "                      knowf2_cat_list )            \n",
    "        hardcoded_fix(\"knowf2f3\",\n",
    "                      knowf2_cat_list )  \n",
    "\n",
    "    if ( dataset_name in [ \"W13_comb\" ] ):  \n",
    "        hardcoded_fix(\"knowf2f2W12\",\n",
    "                      knowf2_cat_list )             \n",
    "        hardcoded_fix(\"knowf2f3W12\",\n",
    "                      knowf2_cat_list )\n",
    "\n",
    "    likeSalmond_list = \"Strongly dislike|1.0|2.0|3.0|4.0|5.0|6.0|7.0|8.0|9.0|Strongly like|Don't know\"\n",
    "    if ( dataset_name in [ \"W4_comb\",\"W4_comb\",\"W5_comb\" ] ):\n",
    "        hardcoded_fix(\"likeSalmondW1\",\n",
    "                      likeSalmond_list )   \n",
    "        hardcoded_fix(\"likeSalmondW2\",\n",
    "                      likeSalmond_list )\n",
    "        hardcoded_fix(\"likeSalmondW3\",\n",
    "                      likeSalmond_list )\n",
    "\n",
    "    eesEUIntegration_list = \"Unification has already gone too far|1.0|2.0|3.0|4.0|5.0|6.0|7.0|8.0|9.0|Unification should be pushed further|Don't know\"    \n",
    "    if ( dataset_name in [ \"W3_comb\",\"W4_comb\",\"W4_comb\",\"W5_comb\" ] ):\n",
    "        hardcoded_fix(\"eesEUIntegrationGreenW2\",\n",
    "                      eesEUIntegration_list )    \n",
    "\n",
    "    likeSturgeon_list = \"Strongly dislike|1.0|2.0|3.0|4.0|5.0|6.0|7.0|8.0|9.0|Strongly like|Don't know\"    \n",
    "    if ( dataset_name in [ \"W4_comb\",\"W4_comb\",\"W5_comb\" ] ):\n",
    "        hardcoded_fix(\"likeSturgeonW4\",\n",
    "                      likeSturgeon_list )\n",
    "\n",
    "    # W5_comb\n",
    "    # No|Yes\tGot a lot worse|Got a little worse\n",
    "    # partyContactDKW5, participation_1-6W5, sharedContentOnline_1-5W5, participation_99W5\n",
    "    participation_list = \"No|Yes\"    \n",
    "    if ( dataset_name in [ \"W5_comb\" ] ):\n",
    "        hardcoded_fix(\"partyContactDKW5\",\n",
    "                      participation_list )    \n",
    "        hardcoded_fix(\"participation_1W5\",\n",
    "                      participation_list )   \n",
    "        hardcoded_fix(\"participation_2W5\",\n",
    "                      participation_list )   \n",
    "        hardcoded_fix(\"participation_3W5\",\n",
    "                      participation_list )   \n",
    "        hardcoded_fix(\"participation_4W5\",\n",
    "                      participation_list )   \n",
    "        hardcoded_fix(\"participation_5W5\",\n",
    "                      participation_list )   \n",
    "        hardcoded_fix(\"participation_6W5\",\n",
    "                      participation_list )   \n",
    "        hardcoded_fix(\"sharedContentOnline_1W5\",\n",
    "                      participation_list )  \n",
    "        hardcoded_fix(\"sharedContentOnline_2W5\",\n",
    "                      participation_list )      \n",
    "        hardcoded_fix(\"sharedContentOnline_3W5\",\n",
    "                      participation_list )      \n",
    "        hardcoded_fix(\"sharedContentOnline_4W5\",\n",
    "                      participation_list )  \n",
    "        hardcoded_fix(\"sharedContentOnline_5W5\",\n",
    "                      participation_list )      \n",
    "        hardcoded_fix(\"participation_99W5\",\n",
    "                      participation_list )       \n",
    "        \n",
    "    return BES_Panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_100_seq(col, start, finish, weasel, rng=100):\n",
    "    lst = list([weasel,start, finish])\n",
    "    lst_dict = {\"0\":start,str(rng):finish}\n",
    "\n",
    "    fullseq = [start]\n",
    "    [fullseq.append(str(x)) for x in range(1,rng)]\n",
    "    fullseq.append(finish)\n",
    "    fullseq.append(weasel)\n",
    "    # make sure all numbers in same format (string integers)\n",
    "    BES_Panel[col] = BES_Panel[col].cat.rename_categories( [str(int(x)) if x not in lst else x for x in BES_Panel[col].cat.categories ] )\n",
    "    BES_Panel[col] = BES_Panel[col].cat.rename_categories( [lst_dict[x] if x in lst_dict.keys() else x for x in BES_Panel[col].cat.categories ] )\n",
    "    \n",
    "    # change categories to correct range\n",
    "    BES_Panel[col] = BES_Panel[col].cat.set_categories(fullseq)\n",
    "    if len( BES_Panel[col].cat.categories ) != rng+2:\n",
    "        raise Exception(\"wrong number of categories!\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def number_and_string_sequences(  ):\n",
    "\n",
    "# How to deal with large sequences of numbers (e.g. %)\n",
    "# Which have some values missing (presumably because no entries)\n",
    "# But also have strings at the ends\n",
    "\n",
    "# Want to keep the string categories (because they're useful for clarification)\n",
    "# But also want the numeric coding to be remain accurate\n",
    "# e.g. \"0% no support for X, 1% ... 45%, 83%, 100% complete support for X\" -> would normally turn into [0,1...45,46,47]\n",
    "# should turn into [0,1...45,83,100]\n",
    "\n",
    "# It's *POSSIBLE* that question answerers don't think this way - might get cleaner results by just assuming positional placement\n",
    "# Would be useful to have a switch to test that\n",
    "\n",
    "\n",
    "\n",
    "# run on everything like this\n",
    "\n",
    "#\n",
    "\n",
    "# re.match( \"(winConstituency[a-zA-Z0-9_]+)\", \"winConstituencyConW4\").groups()[0]\n",
    "\n",
    "# maybe simply run this on all variables marked 6?\n",
    "# tweak the ends, drop the DKS, then turn to floats?\n",
    "\n",
    "\n",
    "    str_float_0_100_cats = [str(float(x)) for x in range(0,101)] # ['0.0', '1.0', '2.0', '3.0' ... '98.0', '99.0', '100.0']\n",
    "\n",
    "    ### this isn't an error so much as a matter of practicality\n",
    "    # if I make all these values integers then we don't have to\n",
    "    # worry about missing categories\n",
    "    # (assuming they're only missing because of legit. lack of entries)\n",
    "    col = \"scotRefExpectationTurnout\"\n",
    "\n",
    "    if ( col in  BES_Panel.columns ):    \n",
    "\n",
    "        start = \"0% of people will vote\"\n",
    "        finish = \"100% of people will vote\"\n",
    "        weasel = \"Don't know\"        \n",
    "        fix_100_seq(col, start, finish, weasel)         \n",
    "        \n",
    "#         scotRefExpectationTurnout_list = [\"100.0\" if x==\"100% of people will vote\" else x for x in BES_Panel[col].cat.categories]\n",
    "#         BES_Panel[col].cat.rename_categories( scotRefExpectationTurnout_list, inplace=True )\n",
    "#         add_categories()\n",
    "\n",
    "\n",
    "    col = \"winConstituencyPC\"    \n",
    "    if ( col in  BES_Panel.columns ):\n",
    "        \n",
    "        start = \"0 - Very unlikely to win\"\n",
    "        finish = \"100 - Very likely to win\"\n",
    "        weasel = \"Don't know\"        \n",
    "        fix_100_seq(col, start, finish, weasel)          \n",
    "        \n",
    "#         winConstituencyPC_list = [\"100.0\" if x==\"100 - Very likely to win\" else x for x in BES_Panel[col].cat.categories]\n",
    "#         winConstituencyPC_list = [\"0.0\" if x==\"0 - Very unlikely to win\" else x for x in winConstituencyPC_list]\n",
    "#         BES_Panel[col].cat.rename_categories( winConstituencyPC_list, inplace=True )\n",
    "\n",
    "    col = \"winConstituencySNP\"\n",
    "    if ( col in  BES_Panel.columns ):    \n",
    "        start = \"0 - Very unlikely to win\"\n",
    "        finish = \"100 - Very likely to win\"\n",
    "        weasel = \"Don't know\"        \n",
    "        fix_100_seq(col, start, finish, weasel)   \n",
    "\n",
    "    col = \"winConstituencyGreen\"\n",
    "    if ( col in  BES_Panel.columns ):    \n",
    "        start = \"0 - Very unlikely to win\"\n",
    "        finish = \"100 - Very likely to win\"\n",
    "        weasel = \"Don't know\"        \n",
    "        fix_100_seq(col, start, finish, weasel)    \n",
    "        \n",
    "        \n",
    "# Allow many fewer|2|4|5|6|7|8|9|Allow many more|Don't know        \n",
    "\n",
    "    col = \"immigSNP\"\n",
    "    if ( col in  BES_Panel.columns ):    \n",
    "        start = \"Allow many fewer\"\n",
    "        finish = \"Allow many more\"\n",
    "        weasel = \"Don't know\"        \n",
    "        fix_100_seq(col, start, finish, weasel,10)       \n",
    "\n",
    "\n",
    "    col = \"immigPC\"\n",
    "    if ( col in  BES_Panel.columns ):    \n",
    "        start = \"Allow many fewer\"\n",
    "        finish = \"Allow many more\"\n",
    "        weasel = \"Don't know\"        \n",
    "        fix_100_seq(col, start, finish, weasel,10)      \n",
    "## NEED TO SET THESE AS TYPE 6!    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_name = \"W1_only\"\n",
    "# BES_file_manifest = pd.read_csv( BES_small_data_files + \"BES_file_manifest.csv\" )\n",
    "# manifest = BES_file_manifest[ BES_file_manifest[\"Name\"] == dataset_name ]\n",
    "\n",
    "# data_subfolder = BES_data_folder + dataset_name + os.sep\n",
    "\n",
    "# filename = manifest[\"Stata_Filename\"].values[0]\n",
    "\n",
    "# BES_Panel = pd.read_stata( data_subfolder + filename)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# col = \"fatherNumEmployees\"\n",
    "# careful_replace( col , NumEmployees )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# col = \"motherNumEmployees\"\n",
    "# careful_replace( col , NumEmployees )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset(dataset_name):\n",
    "\n",
    "    BES_file_manifest = pd.read_csv( BES_small_data_files + \"BES_file_manifest.csv\" )\n",
    "    manifest = BES_file_manifest[ BES_file_manifest[\"Name\"] == dataset_name ]\n",
    "\n",
    "    data_subfolder = BES_data_folder + dataset_name + os.sep\n",
    "\n",
    "    filename = manifest[\"Stata_Filename\"].values[0]\n",
    "\n",
    "    global BES_Panel\n",
    "    BES_Panel = pd.read_stata( data_subfolder + filename)\n",
    "    ####################################################\n",
    "\n",
    "    # use this dataframe to store *everything* we're doing to transform/ignore variables!\n",
    "    global var_type\n",
    "    var_type = pd.DataFrame(columns = [\"dataset_name\",\"dtype\",\"cat_all_strings\",\"type\",\"pruned\",\"original_cat_list\",\n",
    "                                       \"renamed_cat_list\",\"reordered_cat_list\",\"final_cat_list\",\n",
    "                                       \"dataset_specific_hardcoded_fix\",\n",
    "                                       \"numerical_dont_knows\",\n",
    "                                       \"weasel_words\",\"typos\" ] )\n",
    "    ####################################################\n",
    "\n",
    "    BES_Panel = hard_coded_fixes( dataset_name ) # side effects on BES_Panel and var_type\n",
    "    number_and_string_sequences() # side effects on BES_Panel\n",
    "\n",
    "    variable_categories = pd.read_csv( BES_small_data_files + \"question_categories_correct.csv\",\n",
    "                                       encoding = encoding,index_col=False )\n",
    "    variable_categories.drop('Unnamed: 0', axis=1,inplace=True)\n",
    "\n",
    "    ( var_cat_dict_pruned , var_cat_dict_pruned_2 ) = create_var_list( variable_categories )\n",
    "    ####################################################\n",
    "\n",
    "    missing_col_names = []\n",
    "    try:\n",
    "        for col in BES_Panel.columns:\n",
    "            print(col)\n",
    "            dt =  BES_Panel[col].dtype.name # data type\n",
    "    #         not_found = False\n",
    "\n",
    "            var_type.loc[col,\"dataset_name\"] = dataset_name\n",
    "            # dtype is either nan because not set -> set\n",
    "            if not isinstance(var_type.loc[col,\"dtype\"],str):\n",
    "                var_type.loc[ col , \"dtype\"] = dt    \n",
    "            # if dtype == category *and* cat_all_strings not already set, set\n",
    "            if (var_type.loc[ col , \"dtype\" ] == 'category') and careful_isnan( var_type.loc[ col , \"cat_all_strings\" ] ):\n",
    "                var_type.loc[ col , \"cat_all_strings\" ] = np.all([isinstance(x,str) for x in BES_Panel[ col ].cat.categories])\n",
    "\n",
    "            not_found = False      \n",
    "\n",
    "            if (col in ignore_list) or (var_type.loc[col,\"type\"] == -2): # exclude values from ignore_list *and manually coded errors*\n",
    "                var_type.loc[col,\"type\"] = -2\n",
    "                if var_type.loc[ col , \"cat_all_strings\" ]==True:\n",
    "                    var_type.loc[ col, \"original_cat_list\" ] = \"|\".join( BES_Panel[col].cat.categories )\n",
    "                elif ('float' in dt) or ('int' in dt):\n",
    "                    var_type.loc[ col, \"original_cat_list\" ] = list(BES_Panel[col].unique())\n",
    "\n",
    "            elif (col in [\"id\"] ): # id\n",
    "                var_type.loc[col,\"type\"] = -5\n",
    "\n",
    "            elif (dt == 'object'): # (probably) text\n",
    "                var_type.loc[col,\"type\"] = -4\n",
    "\n",
    "            elif (\"datetime\" in dt): # datetime\n",
    "                var_type.loc[col,\"type\"] = -3\n",
    "\n",
    "        # 0 - personality measures (in steps of .5?), personality_agreeableness ...etc, riskScaleW8        \n",
    "            elif (col in [\"personality_agreeableness\",\n",
    "                         \"personality_conscientiousness\",\n",
    "                         \"personality_extraversion\",\n",
    "                         \"personality_neuroticism\",\n",
    "                         \"personality_openness\"]) or (re.match(\"(cogempathy|affempathy|zeroSum)IRT\",col) is not None) or (re.match(\"riskScale(W[0-9]+)?\",col) is not None) :\n",
    "\n",
    "                var_type.loc[col,\"type\"] = 0\n",
    "\n",
    "        # 7 - soc2010(W3-6_comb,W5_only), v1(W5_comb), RandomIDW1(W3-6_comb), mapNames(W3_only), mapNamesW3 (W3-10_comb,W13_comb)        \n",
    "            elif re.match(\"soc2010|v1|RandomIDW1|mapNames(W[0-9]+)?\" ,col) is not None:\n",
    "                var_type.loc[col,\"type\"] = 7\n",
    "\n",
    "        # 8 - pano, electoratepcon, <party>sh10pcon, turnout10pcon, winnersh10pcon, runnerupsh10pcon, marginsh10pcon\n",
    "        # don't include 'runnerup10pcon', 'winner10pcon'- these are categorical!\n",
    "        # all relate to parliamentary constituency (pano applies to different waves - rest are about 2010 general election)\n",
    "            elif re.match( \"pano(W[0-9]+)?|electoratepcon|[a-zA-Z]+sh10pcon|turnout10pcon\" , col ) is not None:\n",
    "                var_type.loc[col,\"type\"] = 8\n",
    "\n",
    "            elif col in ['cciW1W2W3W4W5','ccinoITW1W2W3W4W5','justITW1W2W3W4W5','cciW6W7W8W9','ccinoITW6W7W8W9','justITW6W7W8W9']:\n",
    "                var_type.loc[col,\"type\"] = 9\n",
    "\n",
    "            # wave flags/weights (int and float)\n",
    "            elif re.match(\"wave[0-9]+|\"\\\n",
    "                          \"w[0-9]+core|\"\\\n",
    "                          \"w[0-9]+full|\"\\\n",
    "                          \"wt_daily_W[0-9]+|\"\\\n",
    "                          \"wt_core_W[0-9]+|\"\\\n",
    "                          \"wt_full_[W0-9]+|\"\\\n",
    "                          \"wt_new_[W0-9]+|\"\\\n",
    "                          \"CampaignDay(W[0-9]+)?|\"\\\n",
    "                          \"miilabelcertainty(W[0-9]+)?|\"\\\n",
    "                          \"Dailyweight(W[0-9]+)?|\"\\\n",
    "                          \"new_full_weight|\"\\\n",
    "                          \"w8_wave6_and_wave7|w8_wave2_and_wave6|w8_wave2_and_wave6_and_wave7|w8_wave9_to_wave13|\"\\\n",
    "                          \"wt_new_|\"\\\n",
    "                          \"wt|\"\\\n",
    "                          \"waves_taken\" , col) is not None: \n",
    "\n",
    "                var_type.loc[col,\"type\"] = -1\n",
    "\n",
    "            # waveX - wave int wave 0/1 flag\n",
    "            # wave 1-11: wt_full_W6, wt_core_W6, wt_full_W1W2W3W4W5W6W7W8W9), \n",
    "            # waves 10: wt_new_W10, wt_full_W1_W13\n",
    "            # CampaignDayWX\n",
    "            # miilabelcertaintyWX\n",
    "\n",
    "            else:\n",
    "                not_found = True\n",
    "                type_range = set(variable_categories[\"type\"].values)\n",
    "                for typ in type_range:\n",
    "                    pruned_variable_name = prune2( prune(col) )\n",
    "                    if pruned_variable_name in var_cat_dict_pruned_2[typ]:\n",
    "                        var_type.loc[col,\"type\"] = typ\n",
    "                        var_type.loc[col,\"pruned\"] = pruned_variable_name\n",
    "                        not_found = False\n",
    "\n",
    "            if not_found == True:\n",
    "                var_type.loc[col,\"type\"] = -99\n",
    "                pruned_variable_name = prune2( prune(col) )\n",
    "                var_type.loc[col,\"pruned\"] = pruned_variable_name\n",
    "                missing_col_names.append(col)\n",
    "    except Exception as e:\n",
    "        print(col, e)            \n",
    "\n",
    "    var_type[\"type\"] = var_type[\"type\"].astype(\"int8\")\n",
    "\n",
    "    # reset order of var_type rows to be same as BES_Panel\n",
    "    var_type = var_type.loc[BES_Panel.columns]\n",
    "\n",
    "    ####################################################\n",
    "\n",
    "    missing_col_names_cat_only = []\n",
    "\n",
    "    for col in missing_col_names:\n",
    "        if BES_Panel[col].dtypes.name == 'category':\n",
    "            missing_col_names_cat_only.append(col)\n",
    "\n",
    "    ####################################################\n",
    "\n",
    "    if missing_col_names:\n",
    "        updated_variable_categories = variable_categories.copy()\n",
    "        # question\tfrequency\tquestion_length\tquestion_options\tcolumn_name\ttype\n",
    "\n",
    "        for i in missing_col_names_cat_only:\n",
    "            str_list = [ str(cat) for cat in BES_Panel[i].cat.categories ]\n",
    "            joined_list = \"|\".join(str_list)\n",
    "            match  = (joined_list == updated_variable_categories[\"question\"])\n",
    "\n",
    "            if match.any(): # answer set already in records\n",
    "                index = updated_variable_categories[match].index\n",
    "                if len(index)>1: # answer set (\"question\") index should be unique!\n",
    "                    raise ValueError('answer set (\"question\") index should be unique!')\n",
    "\n",
    "                # add column name and increase frequency\n",
    "                updated_variable_categories.loc[index,\"frequency\"] = updated_variable_categories.loc[index,\"frequency\"]+1\n",
    "                current_list_col_names = updated_variable_categories.loc[index,\"column_name\"].values[0].split(\"|\")\n",
    "                current_list_col_names.append(i)\n",
    "                updated_variable_categories.loc[index,\"column_name\"] = \"|\".join( current_list_col_names )\n",
    "\n",
    "            else: # answer set not already in records - add new line to dataframe\n",
    "                df = pd.DataFrame([],  columns = updated_variable_categories.columns )\n",
    "\n",
    "                # no need to add index\n",
    "                # updated_variable_categories.shape[0], \n",
    "                df.loc[0] = [joined_list,\n",
    "                             1,\n",
    "                             len(joined_list),\n",
    "                             len(str_list),\n",
    "                             i,-99]\n",
    "                \n",
    "#                 df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "                updated_variable_categories = pd.concat( [updated_variable_categories,df], ignore_index = True  )\n",
    "#                 updated_variable_categories = updated_variable_categories.append(df, ignore_index=True)\n",
    "\n",
    "        variable_categories = updated_variable_categories\n",
    "        updated_variable_categories.to_csv(BES_small_data_files + \"question_categories_correct_updatesneeded!.csv\",\n",
    "                                           encoding = encoding )\n",
    "\n",
    "\n",
    "        display([x for x in zip(missing_col_names, BES_Panel[missing_col_names].dtypes)])\n",
    "\n",
    "        manual_fixing_advice_string = \"Stop - new variables detected\\n\"\\\n",
    "                                      \"Go look at question_categories_correct_updatesneeded!.csv\\n\"\\\n",
    "                                      \"fill in types, save as question_categories_correct.csv and rerun this code\"\n",
    "\n",
    "\n",
    "        raise Exception(manual_fixing_advice_string)\n",
    "    ####################################################\n",
    "\n",
    "    # [-5, -4, -3, -2, -1, 4, 7, 8, 9] -> meta list\n",
    "    # [0, 1, 2, 3, 5, 6] ->     \n",
    "    content_list = [0, 1, 2, 3, 5, 6]\n",
    "    meta_list = [-5, -4, -3, -2, -1, 7, 8, 9] # -99, 4 excluded because could be categorical\n",
    "    # 'numeric' columns (ones that can be transformed into numbers)\n",
    "    num_cols     = BES_Panel.columns[ (var_type[\"type\"].apply( lambda x: x in [0,1,2,3,5,6] )).values ]\n",
    "    # can't be transformed into numbers / are numbers but are meta-data rather than raw content (e.g. weights)\n",
    "    non_num_cols = BES_Panel.columns[ (var_type[\"type\"].apply( lambda x: x in [-99,-5,-4,-3,-1 ]  )).values ]\n",
    "\n",
    "    BES_numeric  = BES_Panel[num_cols].copy()\n",
    "    for col in BES_numeric:\n",
    "\n",
    "        if col not in var_type[\"type\"].index:\n",
    "            raise Exception( \"variable not registered - and somehow slipped past!\" )\n",
    "\n",
    "        if var_type.loc[ col, \"type\" ] in [0,7]:\n",
    "            continue\n",
    "\n",
    "        # force all category elements into strings\n",
    "        # ARE THEY EVER NOT?\n",
    "        BES_numeric[col].cat.rename_categories( BES_numeric[col].cat.categories.map(str), inplace=True )\n",
    "\n",
    "        join_list = \"|\".join( BES_numeric[col].cat.categories ) # create category_list_string \"strongly agree|agree|neither|...\"\n",
    "        var_type.loc[ col, \"original_cat_list\" ] = join_list    \n",
    "\n",
    "        # typos - things with weird characters\n",
    "        fixed_cat_string = fix_a_hat_chars( join_list )\n",
    "        if fixed_cat_string is not None:\n",
    "            var_type.loc[ col, \"typos\" ]   = join_list      \n",
    "            BES_numeric[col].cat.rename_categories( fixed_cat_string , inplace=True )\n",
    "            join_list = \"|\".join( BES_numeric[col].cat.categories )        \n",
    "\n",
    "        # rename categories\n",
    "        if join_list in rename_cat_dict.keys():\n",
    "            var_type.loc[ col, \"renamed_cat_list\" ]   = join_list        \n",
    "            BES_numeric[col].cat.rename_categories(  rename_cat_dict[join_list], inplace=True )\n",
    "            join_list = \"|\".join( BES_numeric[col].cat.categories )        \n",
    "\n",
    "        # reorder categories\n",
    "        if join_list in change_cat_dict.keys():\n",
    "            var_type.loc[ col, \"reordered_cat_list\" ] = join_list        \n",
    "            BES_numeric[col].cat.reorder_categories( change_cat_dict[join_list], inplace=True )\n",
    "            join_list = \"|\".join( BES_numeric[col].cat.categories )        \n",
    "\n",
    "        # remove \"Don't Know\"s that are in weird numerical form (eg. [ \"9999.0\", \"997.0\", \"222.0\", \"99.0\", \"0.0\" ])\n",
    "        # de_weasel numbers\n",
    "        numerical_dont_knows = de_weasel_nums( BES_numeric[col].cat.categories )\n",
    "        if len(numerical_dont_knows) != 0:\n",
    "            BES_numeric[col].cat.remove_categories( numerical_dont_knows , inplace=True )\n",
    "            var_type.loc[ col, \"numerical_dont_knows\" ] = \"|\".join( numerical_dont_knows )\n",
    "\n",
    "        # set all digits to floating point format, one decimal place\n",
    "        BES_numeric[col].cat.rename_categories( de_num( BES_numeric[col].cat.categories ), inplace=True )\n",
    "\n",
    "        # de_weasel\n",
    "        weasel_words = BES_numeric[col].cat.categories.intersection(Weasel_set)\n",
    "        if len(weasel_words) != 0:    \n",
    "            BES_numeric[col].cat.remove_categories( weasel_words, inplace=True )\n",
    "            var_type.loc[ col, \"weasel_words\" ] = \"|\".join( weasel_words )\n",
    "\n",
    "        # Laziness - I want an extra column with the destination category sets\n",
    "        # (should be a smaller set than original category sets)\n",
    "        var_type.loc[ col, \"final_cat_list\" ] = \"|\".join( BES_numeric[col].cat.categories )        \n",
    "    ####################################################\n",
    "\n",
    "    # save category data\n",
    "    cat_dictionary = {}\n",
    "    for col in BES_numeric.columns:\n",
    "        if var_type[\"type\"][col] in [1, 2, 3, 5]: # not just cat, but one not already numerical!\n",
    "            cat_dictionary[col] = BES_numeric[col].cat.categories\n",
    "\n",
    "\n",
    "    # turn categories into numbers\n",
    "    for col in BES_numeric:\n",
    "\n",
    "        if var_type[\"type\"][col] in [1,2,3,5]: # category type variables (other than indicators)\n",
    "            BES_numeric[col] = BES_numeric[col].cat.codes\n",
    "\n",
    "        if var_type[\"type\"][col] in [0,1,2,3,5,6,7]:\n",
    "            BES_numeric[col] = BES_numeric[col].astype('float64')\n",
    "\n",
    "    BES_numeric.replace(-1,np.nan, inplace=True) # replace -1 cat code for NaN with actual NaN - downside, requires dtype float\n",
    "    ####################################################\n",
    "\n",
    "    fname = data_subfolder + \"cat_dictionary.pkl\"\n",
    "    with open(fname, \"wb\") as f:\n",
    "        pickle.dump( cat_dictionary, f )\n",
    "\n",
    "    BES_non_numeric = BES_Panel[non_num_cols].copy()\n",
    "\n",
    "    BES_non_numeric.to_pickle( data_subfolder + \"BESnon_numeric.zip\", compression='zip' )\n",
    "\n",
    "    BES_numeric.to_pickle( data_subfolder + \"BESnumeric.zip\",  compression='zip' )\n",
    "\n",
    "    var_type.to_csv( data_subfolder + \"var_type.csv\", encoding = encoding )\n",
    "    # don't think the performance warning will be relevant on such a small dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# types\n",
    "# -99 - Uncategorised!\n",
    "# -5 - id\n",
    "# -4 - text\n",
    "# -3 - datetimes\n",
    "# -2 - ignore_list\n",
    "# -1 - weights/wave indicators/campaign day indicators/miilabeluncertainty\n",
    "# 0 - personality measures (in steps of .5?), personality_agreeableness ...etc, riskScale\n",
    "# 1 - linear category, just use  (some made linear by dropping \"Weasel_answers\")\n",
    "# 2 - categories need to be modified - order changed\n",
    "# 3 - set of non-ordered options\n",
    "# 4 - indirect variables - did someone fill something in in the free text box or not?\n",
    "# 5 - categories need to modified - things removed\n",
    "    # not so clear when this one applies - is it supposed to be whenever weasel words are removed?\n",
    "    # or when variables are *changed*\n",
    "# 6 - categories are integers - should maybe be transformed directly into numbers (mostly \"how much money do people need minimum/well off\"?)\n",
    "# 7 - soc2010(W3-6_comb,W5_only), v1(W5_comb), RandomIDW1(W3-6_comb), mapNames(W3_only), mapNamesW3 (W3-10_comb,W13_comb)        \n",
    "# 8 - pano, electoratepcon, <party>sh10pcon, turnout10pcon, winnersh10pcon, runnerupsh10pcon, marginsh10pcon\n",
    "#     all relate to parliamentary constituency (pano applies to different waves - rest are about 2010 general election)\n",
    "# 9 - 'cciW1W2W3W4W5','ccinoITW1W2W3W4W5','justITW1W2W3W4W5','cciW6W7W8W9','ccinoITW6W7W8W9','justITW6W7W8W9'\n",
    "#     floats - otherwise, no idea what these variables are!\n",
    "#     they are 0/1 - look like wave related indicator variables\n",
    "\n",
    "\n",
    "# [-5, -4, -3, -2, -1, 4, 7, 8, 9] -> meta list\n",
    "# [0, 1, 2, 3, 5, 6] -> \n",
    "\n",
    "# ordinal: 0, 1, 2, 5, 6\n",
    "# non-ordinal: 3, 7\n",
    "\n",
    "# load question_categories_correct.csv\n",
    "# sanity check by type!\n",
    "# turn into list of variables by type\n",
    "# 1, 5 handled the same way -> cat.codes\n",
    "# 6 -> int()\n",
    "# 4 ignored\n",
    "# 3 ignored for now (-> vectorized?)\n",
    "# 2 direct modification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../BES_analysis_data/W26_only\\\\BES2019_W26_v0.0.zip'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " data_subfolder + filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BES_Panel = hard_coded_fixes( dataset_name )\n",
    "# BES_Panel[col].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id\n",
      "wave\n",
      "weight\n",
      "turnoutUKGeneral\n",
      "generalElectionVote\n",
      "partyIdStrength\n",
      "partyId\n",
      "bestOnMII\n",
      "polAttention\n",
      "likeConLeader\n",
      "likeLabLeader\n",
      "likeLDLeader\n",
      "likePCLeader\n",
      "likeBrexitLeader\n",
      "likeSNPLeader\n",
      "likeCon\n",
      "likeLab\n",
      "likeLD\n",
      "likeSNP\n",
      "likePC\n",
      "likeBrexitParty\n",
      "econPersonalRetro\n",
      "econGenRetro\n",
      "riskPoverty\n",
      "riskUnemployment\n",
      "changeNHS\n",
      "EUIntegrationSelf\n",
      "EUIntegrationCon\n",
      "EUIntegrationLab\n",
      "EUIntegrationLD\n",
      "EUIntegrationSNP\n",
      "EUIntegrationPC\n",
      "immigEcon\n",
      "euRefVoteAfter\n",
      "redistSelf\n",
      "redistCon\n",
      "redistLab\n",
      "redistLD\n",
      "redistSNP\n",
      "redistPC\n",
      "enviroGrowth\n",
      "trustMPs\n",
      "immigSelf\n",
      "immigCon\n",
      "immigLab\n",
      "immigLD\n",
      "immigSNP\n",
      "immigPC\n",
      "britishness\n",
      "scottishness\n",
      "welshness\n",
      "englishness\n",
      "europeanness\n",
      "scotReferendumVote\n",
      "welshReferendumIntention\n",
      "approveUKGovt\n",
      "approveScotGovt\n",
      "approveWelshGovt\n",
      "dutyToVote2\n",
      "efficacyNotUnderstand\n",
      "efficacyPolCare\n",
      "subjClass\n",
      "speakWelsh\n",
      "ns_sec_analytic\n",
      "new_pcon\n",
      "small_mii_cat\n",
      "age\n",
      "gor\n",
      "pcon\n",
      "p_work_stat\n",
      "p_gross_household\n",
      "p_housing\n",
      "p_job_sector\n",
      "p_marital\n",
      "p_disability\n",
      "p_religion\n",
      "p_sexuality\n",
      "p_ethnicity\n",
      "p_edlevel\n",
      "lr_scale\n",
      "al_scale\n",
      "gender\n"
     ]
    },
    {
     "ename": "UnicodeEncodeError",
     "evalue": "'latin-1' codec can't encode character '\\u2013' in position 50: ordinal not in range(256)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[59], line 292\u001b[0m\n\u001b[0;32m    288\u001b[0m BES_non_numeric\u001b[38;5;241m.\u001b[39mto_pickle( data_subfolder \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBESnon_numeric.zip\u001b[39m\u001b[38;5;124m\"\u001b[39m, compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzip\u001b[39m\u001b[38;5;124m'\u001b[39m )\n\u001b[0;32m    290\u001b[0m BES_numeric\u001b[38;5;241m.\u001b[39mto_pickle( data_subfolder \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBESnumeric.zip\u001b[39m\u001b[38;5;124m\"\u001b[39m,  compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzip\u001b[39m\u001b[38;5;124m'\u001b[39m )\n\u001b[1;32m--> 292\u001b[0m \u001b[43mvar_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_subfolder\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvar_type.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[38;5;66;03m# don't think the performance warning will be relevant on such a small dataframe\u001b[39;00m\n",
      "File \u001b[1;32mE:\\Users\\Gamer\\anaconda3\\envs\\test_tensorflow_install\\lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    332\u001b[0m     )\n\u001b[1;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mE:\\Users\\Gamer\\anaconda3\\envs\\test_tensorflow_install\\lib\\site-packages\\pandas\\core\\generic.py:3967\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3956\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[0;32m   3958\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3959\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[0;32m   3960\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3964\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m   3965\u001b[0m )\n\u001b[1;32m-> 3967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3969\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3970\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3972\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3973\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3974\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3975\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3976\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3977\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3978\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3979\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3980\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3981\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3982\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3983\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3984\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mE:\\Users\\Gamer\\anaconda3\\envs\\test_tensorflow_install\\lib\\site-packages\\pandas\\io\\formats\\format.py:1014\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m    993\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    995\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[0;32m    996\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[0;32m    997\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[0;32m   1013\u001b[0m )\n\u001b[1;32m-> 1014\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1017\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32mE:\\Users\\Gamer\\anaconda3\\envs\\test_tensorflow_install\\lib\\site-packages\\pandas\\io\\formats\\csvs.py:270\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[0;32m    252\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilepath_or_buffer,\n\u001b[0;32m    253\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    258\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[0;32m    261\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[0;32m    262\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    267\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[0;32m    268\u001b[0m     )\n\u001b[1;32m--> 270\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mE:\\Users\\Gamer\\anaconda3\\envs\\test_tensorflow_install\\lib\\site-packages\\pandas\\io\\formats\\csvs.py:275\u001b[0m, in \u001b[0;36mCSVFormatter._save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_need_to_save_header:\n\u001b[0;32m    274\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_header()\n\u001b[1;32m--> 275\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mE:\\Users\\Gamer\\anaconda3\\envs\\test_tensorflow_install\\lib\\site-packages\\pandas\\io\\formats\\csvs.py:313\u001b[0m, in \u001b[0;36mCSVFormatter._save_body\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m start_i \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m end_i:\n\u001b[0;32m    312\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 313\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_i\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mE:\\Users\\Gamer\\anaconda3\\envs\\test_tensorflow_install\\lib\\site-packages\\pandas\\io\\formats\\csvs.py:324\u001b[0m, in \u001b[0;36mCSVFormatter._save_chunk\u001b[1;34m(self, start_i, end_i)\u001b[0m\n\u001b[0;32m    321\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(res\u001b[38;5;241m.\u001b[39m_iter_column_arrays())\n\u001b[0;32m    323\u001b[0m ix \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_index[slicer]\u001b[38;5;241m.\u001b[39m_get_values_for_csv(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_number_format)\n\u001b[1;32m--> 324\u001b[0m \u001b[43mlibwriters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_csv_rows\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    325\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    326\u001b[0m \u001b[43m    \u001b[49m\u001b[43mix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    327\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    328\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    329\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    330\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mwriters.pyx:76\u001b[0m, in \u001b[0;36mpandas._libs.writers.write_csv_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m: 'latin-1' codec can't encode character '\\u2013' in position 50: ordinal not in range(256)"
     ]
    }
   ],
   "source": [
    "dataset_name = 'W26_only'\n",
    "\n",
    "\n",
    "BES_file_manifest = pd.read_csv( BES_small_data_files + \"BES_file_manifest.csv\",encoding = \"ISO-8859-1\" )\n",
    "manifest = BES_file_manifest[ BES_file_manifest[\"Name\"] == dataset_name ]\n",
    "\n",
    "data_subfolder = BES_data_folder + dataset_name + os.sep\n",
    "\n",
    "filename = manifest[\"Stata_Filename\"].values[0]\n",
    "\n",
    "global BES_Panel\n",
    "if \".zip\" in filename:\n",
    "    BES_Panel = pd.read_pickle( data_subfolder + filename, compression='zip')\n",
    "else:\n",
    "    BES_Panel = pd.read_stata( data_subfolder + filename)\n",
    "####################################################\n",
    "\n",
    "# use this dataframe to store *everything* we're doing to transform/ignore variables!\n",
    "global var_type\n",
    "var_type = pd.DataFrame(columns = [\"dataset_name\",\"dtype\",\"cat_all_strings\",\"type\",\"pruned\",\"original_cat_list\",\n",
    "                                   \"renamed_cat_list\",\"reordered_cat_list\",\"final_cat_list\",\n",
    "                                   \"dataset_specific_hardcoded_fix\",\n",
    "                                   \"numerical_dont_knows\",\n",
    "                                   \"weasel_words\",\"typos\" ] )\n",
    "####################################################\n",
    "\n",
    "BES_Panel = hard_coded_fixes( dataset_name ) # side effects on BES_Panel and var_type\n",
    "number_and_string_sequences() # side effects on BES_Panel\n",
    "\n",
    "variable_categories = pd.read_csv( BES_small_data_files + \"question_categories_correct.csv\",\n",
    "                                   encoding = encoding,index_col=False )\n",
    "variable_categories.drop('Unnamed: 0', axis=1,inplace=True)\n",
    "\n",
    "( var_cat_dict_pruned , var_cat_dict_pruned_2 ) = create_var_list( variable_categories )\n",
    "####################################################\n",
    "\n",
    "missing_col_names = []\n",
    "try:\n",
    "    for col in BES_Panel.columns:\n",
    "        print(col)\n",
    "        dt =  BES_Panel[col].dtype.name # data type\n",
    "#         not_found = False\n",
    "\n",
    "        var_type.loc[col,\"dataset_name\"] = dataset_name\n",
    "        # dtype is either nan because not set -> set\n",
    "        if not isinstance(var_type.loc[col,\"dtype\"],str):\n",
    "            var_type.loc[ col , \"dtype\"] = dt    \n",
    "        # if dtype == category *and* cat_all_strings not already set, set\n",
    "        if (var_type.loc[ col , \"dtype\" ] == 'category') and careful_isnan( var_type.loc[ col , \"cat_all_strings\" ] ):\n",
    "            var_type.loc[ col , \"cat_all_strings\" ] = np.all([isinstance(x,str) for x in BES_Panel[ col ].cat.categories])\n",
    "\n",
    "        not_found = False      \n",
    "\n",
    "        if (col in ignore_list) or (var_type.loc[col,\"type\"] == -2): # exclude values from ignore_list *and manually coded errors*\n",
    "            var_type.loc[col,\"type\"] = -2\n",
    "            if var_type.loc[ col , \"cat_all_strings\" ]==True:\n",
    "                var_type.loc[ col, \"original_cat_list\" ] = \"|\".join( BES_Panel[col].cat.categories )\n",
    "            elif ('float' in dt) or ('int' in dt):\n",
    "                var_type.loc[ col, \"original_cat_list\" ] = list(BES_Panel[col].unique())\n",
    "\n",
    "        elif (col in [\"id\"] ): # id\n",
    "            var_type.loc[col,\"type\"] = -5\n",
    "\n",
    "        elif (dt == 'object'): # (probably) text\n",
    "            var_type.loc[col,\"type\"] = -4\n",
    "\n",
    "        elif (\"datetime\" in dt): # datetime\n",
    "            var_type.loc[col,\"type\"] = -3\n",
    "\n",
    "    # 0 - personality measures (in steps of .5?), personality_agreeableness ...etc, riskScaleW8        \n",
    "        elif (col in [\"personality_agreeableness\",\n",
    "                     \"personality_conscientiousness\",\n",
    "                     \"personality_extraversion\",\n",
    "                     \"personality_neuroticism\",\n",
    "                     \"personality_openness\"]) or (re.match(\"(cogempathy|affempathy|zeroSum)IRT\",col) is not None) or (re.match(\"riskScale(W[0-9]+)?\",col) is not None) :\n",
    "            \n",
    "            var_type.loc[col,\"type\"] = 0\n",
    "\n",
    "    # 7 - soc2010(W3-6_comb,W5_only), v1(W5_comb), RandomIDW1(W3-6_comb), mapNames(W3_only), mapNamesW3 (W3-10_comb,W13_comb)        \n",
    "        elif re.match(\"soc2010|v1|RandomIDW1|mapNames(W[0-9]+)?\" ,col) is not None:\n",
    "            var_type.loc[col,\"type\"] = 7\n",
    "\n",
    "    # 8 - pano, electoratepcon, <party>sh10pcon, turnout10pcon, winnersh10pcon, runnerupsh10pcon, marginsh10pcon\n",
    "    # don't include 'runnerup10pcon', 'winner10pcon'- these are categorical!\n",
    "    # all relate to parliamentary constituency (pano applies to different waves - rest are about 2010 general election)\n",
    "        elif re.match( \"pano(W[0-9]+)?|electoratepcon|[a-zA-Z]+sh10pcon|turnout10pcon\" , col ) is not None:\n",
    "            var_type.loc[col,\"type\"] = 8\n",
    "\n",
    "        elif col in ['cciW1W2W3W4W5','ccinoITW1W2W3W4W5','justITW1W2W3W4W5','cciW6W7W8W9','ccinoITW6W7W8W9','justITW6W7W8W9']:\n",
    "            var_type.loc[col,\"type\"] = 9\n",
    "\n",
    "        # wave flags/weights (int and float)\n",
    "        elif re.match(\"wave[0-9]+|\"\\\n",
    "                      \"w[0-9]+core|\"\\\n",
    "                      \"w[0-9]+full|\"\\\n",
    "                      \"wt_daily_W[0-9]+|\"\\\n",
    "                      \"wt_core_W[0-9]+|\"\\\n",
    "                      \"wt_full_[W0-9]+|\"\\\n",
    "                      \"wt_new_[W0-9]+|\"\\\n",
    "                      \"CampaignDay(W[0-9]+)?|\"\\\n",
    "                      \"miilabelcertainty(W[0-9]+)?|\"\\\n",
    "                      \"Dailyweight(W[0-9]+)?|\"\\\n",
    "                      \"new_full_weight|\"\\\n",
    "                      \"w8_wave6_and_wave7|w8_wave2_and_wave6|w8_wave2_and_wave6_and_wave7|w8_wave9_to_wave13|\"\\\n",
    "                      \"wt_new_|\"\\\n",
    "                      \"wt|\"\\\n",
    "                      \"waves_taken|wave|weight\" , col) is not None: \n",
    "\n",
    "            var_type.loc[col,\"type\"] = -1\n",
    "\n",
    "        # waveX - wave int wave 0/1 flag\n",
    "        # wave 1-11: wt_full_W6, wt_core_W6, wt_full_W1W2W3W4W5W6W7W8W9), \n",
    "        # waves 10: wt_new_W10, wt_full_W1_W13\n",
    "        # CampaignDayWX\n",
    "        # miilabelcertaintyWX\n",
    "\n",
    "        else:\n",
    "            not_found = True\n",
    "            type_range = set(variable_categories[\"type\"].values)\n",
    "            for typ in type_range:\n",
    "                pruned_variable_name = prune2( prune(col) )\n",
    "                if pruned_variable_name in var_cat_dict_pruned_2[typ]:\n",
    "                    var_type.loc[col,\"type\"] = typ\n",
    "                    var_type.loc[col,\"pruned\"] = pruned_variable_name\n",
    "                    not_found = False\n",
    "\n",
    "        if not_found == True:\n",
    "            var_type.loc[col,\"type\"] = -99\n",
    "            pruned_variable_name = prune2( prune(col) )\n",
    "            var_type.loc[col,\"pruned\"] = pruned_variable_name\n",
    "            missing_col_names.append(col)\n",
    "except Exception as e:\n",
    "    print(col, e)            \n",
    "\n",
    "var_type[\"type\"] = var_type[\"type\"].astype(\"int8\")\n",
    "\n",
    "# reset order of var_type rows to be same as BES_Panel\n",
    "var_type = var_type.loc[BES_Panel.columns]\n",
    "\n",
    "####################################################\n",
    "\n",
    "missing_col_names_cat_only = []\n",
    "\n",
    "for col in missing_col_names:\n",
    "    if BES_Panel[col].dtypes.name == 'category':\n",
    "        missing_col_names_cat_only.append(col)\n",
    "\n",
    "####################################################\n",
    "\n",
    "if missing_col_names:\n",
    "    updated_variable_categories = variable_categories.copy()\n",
    "    # question\tfrequency\tquestion_length\tquestion_options\tcolumn_name\ttype\n",
    "\n",
    "    for i in missing_col_names_cat_only:\n",
    "        str_list = [ str(cat) for cat in BES_Panel[i].cat.categories ]\n",
    "        joined_list = \"|\".join(str_list)\n",
    "        match  = (joined_list == updated_variable_categories[\"question\"])\n",
    "\n",
    "        if match.any(): # answer set already in records\n",
    "            index = updated_variable_categories[match].index\n",
    "            if len(index)>1: # answer set (\"question\") index should be unique!\n",
    "                raise ValueError('answer set (\"question\") index should be unique!')\n",
    "\n",
    "            # add column name and increase frequency\n",
    "            updated_variable_categories.loc[index,\"frequency\"] = updated_variable_categories.loc[index,\"frequency\"]+1\n",
    "            current_list_col_names = updated_variable_categories.loc[index,\"column_name\"].values[0].split(\"|\")\n",
    "            current_list_col_names.append(i)\n",
    "            updated_variable_categories.loc[index,\"column_name\"] = \"|\".join( current_list_col_names )\n",
    "\n",
    "        else: # answer set not already in records - add new line to dataframe\n",
    "            df = pd.DataFrame([],  columns = updated_variable_categories.columns )\n",
    "\n",
    "            # no need to add index\n",
    "            # updated_variable_categories.shape[0], \n",
    "            df.loc[0] = [joined_list,\n",
    "                         1,\n",
    "                         len(joined_list),\n",
    "                         len(str_list),\n",
    "                         i,-99]\n",
    "#             updated_variable_categories = updated_variable_categories.append(df, ignore_index=True)\n",
    "            updated_variable_categories = pd.concat( [updated_variable_categories,df], ignore_index = True  )\n",
    "\n",
    "    variable_categories = updated_variable_categories\n",
    "    updated_variable_categories.to_csv(BES_small_data_files + \"question_categories_correct_updatesneeded!.csv\",\n",
    "                                       encoding = encoding )\n",
    "\n",
    "\n",
    "    display([x for x in zip(missing_col_names, BES_Panel[missing_col_names].dtypes)])\n",
    "\n",
    "    manual_fixing_advice_string = \"Stop - new variables detected\\n\"\\\n",
    "                                  \"Go look at question_categories_correct_updatesneeded!.csv\\n\"\\\n",
    "                                  \"fill in types, save as question_categories_correct.csv and rerun this code\"\n",
    "\n",
    "\n",
    "    raise Exception(manual_fixing_advice_string)\n",
    "####################################################\n",
    "\n",
    "# [-5, -4, -3, -2, -1, 4, 7, 8, 9] -> meta list\n",
    "# [0, 1, 2, 3, 5, 6] ->     \n",
    "content_list = [0, 1, 2, 3, 5, 6]\n",
    "meta_list = [-5, -4, -3, -2, -1, 7, 8, 9] # -99, 4 excluded because could be categorical\n",
    "# 'numeric' columns (ones that can be transformed into numbers)\n",
    "num_cols     = BES_Panel.columns[ (var_type[\"type\"].apply( lambda x: x in [0,1,2,3,5,6] )).values ]\n",
    "# can't be transformed into numbers / are numbers but are meta-data rather than raw content (e.g. weights)\n",
    "non_num_cols = BES_Panel.columns[ (var_type[\"type\"].apply( lambda x: x in [-99,-5,-4,-3,-1 ]  )).values ]\n",
    "\n",
    "BES_numeric  = BES_Panel[num_cols].copy()\n",
    "for col in BES_numeric:\n",
    "\n",
    "    if col not in var_type[\"type\"].index:\n",
    "        raise Exception( \"variable not registered - and somehow slipped past!\" )\n",
    "\n",
    "    if var_type.loc[ col, \"type\" ] in [0,7]:\n",
    "        continue\n",
    "\n",
    "    # force all category elements into strings\n",
    "    # ARE THEY EVER NOT?\n",
    "    BES_numeric[col] = BES_numeric[col].cat.rename_categories( BES_numeric[col].cat.categories.map(str) )\n",
    "\n",
    "    join_list = \"|\".join( BES_numeric[col].cat.categories ) # create category_list_string \"strongly agree|agree|neither|...\"\n",
    "    var_type.loc[ col, \"original_cat_list\" ] = join_list    \n",
    "\n",
    "    # typos - things with weird characters\n",
    "    fixed_cat_string = fix_a_hat_chars( join_list )\n",
    "    if fixed_cat_string is not None:\n",
    "        var_type.loc[ col, \"typos\" ]   = join_list      \n",
    "        BES_numeric[col] = BES_numeric[col].cat.rename_categories( fixed_cat_string )\n",
    "        join_list = \"|\".join( BES_numeric[col].cat.categories )        \n",
    "\n",
    "    # rename categories\n",
    "    if join_list in rename_cat_dict.keys():\n",
    "        var_type.loc[ col, \"renamed_cat_list\" ]   = join_list        \n",
    "        BES_numeric[col] = BES_numeric[col].cat.rename_categories(  rename_cat_dict[join_list] )\n",
    "        join_list = \"|\".join( BES_numeric[col].cat.categories )        \n",
    "\n",
    "    # reorder categories\n",
    "    if join_list in change_cat_dict.keys():\n",
    "        var_type.loc[ col, \"reordered_cat_list\" ] = join_list        \n",
    "        BES_numeric[col] = BES_numeric[col].cat.reorder_categories( change_cat_dict[join_list] )\n",
    "        join_list = \"|\".join( BES_numeric[col].cat.categories )        \n",
    "\n",
    "    # remove \"Don't Know\"s that are in weird numerical form (eg. [ \"9999.0\", \"997.0\", \"222.0\", \"99.0\", \"0.0\" ])\n",
    "    # de_weasel numbers\n",
    "    numerical_dont_knows = de_weasel_nums( BES_numeric[col].cat.categories )\n",
    "    if len(numerical_dont_knows) != 0:\n",
    "        BES_numeric[col] = BES_numeric[col].cat.remove_categories( numerical_dont_knows )\n",
    "        var_type.loc[ col, \"numerical_dont_knows\" ] = \"|\".join( numerical_dont_knows )\n",
    "\n",
    "    # set all digits to floating point format, one decimal place\n",
    "    BES_numeric[col] = BES_numeric[col].cat.rename_categories( de_num( BES_numeric[col].cat.categories ) )\n",
    "\n",
    "    # de_weasel\n",
    "    weasel_words = BES_numeric[col].cat.categories.intersection(Weasel_set)\n",
    "    if len(weasel_words) != 0:    \n",
    "        BES_numeric[col] = BES_numeric[col].cat.remove_categories( weasel_words )\n",
    "        var_type.loc[ col, \"weasel_words\" ] = \"|\".join( weasel_words )\n",
    "\n",
    "    # Laziness - I want an extra column with the destination category sets\n",
    "    # (should be a smaller set than original category sets)\n",
    "    var_type.loc[ col, \"final_cat_list\" ] = \"|\".join( BES_numeric[col].cat.categories )        \n",
    "####################################################\n",
    "\n",
    "# save category data\n",
    "cat_dictionary = {}\n",
    "for col in BES_numeric.columns:\n",
    "    if var_type[\"type\"][col] in [1, 2, 3, 5]: # not just cat, but one not already numerical!\n",
    "        cat_dictionary[col] = BES_numeric[col].cat.categories\n",
    "\n",
    "\n",
    "# turn categories into numbers\n",
    "for col in BES_numeric:\n",
    "\n",
    "    if var_type[\"type\"][col] in [1,2,3,5]: # category type variables (other than indicators)\n",
    "        BES_numeric[col] = BES_numeric[col].cat.codes\n",
    "\n",
    "    if var_type[\"type\"][col] in [0,1,2,3,5,6,7]:\n",
    "        BES_numeric[col] = BES_numeric[col].astype('float64')\n",
    "\n",
    "BES_numeric.replace(-1,np.nan, inplace=True) # replace -1 cat code for NaN with actual NaN - downside, requires dtype float\n",
    "####################################################\n",
    "\n",
    "fname = data_subfolder + \"cat_dictionary.pkl\"\n",
    "with open(fname, \"wb\") as f:\n",
    "    pickle.dump( cat_dictionary, f )\n",
    "\n",
    "BES_non_numeric = BES_Panel[non_num_cols].copy()\n",
    "\n",
    "BES_non_numeric.to_pickle( data_subfolder + \"BESnon_numeric.zip\", compression='zip' )\n",
    "\n",
    "BES_numeric.to_pickle( data_subfolder + \"BESnumeric.zip\",  compression='zip' )\n",
    "\n",
    "var_type.to_csv( data_subfolder + \"var_type.csv\", encoding = encoding )\n",
    "# don't think the performance warning will be relevant on such a small dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[1;32me:\\users\\gamer\\documents\\github\\bes_analysis\\bes_analysis_code\\writers.pyx\u001b[0m(76)\u001b[0;36mpandas._libs.writers.write_csv_rows\u001b[1;34m()\u001b[0m\n",
      "\n",
      "ipdb> data\n",
      "*** NameError: name 'data' is not defined\n",
      "ipdb> up\n",
      "> \u001b[1;32me:\\users\\gamer\\anaconda3\\envs\\test_tensorflow_install\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m(324)\u001b[0;36m_save_chunk\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m    322 \u001b[1;33m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m    323 \u001b[1;33m        \u001b[0mix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_index\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mslicer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_values_for_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_number_format\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m--> 324 \u001b[1;33m        libwriters.write_csv_rows(\n",
      "\u001b[0m\u001b[1;32m    325 \u001b[1;33m            \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m    326 \u001b[1;33m            \u001b[0mix\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> data\n",
      "[array(['W26_only', 'W26_only', 'W26_only', 'W26_only', 'W26_only',\n",
      "       'W26_only', 'W26_only', 'W26_only', 'W26_only', 'W26_only',\n",
      "       'W26_only', 'W26_only', 'W26_only', 'W26_only', 'W26_only',\n",
      "       'W26_only', 'W26_only', 'W26_only', 'W26_only', 'W26_only',\n",
      "       'W26_only', 'W26_only', 'W26_only', 'W26_only', 'W26_only',\n",
      "       'W26_only', 'W26_only', 'W26_only', 'W26_only', 'W26_only',\n",
      "       'W26_only', 'W26_only', 'W26_only', 'W26_only', 'W26_only',\n",
      "       'W26_only', 'W26_only', 'W26_only', 'W26_only', 'W26_only',\n",
      "       'W26_only', 'W26_only', 'W26_only', 'W26_only', 'W26_only',\n",
      "       'W26_only', 'W26_only', 'W26_only', 'W26_only', 'W26_only',\n",
      "       'W26_only', 'W26_only', 'W26_only', 'W26_only', 'W26_only',\n",
      "       'W26_only', 'W26_only', 'W26_only', 'W26_only', 'W26_only',\n",
      "       'W26_only', 'W26_only', 'W26_only', 'W26_only', 'W26_only',\n",
      "       'W26_only', 'W26_only', 'W26_only', 'W26_only', 'W26_only',\n",
      "       'W26_only', 'W26_only', 'W26_only', 'W26_only', 'W26_only',\n",
      "       'W26_only', 'W26_only', 'W26_only', 'W26_only', 'W26_only',\n",
      "       'W26_only', 'W26_only'], dtype=object), array(['int32', 'int8', 'float64', 'category', 'category', 'category',\n",
      "       'category', 'category', 'category', 'category', 'category',\n",
      "       'category', 'category', 'category', 'category', 'category',\n",
      "       'category', 'category', 'category', 'category', 'category',\n",
      "       'category', 'category', 'category', 'category', 'category',\n",
      "       'category', 'category', 'category', 'category', 'category',\n",
      "       'category', 'category', 'category', 'category', 'category',\n",
      "       'category', 'category', 'category', 'category', 'category',\n",
      "       'category', 'category', 'category', 'category', 'category',\n",
      "       'category', 'category', 'category', 'category', 'category',\n",
      "       'category', 'category', 'category', 'category', 'category',\n",
      "       'category', 'category', 'category', 'category', 'category',\n",
      "       'category', 'category', 'category', 'category', 'category',\n",
      "       'category', 'category', 'category', 'category', 'category',\n",
      "       'category', 'category', 'category', 'category', 'category',\n",
      "       'category', 'category', 'category', 'category', 'category',\n",
      "       'category'], dtype=object), array(['', '', '', True, True, True, True, True, True, True, True, True,\n",
      "       True, True, True, True, True, True, True, True, True, True, True,\n",
      "       True, True, True, True, True, True, True, True, True, True, True,\n",
      "       True, True, True, True, True, True, True, True, True, True, True,\n",
      "       True, True, True, True, True, True, True, True, True, True, True,\n",
      "       True, True, True, True, True, True, True, True, True, True, False,\n",
      "       True, True, True, True, True, False, True, True, False, True, True,\n",
      "       True, False, False, True], dtype=object), array([-5, -1, -1, 1, 3, 1, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 3, 3,\n",
      "       3, 6, 3, 3, 3, 2, 3, 3, 3, 1, 3, 3, 3, 1, 1, 1, 1], dtype=object), array(['', '', '', 'turnoutUKGeneral', 'generalElectionVote',\n",
      "       'partyIdStrength', 'partyId', 'bestOnMII', 'polAttention',\n",
      "       'likeConLeader', 'likeLabLeader', 'likeLDLeader', 'likePCLeader',\n",
      "       'likeBrexitLeader', 'likeSNPLeader', 'likeCon', 'likeLab',\n",
      "       'likeLD', 'likeSNP', 'likePC', 'likeBrexitParty',\n",
      "       'econPersonalRetro', 'econGenRetro', 'riskPoverty',\n",
      "       'riskUnemployment', 'changeNHS', 'EUIntegrationSelf',\n",
      "       'EUIntegrationCon', 'EUIntegrationLab', 'EUIntegrationLD',\n",
      "       'EUIntegrationSNP', 'EUIntegrationPC', 'immigEcon',\n",
      "       'euRefVoteAfter', 'redistSelf', 'redistCon', 'redistLab',\n",
      "       'redistLD', 'redistSNP', 'redistPC', 'enviroGrowth', 'trustMPs',\n",
      "       'immigSelf', 'immigCon', 'immigLab', 'immigLD', 'immigSNP',\n",
      "       'immigPC', 'britishness', 'scottishness', 'welshness',\n",
      "       'englishness', 'europeanness', 'scotReferendumVote',\n",
      "       'welshReferendumIntention', 'approveUKGovt', 'approveScotGovt',\n",
      "       'approveWelshGovt', 'dutyToVote', 'efficacyNotUnderstand',\n",
      "       'efficacyPolCare', 'subjClass', 'speakWelsh', 'ns_sec_analytic',\n",
      "       'new_pcon', 'small_mii_cat', 'age', 'gor', 'pcon', 'p_work_stat',\n",
      "       'p_gross_household', 'p_housing', 'p_job_sector', 'p_marital',\n",
      "       'p_disability', 'p_religion', 'p_sexuality', 'p_ethnicity',\n",
      "       'p_edlevel', 'lr_scale', 'al_scale', 'gender'], dtype=object), array(['', '', '',\n",
      "       \"Very unlikely that I would vote|Fairly unlikely|Neither likely nor unlikely|Fairly likely|Very likely that I would vote|Don't know\",\n",
      "       \"I would/did not vote|Conservative|Labour|Liberal Democrat|Scottish National Party (SNP)|Plaid Cymru|United Kingdom Independence Party (UKIP)|Green Party|British National Party (BNP)|Other|Change UK- The Independent Group|Brexit Party/Reform UK|An independent candidate|Don't know\",\n",
      "       \"Very strong|Fairly strong|Not very strong|Don't know\",\n",
      "       \"Conservative|Labour|Liberal Democrat|Scottish National Party (SNP)|Plaid Cymru|United Kingdom Independence Party (UKIP)|Green Party|British National Party (BNP)|Other|No - none|Change UK- The Independent Group|Brexit Party/Reform UK|Don't know\",\n",
      "       \"No party is best able to handle this issue|Conservative|Labour|Liberal Democrat|Scottish National Party (SNP)|Plaid Cymru|United Kingdom Independence Party (UKIP)|Green Party|British National Party (BNP)|Other party|Change UK- The Independent Group|Brexit Party/Reform UK|Don't know\",\n",
      "       \"Pay no attention|1|2|3|4|5|6|7|8|9|Pay a great deal of attention|Don't know\",\n",
      "       \"Strongly dislike|1|2|3|4|5|6|7|8|9|Strongly like|Don't know\",\n",
      "       \"Strongly dislike|1|2|3|4|5|6|7|8|9|Strongly like|Don't know\",\n",
      "       \"Strongly dislike|1|2|3|4|5|6|7|8|9|Strongly like|Don't know\",\n",
      "       \"Strongly dislike|1|2|3|4|5|6|7|8|9|Strongly like|Don't know\",\n",
      "       \"Strongly dislike|1|2|3|4|5|6|7|8|9|Strongly like|Don't know\",\n",
      "       \"Strongly dislike|1|2|3|4|5|6|7|8|9|Strongly like|Don't know\",\n",
      "       \"Strongly dislike|1|2|3|4|5|6|7|8|9|Strongly like|Don't know\",\n",
      "       \"Strongly dislike|1|2|3|4|5|6|7|8|9|Strongly like|Don't know\",\n",
      "       \"Strongly dislike|1|2|3|4|5|6|7|8|9|Strongly like|Don't know\",\n",
      "       \"Strongly dislike|1|2|3|4|5|6|7|8|9|Strongly like|Don't know\",\n",
      "       \"Strongly dislike|1|2|3|4|5|6|7|8|9|Strongly like|Don't know\",\n",
      "       \"Strongly dislike|1|2|3|4|5|6|7|8|9|Strongly like|Don't know\",\n",
      "       \"Got a lot worse|Got a little worse|Stayed the same|Got a little better|Got a lot better|Don't know\",\n",
      "       \"Got a lot worse|Got a little worse|Stayed the same|Got a little better|Got a lot better|Don't know\",\n",
      "       \"Very unlikely|Fairly unlikely|Neither likely nor unlikely|Fairly likely|Very likely|Don't know\",\n",
      "       \"Very unlikely|Fairly unlikely|Neither likely nor unlikely|Fairly likely|Very likely|Don't know\",\n",
      "       \"Getting a lot worse|Getting a little worse|Staying about the same|Getting a little better|Getting a lot better|Don't know\",\n",
      "       \"Unite fully with the European Union|1|2|3|4|5|6|7|8|9|Protect our independence|Don't know\",\n",
      "       \"Unite fully with the European Union|1|2|3|4|5|6|7|8|9|Protect our independence|Don't know\",\n",
      "       \"Unite fully with the European Union|1|2|3|4|5|6|7|8|9|Protect our independence|Don't know\",\n",
      "       \"Unite fully with the European Union|1|2|3|4|5|6|7|8|9|Protect our independence|Don't know\",\n",
      "       \"Unite fully with the European Union|1|2|3|4|5|6|7|8|9|Protect our independence|Don't know\",\n",
      "       \"Unite fully with the European Union|1|2|3|4|5|6|7|8|9|Protect our independence|Don't know\",\n",
      "       \"Bad for economy|2|3|4|5|6|Good for economy|Don't know\",\n",
      "       \"Rejoin the EU|Stay out of the EU|I would not vote|Don't know\",\n",
      "       \"Government should try to make incomes equal|1|2|3|4|5|6|7|8|9|Government should be less concerned about equal incomes|Don't know\",\n",
      "       \"Government should try to make incomes equal|1|2|3|4|5|6|7|8|9|Government should be less concerned about equal incomes|Don't know\",\n",
      "       \"Government should try to make incomes equal|1|2|3|4|5|6|7|8|9|Government should be less concerned about equal incomes|Don't know\",\n",
      "       \"Government should try to make incomes equal|1|2|3|4|5|6|7|8|9|Government should be less concerned about equal incomes|Don't know\",\n",
      "       \"Government should try to make incomes equal|1|2|3|4|5|6|7|8|9|Government should be less concerned about equal incomes|Don't know\",\n",
      "       \"Government should try to make incomes equal|1|2|3|4|5|6|7|8|9|Government should be less concerned about equal incomes|Don't know\",\n",
      "       \"Economic growth should have priority|1|2|3|4|5|6|7|8|9|Protecting the environment should have priority|Don't know\",\n",
      "       \"No trust|2|3|4|5|6|A great deal of trust|Don't know\",\n",
      "       \"Allow many fewer|1|2|3|4|5|6|7|8|9|Allow many more|Don't know\",\n",
      "       \"Allow many fewer|1|2|3|4|5|6|7|8|9|Allow many more|Don't know\",\n",
      "       \"Allow many fewer|1|2|3|4|5|6|7|8|9|Allow many more|Don't know\",\n",
      "       \"Allow many fewer|1|2|3|4|5|6|7|8|9|Allow many more|Don't know\",\n",
      "       \"Allow many fewer|1|2|3|4|5|6|7|8|9|Allow many more|Don't know\",\n",
      "       \"Allow many fewer|1|2|3|4|5|6|7|8|9|Allow many more|Don't know\",\n",
      "       \"Not at all British|2|3|4|5|6|Very strongly British|Don't know\",\n",
      "       \"Not at all Scottish|2|3|4|5|6|Very strongly Scottish|Don't know\",\n",
      "       \"Not at all Welsh|2|3|4|5|6|Very strongly Welsh|Don't know\",\n",
      "       \"Not at all English|2|3|4|5|6|Very strongly English|Don't know\",\n",
      "       \"Not at all European|2|3|4|5|6|Very strongly European|Don't know\",\n",
      "       \"I would vote 'No' (stay in the UK)|I would vote 'Yes' (leave the UK)|Would not vote|Don't know\",\n",
      "       \"Will vote no|Will vote 'Yes'|Will not vote|Don't know\",\n",
      "       \"Strongly disapprove|Disapprove|Neither approve nor disapprove|Approve|Strongly approve|Don't know\",\n",
      "       \"Strongly disapprove|Disapprove|Neither approve nor disapprove|Approve|Strongly approve|Don't know\",\n",
      "       \"Strongly disapprove|Disapprove|Neither approve nor disapprove|Approve|Strongly approve|Don't know\",\n",
      "       \"Strongly disagree|Disagree|Neither agree nor disagree|Agree|Strongly agree|Don't know\",\n",
      "       \"Strongly disagree|Disagree|Neither agree nor disagree|Agree|Strongly agree|Don't know\",\n",
      "       \"Strongly disagree|Disagree|Neither agree nor disagree|Agree|Strongly agree|Don't know\",\n",
      "       \"No|Yes, middle class|Yes, working class|Yes, other|Don't know\",\n",
      "       \"No|Yes, but not fluently|Yes, fluently|Don't know\",\n",
      "       'Employers in large organisations and higher managerial|Higher professional occupations|Lower professional and managerial and higher supervisory|Intermediate occupations|Employers in small organisations and own account workers|Lower supervisory and technical occupations|Semi-routine occupations|Routine occupations',\n",
      "       \"Aberafan Maesteg|Aberdeen North|Aberdeen South|Aberdeenshire North and Moray East|Airdrie and Shotts|Aldershot|Aldridge-Brownhills|Alloa and Grangemouth|Altrincham and Sale West|Alyn and Deeside|Amber Valley|Angus and Perthshire Glens|Arbroath and Broughty Ferry|Argyll, Bute and South Lochaber|Arundel and South Downs|Ashfield|Ashford|Ashton-under-Lyne|Aylesbury|Ayr, Carrick and Cumnock|Banbury|Bangor Aberconwy|Barking|Barnsley North|Barnsley South|Barrow and Furness|Basildon and Billericay|Basingstoke|Bassetlaw|Bath|Bathgate and Linlithgow|Battersea|Beaconsfield|Beckenham and Penge|Bedford|Bermondsey and Old Southwark|Berwickshire, Roxburgh and Selkirk|Bethnal Green and Stepney|Beverley and Holderness|Bexhill and Battle|Bexleyheath and Crayford|Bicester and Woodstock|Birkenhead|Birmingham Edgbaston|Birmingham Erdington|Birmingham Hall Green and Moseley|Birmingham Hodge Hill and Solihull North|Birmingham Ladywood|Birmingham Northfield|Birmingham Perry Barr|Birmingham Selly Oak|Birmingham Yardley|Bishop Auckland|Blackburn|Blackley and Middleton South|Blackpool North and Fleetwood|Blackpool South|Blaenau Gwent and Rhymney|Blaydon and Consett|Blyth and Ashington|Bognor Regis and Littlehampton|Bolsover|Bolton North East|Bolton South and Walkden|Bolton West|Bootle|Boston and Skegness|Bournemouth East|Bournemouth West|Bracknell|Bradford East|Bradford South|Bradford West|Braintree|Brecon, Radnor and Cwm Tawe|Brent East|Brent West|Brentford and Isleworth|Brentwood and Ongar|Bridgend|Bridgwater|Bridlington and The Wolds|Brigg and Immingham|Brighton Kemptown and Peacehaven|Brighton Pavilion|Bristol Central|Bristol East|Bristol North East|Bristol North West|Bristol South|Broadland and Fakenham|Bromley and Biggin Hill|Bromsgrove|Broxbourne|Broxtowe|Buckingham and Bletchley|Burnley|Burton and Uttoxeter|Bury North|Bury South|Bury St Edmunds and Stowmarket|Caerfyrddin|Caerphilly|Caithness, Sutherland and Easter Ross|Calder Valley|Camborne and Redruth|Cambridge|Cannock Chase|Canterbury|Cardiff East|Cardiff North|Cardiff South and Penarth|Cardiff West|Carlisle|Carshalton and Wallington|Castle Point|Central Ayrshire|Central Devon|Central Suffolk and North Ipswich|Ceredigion Preseli|Chatham and Aylesford|Cheadle|Chelmsford|Chelsea and Fulham|Cheltenham|Chesham and Amersham|Chester North and Neston|Chester South and Eddisbury|Chesterfield|Chichester|Chingford and Woodford Green|Chippenham|Chipping Barnet|Chorley|Christchurch|Cities of London and Westminster|City of Durham|Clacton|Clapham and Brixton Hill|Clwyd East|Clwyd North|Coatbridge and Bellshill|Colchester|Colne Valley|Congleton|Corby and East Northamptonshire|Coventry East|Coventry North West|Coventry South|Cowdenbeath and Kirkcaldy|Cramlington and Killingworth|Crawley|Crewe and Nantwich|Croydon East|Croydon South|Croydon West|Cumbernauld and Kirkintilloch|Dagenham and Rainham|Darlington|Dartford|Daventry|Derby North|Derby South|Derbyshire Dales|Dewsbury and Batley|Didcot and Wantage|Doncaster Central|Doncaster East and the Isle of Axholme|Doncaster North|Dorking and Horley|Dover and Deal|Droitwich and Evesham|Dudley|Dulwich and West Norwood|Dumfries and Galloway|Dumfriesshire, Clydesdale and Tweeddale|Dundee Central|Dunfermline and Dollar|Dunstable and Leighton Buzzard|Dwyfor Meirionnydd|Ealing Central and Acton|Ealing North|Ealing Southall|Earley and Woodley|Easington|East Grinstead and Uckfield|East Ham|East Hampshire|East Kilbride and Strathaven|East Renfrewshire|East Surrey|East Thanet|East Wiltshire|East Worthing and Shoreham|Eastbourne|Eastleigh|Edinburgh East and Musselburgh|Edinburgh North and Leith|Edinburgh South|Edinburgh South West|Edinburgh West|Edmonton and Winchmore Hill|Ellesmere Port and Bromborough|Eltham and Chislehurst|Ely and East Cambridgeshire|Enfield North|Epping Forest|Epsom and Ewell|Erewash|Erith and Thamesmead|Esher and Walton|Exeter|Exmouth and Exeter East|Falkirk|Fareham and Waterlooville|Farnham and Bordon|Faversham and Mid Kent|Feltham and Heston|Filton and Bradley Stoke|Finchley and Golders Green|Folkestone and Hythe|Forest of Dean|Frome and East Somerset|Fylde|Gainsborough|Gateshead Central and Whickham|Gedling|Gillingham and Rainham|Glasgow East|Glasgow North|Glasgow North East|Glasgow South|Glasgow South West|Glasgow West|Glastonbury and Somerton|Glenrothes and Mid Fife|Gloucester|Godalming and Ash|Goole and Pocklington|Gordon and Buchan|Gorton and Denton|Gosport|Gower|Grantham and Bourne|Gravesham|Great Grimsby and Cleethorpes|Great Yarmouth|Greenwich and Woolwich|Guildford|Hackney North and Stoke Newington|Hackney South and Shoreditch|Halesowen|Halifax|Hamble Valley|Hamilton and Clyde Valley|Hammersmith and Chiswick|Hampstead and Highgate|Harborough, Oadby and Wigston|Harlow|Harpenden and Berkhamsted|Harrogate and Knaresborough|Harrow East|Harrow West|Hartlepool|Harwich and North Essex|Hastings and Rye|Havant|Hayes and Harlington|Hazel Grove|Hemel Hempstead|Hendon|Henley and Thame|Hereford and South Herefordshire|Herne Bay and Sandwich|Hertford and Stortford|Hertsmere|Hexham|Heywood and Middleton North|High Peak|Hinckley and Bosworth|Hitchin|Holborn and St Pancras|Honiton and Sidmouth|Hornchurch and Upminster|Hornsey and Friern Barnet|Horsham|Houghton and Sunderland South|Hove and Portslade|Huddersfield|Huntingdon|Hyndburn|Ilford North|Ilford South|Inverclyde and Renfrewshire West|Inverness, Skye and West Ross-shire|Ipswich|Isle of Wight East|Isle of Wight West|Islington North|Islington South and Finsbury|Jarrow and Gateshead East|Keighley and Ilkley|Kenilworth and Southam|Kensington and Bayswater|Kettering|Kilmarnock and Loudoun|Kingston and Surbiton|Kingston upon Hull East|Kingston upon Hull North and Cottingham|Kingston upon Hull West and Haltemprice|Kingswinford and South Staffordshire|Knowsley|Lancaster and Wyre|Leeds Central and Headingley|Leeds East|Leeds North East|Leeds North West|Leeds South|Leeds South West and Morley|Leeds West and Pudsey|Leicester East|Leicester South|Leicester West|Leigh and Atherton|Lewes|Lewisham East|Lewisham North|Lewisham West and East Dulwich|Leyton and Wanstead|Lichfield|Lincoln|Liverpool Garston|Liverpool Riverside|Liverpool Walton|Liverpool Wavertree|Liverpool West Derby|Livingston|Llanelli|Lothian East|Loughborough|Louth and Horncastle|Lowestoft|Luton North|Luton South and South Bedfordshire|Macclesfield|Maidenhead|Maidstone and Malling|Makerfield|Maldon|Manchester Central|Manchester Rusholme|Manchester Withington|Mansfield|Melksham and Devizes|Melton and Syston|Meriden and Solihull East|Merthyr Tydfil and Aberdare|Mid and South Pembrokeshire|Mid Bedfordshire|Mid Buckinghamshire|Mid Cheshire|Mid Derbyshire|Mid Dorset and North Poole|Mid Dunbartonshire|Mid Leicestershire|Mid Norfolk|Mid Sussex|Middlesbrough and Thornaby East|Middlesbrough South and East Cleveland|Midlothian|Milton Keynes Central|Milton Keynes North|Mitcham and Morden|Monmouthshire|Montgomeryshire and Glyndwr|Moray West, Nairn and Strathspey|Morecambe and Lunesdale|Motherwell, Wishaw and Carluke|Na h-Eileanan an Iar|Neath and Swansea East|New Forest East|New Forest West|Newark|Newbury|Newcastle upon Tyne Central and West|Newcastle upon Tyne East and Wallsend|Newcastle upon Tyne North|Newcastle-under-Lyme|Newport East|Newport West and Islwyn|Newton Abbot|Newton Aycliffe and Spennymoor|Normanton and Hemsworth|North Ayrshire and Arran|North Bedfordshire|North Cornwall|North Cotswolds|North Devon|North Dorset|North Durham|North East Cambridgeshire|North East Derbyshire|North East Fife|North East Hampshire|North East Hertfordshire|North East Somerset and Hanham|North Herefordshire|North Norfolk|North Northumberland|North Shropshire|North Somerset|North Warwickshire and Bedworth|North West Cambridgeshire|North West Essex|North West Hampshire|North West Leicestershire|North West Norfolk|Northampton North|Northampton South|Norwich North|Norwich South|Nottingham East|Nottingham North and Kimberley|Nottingham South|Nuneaton|Old Bexley and Sidcup|Oldham East and Saddleworth|Oldham West, Chadderton and Royton|Orkney and Shetland|Orpington|Ossett and Denby Dale|Oxford East|Oxford West and Abingdon|Paisley and Renfrewshire North|Paisley and Renfrewshire South|Peckham|Pendle and Clitheroe|Penistone and Stocksbridge|Penrith and Solway|Perth and Kinross-shire|Peterborough|Plymouth Moor View|Plymouth Sutton and Devonport|Pontefract, Castleford and Knottingley|Pontypridd|Poole|Poplar and Limehouse|Portsmouth North|Portsmouth South|Preston|Putney|Queen's Park and Maida Vale|Rawmarsh and Conisbrough|Rayleigh and Wickford|Reading Central|Reading West and Mid Berkshire|Redcar|Redditch|Reigate|Rhondda and Ogmore|Ribble Valley|Richmond and Northallerton|Richmond Park|Rochdale|Rochester and Strood|Romford|Romsey and Southampton North|Rossendale and Darwen|Rother Valley|Rotherham|Rugby|Ruislip, Northwood and Pinner|Runcorn and Helsby|Runnymede and Weybridge|Rushcliffe|Rutherglen|Rutland and Stamford|Salford|Salisbury|Scarborough and Whitby|Scunthorpe|Sefton Central|Selby|Sevenoaks|Sheffield Brightside and Hillsborough|Sheffield Central|Sheffield Hallam|Sheffield Heeley|Sheffield South East|Sherwood Forest|Shipley|Shrewsbury|Sittingbourne and Sheppey|Skipton and Ripon|Sleaford and North Hykeham|Slough|Smethwick|Solihull West and Shirley|South Basildon and East Thurrock|South Cambridgeshire|South Cotswolds|South Derbyshire|South Devon|South Dorset|South East Cornwall|South Holland and The Deepings|South Leicestershire|South Norfolk|South Northamptonshire|South Ribble|South Shields|South Shropshire|South Suffolk|South West Devon|South West Hertfordshire|South West Norfolk|South West Wiltshire|Southampton Itchen|Southampton Test|Southend East and Rochford|Southend West and Leigh|Southgate and Wood Green|Southport|Spelthorne|Spen Valley|St Albans|St Austell and Newquay|St Helens North|St Helens South and Whiston|St Ives|St Neots and Mid Cambridgeshire|Stafford|Staffordshire Moorlands|Stalybridge and Hyde|Stevenage|Stirling and Strathallan|Stockport|Stockton North|Stockton West|Stoke-on-Trent Central|Stoke-on-Trent North|Stoke-on-Trent South|Stone, Great Wyrley and Penkridge|Stourbridge|Stratford and Bow|Stratford-on-Avon|Streatham and Croydon North|Stretford and Urmston|Stroud|Suffolk Coastal|Sunderland Central|Surrey Heath|Sussex Weald|Sutton and Cheam|Sutton Coldfield|Swansea West|Swindon North|Swindon South|Tamworth|Tatton|Taunton and Wellington|Telford|Tewkesbury|The Wrekin|Thirsk and Malton|Thornbury and Yate|Thurrock|Tipton and Wednesbury|Tiverton and Minehead|Tonbridge|Tooting|Torbay|Torfaen|Torridge and Tavistock|Tottenham|Truro and Falmouth|Tunbridge Wells|Twickenham|Tynemouth|Uxbridge and South Ruislip|Vale of Glamorgan|Vauxhall and Camberwell Green|Wakefield and Rothwell|Wallasey|Walsall and Bloxwich|Walthamstow|Warrington North|Warrington South|Warwick and Leamington|Washington and Gateshead South|Watford|Waveney Valley|Weald of Kent|Wellingborough and Rushden|Wells and Mendip Hills|Welwyn Hatfield|West Aberdeenshire and Kincardine|West Bromwich|West Dorset|West Dunbartonshire|West Ham and Beckton|West Lancashire|West Suffolk|West Worcestershire|Westmorland and Lonsdale|Weston-super-Mare|Wetherby and Easingwold|Whitehaven and Workington|Widnes and Halewood|Wigan|Wimbledon|Winchester|Windsor|Wirral West|Witham|Witney|Woking|Wokingham|Wolverhampton North East|Wolverhampton South East|Wolverhampton West|Worcester|Worsley and Eccles|Worthing West|Wrexham|Wycombe|Wyre Forest|Wythenshawe and Sale East|Yeovil|Ynys Mon|York Central|York Outer\",\n",
      "       'Europe|Immigration|Economy|Health|Terrorism|Inequality|Environment|Austerity/spending|Negativity|Other lib-auth|Other left-right|Other',\n",
      "       '16.0|17.0|18.0|19.0|20.0|21.0|22.0|23.0|24.0|25.0|26.0|27.0|28.0|29.0|30.0|31.0|32.0|33.0|34.0|35.0|36.0|37.0|38.0|39.0|40.0|41.0|42.0|43.0|44.0|45.0|46.0|47.0|48.0|49.0|50.0|51.0|52.0|53.0|54.0|55.0|56.0|57.0|58.0|59.0|60.0|61.0|62.0|63.0|64.0|65.0|66.0|67.0|68.0|69.0|70.0|71.0|72.0|73.0|74.0|75.0|76.0|77.0|78.0|79.0|80.0|81.0|82.0|83.0|84.0|85.0|86.0|87.0|88.0|89.0|90.0|91.0|92.0|93.0|94.0|95.0|96.0|97.0|98.0|100.0|101.0|105.0|109.0|110.0',\n",
      "       'North East|North West|Yorkshire and the Humber|East Midlands|West Midlands|East of England|London|South East|South West|Wales|Scotland|Northern Ireland',\n",
      "       'Aldershot|Aldridge-Brownhills|Altrincham and Sale West|Amber Valley|Arundel and South Downs|Ashfield|Ashford|Ashton-under-Lyne|Aylesbury|Banbury|Barking|Barnsley Central|Barnsley East|Barrow and Furness|Basildon and Billericay|Basingstoke|Bassetlaw|Bath|Batley and Spen|Battersea|Beaconsfield|Beckenham|Bedford|Bermondsey and Old Southwark|Berwick-upon-Tweed|Bethnal Green and Bow|Beverley and Holderness|Bexhill and Battle|Bexleyheath and Crayford|Birkenhead|Birmingham, Edgbaston|Birmingham, Erdington|Birmingham, Hall Green|Birmingham, Hodge Hill|Birmingham, Ladywood|Birmingham, Northfield|Birmingham, Perry Barr|Birmingham, Selly Oak|Birmingham, Yardley|Bishop Auckland|Blackburn|Blackley and Broughton|Blackpool North and Cleveleys|Blackpool South|Blaydon|Blyth Valley|Bognor Regis and Littlehampton|Bolsover|Bolton North East|Bolton South East|Bolton West|Bootle|Boston and Skegness|Bosworth|Bournemouth East|Bournemouth West|Bracknell|Bradford East|Bradford South|Bradford West|Braintree|Brent Central|Brent North|Brentford and Isleworth|Brentwood and Ongar|Bridgwater and West Somerset|Brigg and Goole|Brighton, Kemptown|Brighton, Pavilion|Bristol East|Bristol North West|Bristol South|Bristol West|Broadland|Bromley and Chislehurst|Bromsgrove|Broxbourne|Broxtowe|Buckingham|Burnley|Burton|Bury North|Bury South|Bury St Edmunds|Calder Valley|Camberwell and Peckham|Camborne and Redruth|Cambridge|Cannock Chase|Canterbury|Carlisle|Carshalton and Wallington|Castle Point|Central Devon|Central Suffolk and North Ipswich|Charnwood|Chatham and Aylesford|Cheadle|Chelmsford|Chelsea and Fulham|Cheltenham|Chesham and Amersham|Chesterfield|Chichester|Chingford and Woodford Green|Chippenham|Chipping Barnet|Chorley|Christchurch|Cities of London and Westminster|City of Chester|City of Durham|Clacton|Cleethorpes|Colchester|Colne Valley|Congleton|Copeland|Corby|Coventry North East|Coventry North West|Coventry South|Crawley|Crewe and Nantwich|Croydon Central|Croydon North|Croydon South|Dagenham and Rainham|Darlington|Dartford|Daventry|Denton and Reddish|Derby North|Derby South|Derbyshire Dales|Devizes|Dewsbury|Don Valley|Doncaster Central|Doncaster North|Dover|Dudley North|Dudley South|Dulwich and West Norwood|Ealing Central and Acton|Ealing North|Ealing, Southall|Easington|East Devon|East Ham|East Hampshire|East Surrey|East Worthing and Shoreham|East Yorkshire|Eastbourne|Eastleigh|Eddisbury|Edmonton|Ellesmere Port and Neston|Elmet and Rothwell|Eltham|Enfield North|Enfield, Southgate|Epping Forest|Epsom and Ewell|Erewash|Erith and Thamesmead|Esher and Walton|Exeter|Fareham|Faversham and Mid Kent|Feltham and Heston|Filton and Bradley Stoke|Finchley and Golders Green|Folkestone and Hythe|Forest of Dean|Fylde|Gainsborough|Garston and Halewood|Gateshead|Gedling|Gillingham and Rainham|Gloucester|Gosport|Grantham and Stamford|Gravesham|Great Grimsby|Great Yarmouth|Greenwich and Woolwich|Guildford|Hackney North and Stoke Newington|Hackney South and Shoreditch|Halesowen and Rowley Regis|Halifax|Haltemprice and Howden|Halton|Hammersmith|Hampstead and Kilburn|Harborough|Harlow|Harrogate and Knaresborough|Harrow East|Harrow West|Hartlepool|Harwich and North Essex|Hastings and Rye|Havant|Hayes and Harlington|Hazel Grove|Hemel Hempstead|Hemsworth|Hendon|Henley|Hereford and South Herefordshire|Hertford and Stortford|Hertsmere|Hexham|Heywood and Middleton|High Peak|Hitchin and Harpenden|Holborn and St Pancras|Hornchurch and Upminster|Hornsey and Wood Green|Horsham|Houghton and Sunderland South|Hove|Huddersfield|Huntingdon|Hyndburn|Ilford North|Ilford South|Ipswich|Isle of Wight|Islington North|Islington South and Finsbury|Jarrow|Keighley|Kenilworth and Southam|Kensington|Kettering|Kingston and Surbiton|Kingston upon Hull East|Kingston upon Hull North|Kingston upon Hull West and Hessle|Kingswood|Knowsley|Lancaster and Fleetwood|Leeds Central|Leeds East|Leeds North East|Leeds North West|Leeds West|Leicester East|Leicester South|Leicester West|Leigh|Lewes|Lewisham East|Lewisham West and Penge|Lewisham, Deptford|Leyton and Wanstead|Lichfield|Lincoln|Liverpool, Riverside|Liverpool, Walton|Liverpool, Wavertree|Liverpool, West Derby|Loughborough|Louth and Horncastle|Ludlow|Luton North|Luton South|Macclesfield|Maidenhead|Maidstone and The Weald|Makerfield|Maldon|Manchester Central|Manchester, Gorton|Manchester, Withington|Mansfield|Meon Valley|Meriden|Mid Bedfordshire|Mid Derbyshire|Mid Dorset and North Poole|Mid Norfolk|Mid Sussex|Mid Worcestershire|Middlesbrough|Middlesbrough South and East Cleveland|Milton Keynes North|Milton Keynes South|Mitcham and Morden|Mole Valley|Morecambe and Lunesdale|Morley and Outwood|New Forest East|New Forest West|Newark|Newbury|Newcastle upon Tyne Central|Newcastle upon Tyne East|Newcastle upon Tyne North|Newcastle-under-Lyme|Newton Abbot|Normanton, Pontefract and Castleford|North Cornwall|North Devon|North Dorset|North Durham|North East Bedfordshire|North East Cambridgeshire|North East Derbyshire|North East Hampshire|North East Hertfordshire|North East Somerset|North Herefordshire|North Norfolk|North Shropshire|North Somerset|North Swindon|North Thanet|North Tyneside|North Warwickshire|North West Cambridgeshire|North West Durham|North West Hampshire|North West Leicestershire|North West Norfolk|North Wiltshire|Northampton North|Northampton South|Norwich North|Norwich South|Nottingham East|Nottingham North|Nottingham South|Nuneaton|Old Bexley and Sidcup|Oldham East and Saddleworth|Oldham West and Royton|Orpington|Oxford East|Oxford West and Abingdon|Pendle|Penistone and Stocksbridge|Penrith and The Border|Peterborough|Plymouth, Moor View|Plymouth, Sutton and Devonport|Poole|Poplar and Limehouse|Portsmouth North|Portsmouth South|Preston|Pudsey|Putney|Rayleigh and Wickford|Reading East|Reading West|Redcar|Redditch|Reigate|Ribble Valley|Richmond (Yorks)|Richmond Park|Rochdale|Rochester and Strood|Rochford and Southend East|Romford|Romsey and Southampton North|Rossendale and Darwen|Rother Valley|Rotherham|Rugby|Ruislip, Northwood and Pinner|Runnymede and Weybridge|Rushcliffe|Rutland and Melton|Saffron Walden|Salford and Eccles|Salisbury|Scarborough and Whitby|Scunthorpe|Sedgefield|Sefton Central|Selby and Ainsty|Sevenoaks|Sheffield Central|Sheffield South East|Sheffield, Brightside and Hillsborough|Sheffield, Hallam|Sheffield, Heeley|Sherwood|Shipley|Shrewsbury and Atcham|Sittingbourne and Sheppey|Skipton and Ripon|Sleaford and North Hykeham|Slough|Solihull|Somerton and Frome|South Basildon and East Thurrock|South Cambridgeshire|South Derbyshire|South Dorset|South East Cambridgeshire|South East Cornwall|South Holland and The Deepings|South Leicestershire|South Norfolk|South Northamptonshire|South Ribble|South Shields|South Staffordshire|South Suffolk|South Swindon|South Thanet|South West Bedfordshire|South West Devon|South West Hertfordshire|South West Norfolk|South West Surrey|South West Wiltshire|Southampton, Itchen|Southampton, Test|Southend West|Southport|Spelthorne|St Albans|St Austell and Newquay|St Helens North|St Helens South and Whiston|St Ives|Stafford|Staffordshire Moorlands|Stalybridge and Hyde|Stevenage|Stockport|Stockton North|Stockton South|Stoke-on-Trent Central|Stoke-on-Trent North|Stoke-on-Trent South|Stone|Stourbridge|Stratford-on-Avon|Streatham|Stretford and Urmston|Stroud|Suffolk Coastal|Sunderland Central|Surrey Heath|Sutton and Cheam|Sutton Coldfield|Tamworth|Tatton|Taunton Deane|Telford|Tewkesbury|The Cotswolds|The Wrekin|Thirsk and Malton|Thornbury and Yate|Thurrock|Tiverton and Honiton|Tonbridge and Malling|Tooting|Torbay|Torridge and West Devon|Totnes|Tottenham|Truro and Falmouth|Tunbridge Wells|Twickenham|Tynemouth|Uxbridge and South Ruislip|Vauxhall|Wakefield|Wallasey|Walsall North|Walsall South|Walthamstow|Wansbeck|Wantage|Warley|Warrington North|Warrington South|Warwick and Leamington|Washington and Sunderland West|Watford|Waveney|Wealden|Weaver Vale|Wellingborough|Wells|Welwyn Hatfield|Wentworth and Dearne|West Bromwich East|West Bromwich West|West Dorset|West Ham|West Lancashire|West Suffolk|West Worcestershire|Westminster North|Westmorland and Lonsdale|Weston-Super-Mare|Wigan|Wimbledon|Winchester|Windsor|Wirral South|Wirral West|Witham|Witney|Woking|Wokingham|Wolverhampton North East|Wolverhampton South East|Wolverhampton South West|Worcester|Workington|Worsley and Eccles South|Worthing West|Wycombe|Wyre and Preston North|Wyre Forest|Wythenshawe and Sale East|Yeovil|York Central|York Outer|Ynys Mon|Delyn|Alyn and Deeside|Wrexham|Llanelli|Gower|Swansea West|Swansea East|Aberavon|Cardiff Central|Cardiff North|Rhondda|Torfaen|Monmouth|Newport East|Newport West|Arfon|Aberconwy|Clwyd West|Vale of Clwyd|Dwyfor Meirionnydd|Clwyd South|Montgomeryshire|Ceredigion|Preseli Pembrokeshire|Carmarthen West and South Pembrokeshire|Carmarthen East and Dinefwr|Brecon and Radnorshire|Neath|Cynon Valley|Merthyr Tydfil and Rhymney|Blaenau Gwent|Bridgend|Ogmore|Pontypridd|Caerphilly|Islwyn|Vale of Glamorgan|Cardiff West|Cardiff South and Penarth|Aberdeen North|Aberdeen South|Airdrie and Shotts|Angus|Argyll and Bute|Ayr, Carrick and Cumnock|Banff and Buchan|Berwickshire, Roxburgh and Selkirk|Caithness, Sutherland and Easter Ross|Central Ayrshire|Coatbridge, Chryston and Bellshill|Cumbernauld, Kilsyth and Kirkintilloch East|Dumfries and Galloway|Dumfriesshire, Clydesdale and Tweeddale|Dundee East|Dundee West|Dunfermline and West Fife|East Dunbartonshire|East Kilbride, Strathaven and Lesmahagow|East Lothian|East Renfrewshire|Edinburgh East|Edinburgh North and Leith|Edinburgh South|Edinburgh South West|Edinburgh West|Falkirk|Glasgow Central|Glasgow East|Glasgow North|Glasgow North East|Glasgow North West|Glasgow South|Glasgow South West|Glenrothes|Gordon|Inverclyde|Inverness, Nairn, Badenoch and Strathspey|Kilmarnock and Loudoun|Kirkcaldy and Cowdenbeath|Lanark and Hamilton East|Linlithgow and East Falkirk|Livingston|Midlothian|Moray|Motherwell and Wishaw|Na h-Eileanan an Iar|North Ayrshire and Arran|North East Fife|Ochil and South Perthshire|Orkney and Shetland|Paisley and Renfrewshire North|Paisley and Renfrewshire South|Perth and North Perthshire|Ross, Skye and Lochaber|Rutherglen and Hamilton West|Stirling|West Aberdeenshire and Kincardine|West Dunbartonshire|Belfast West|South Down',\n",
      "       'Working full time (30 or more hours per week)|Working part time (8-29 hours a week)|Working part time (Less than 8 hours a week)|Full time student|Retired|Unemployed|Not working|Other',\n",
      "       \"under £5,000 per year|£5,000 to £9,999 per year|£10,000 to £14,999 per year|£15,000 to £19,999 per year|£20,000 to £24,999 per year|£25,000 to £29,999 per year|£30,000 to £34,999 per year|£35,000 to £39,999 per year|£40,000 to £44,999 per year|£45,000 to £49,999 per year|£50,000 to £59,999 per year|£60,000 to £69,999 per year|£70,000 to £99,999 per year|£100,000 to £149,999 per year|£150,000 and over|Prefer not to answer|Don't know\",\n",
      "       'Own – outright|Own – with a mortgage|Own (part-own) – through shared ownership scheme (i.e. pay part mortgage, part rent)|Rent – from a private landlord|Rent – from my local authority|Rent – from a housing association|Neither – I live with my parents, family or friends but pay some rent to them|Neither – I live rent-free with my parents, family or friends|Other',\n",
      "       'Private sector - profit seeking|Public sector - government owned or funded|Third sector - non-profit, non-government|98.0|99.0',\n",
      "       'Married|In a civil partnership|Separated but still legally married or in a civil partnership|Living with a partner but neither married nor in a civil partnership|In a relationship, but not living together|Single|Divorced|Widowed',\n",
      "       'Yes, limited a lot|Yes, limited a little|No',\n",
      "       'No, I do not regard myself as belonging to any particular religion|Yes - Church of England/Anglican/Episcopal|Yes - Roman Catholic|Yes - Presbyterian/Church of Scotland|Yes - Methodist|Yes - Baptist|Yes - United Reformed Church|Yes - Free Presbyterian| Yes - Brethren|Yes - Judaism|Yes - Hinduism|Yes - Islam|Yes - Sikhism|Yes - Buddhism|Yes - Other|16.0|Yes – Orthodox Christian|Yes - Pentecostal (e.g. Assemblies of God, Elim Pentecostal Church, New Testament Church of God, Redeemed Christian Church of God)|Yes - Evangelical – independent/non-denominational (e.g. FIEC, Pioneer, Vineyard, Newfrontiers)',\n",
      "       'Heterosexual|Gay or lesbian|Bisexual|Other|Prefer not to say',\n",
      "       'White British|Any other white background|White and Black Caribbean|White and Black African|White and Asian|Any other mixed background|Indian|Pakistani|Bangladeshi|Any other Asian background|Black Caribbean|Black African|Any other black background|Chinese|Other ethnic group|Prefer not to say',\n",
      "       'No qualifications|Below GCSE|GCSE|A-level|Undergraduate|Postgrad',\n",
      "       'Left|0.5|1.0|1.5|2.0|2.5|3.0|3.5|4.0|4.5|5.0|5.5|6.0|6.5|7.0|7.5|8.0|8.5|9.0|9.5|Right',\n",
      "       'Libertarian|0.5|1.0|1.5|2.0|2.5|3.0|3.5|4.0|4.5|5.0|5.5|6.0|6.5|7.0|7.5|8.0|8.5|9.0|9.5|Authoritarian',\n",
      "       'Men|Female'], dtype=object), array(['', '', '',\n",
      "       \"Very unlikely that I would vote|Fairly unlikely|Neither likely nor unlikely|Fairly likely|Very likely that I would vote|Don't know\",\n",
      "       '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
      "       '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
      "       '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
      "       '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
      "       '', '', '', '', '', '', '', '', '', ''], dtype=object), array(['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
      "       '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
      "       '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
      "       '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
      "       '', '', '', '', '', '', '', '', '', '', '', '', '', ''],\n",
      "      dtype=object), array(['', '', '',\n",
      "       'Very unlikely that I will vote|Fairly unlikely|Neither likely nor unlikely|Fairly likely|Very likely that I will vote',\n",
      "       'I would/did not vote|Conservative|Labour|Liberal Democrat|Scottish National Party (SNP)|Plaid Cymru|United Kingdom Independence Party (UKIP)|Green Party|British National Party (BNP)|Change UK- The Independent Group|Brexit Party/Reform UK|An independent candidate',\n",
      "       'Very strong|Fairly strong|Not very strong',\n",
      "       'Conservative|Labour|Liberal Democrat|Scottish National Party (SNP)|Plaid Cymru|United Kingdom Independence Party (UKIP)|Green Party|British National Party (BNP)|No - none|Change UK- The Independent Group|Brexit Party/Reform UK',\n",
      "       'No party is best able to handle this issue|Conservative|Labour|Liberal Democrat|Scottish National Party (SNP)|Plaid Cymru|United Kingdom Independence Party (UKIP)|Green Party|British National Party (BNP)|Other party|Change UK- The Independent Group|Brexit Party/Reform UK',\n",
      "       'Pay no attention|1.0|2.0|3.0|4.0|5.0|6.0|7.0|8.0|9.0|Pay a great deal of attention',\n",
      "       'Strongly dislike|1.0|2.0|3.0|4.0|5.0|6.0|7.0|8.0|9.0|Strongly like',\n",
      "       'Strongly dislike|1.0|2.0|3.0|4.0|5.0|6.0|7.0|8.0|9.0|Strongly like',\n",
      "       'Strongly dislike|1.0|2.0|3.0|4.0|5.0|6.0|7.0|8.0|9.0|Strongly like',\n",
      "       'Strongly dislike|1.0|2.0|3.0|4.0|5.0|6.0|7.0|8.0|9.0|Strongly like',\n",
      "       'Strongly dislike|1.0|2.0|3.0|4.0|5.0|6.0|7.0|8.0|9.0|Strongly like',\n",
      "       'Strongly dislike|1.0|2.0|3.0|4.0|5.0|6.0|7.0|8.0|9.0|Strongly like',\n",
      "       'Strongly dislike|1.0|2.0|3.0|4.0|5.0|6.0|7.0|8.0|9.0|Strongly like',\n",
      "       'Strongly dislike|1.0|2.0|3.0|4.0|5.0|6.0|7.0|8.0|9.0|Strongly like',\n",
      "       'Strongly dislike|1.0|2.0|3.0|4.0|5.0|6.0|7.0|8.0|9.0|Strongly like',\n",
      "       'Strongly dislike|1.0|2.0|3.0|4.0|5.0|6.0|7.0|8.0|9.0|Strongly like',\n",
      "       'Strongly dislike|1.0|2.0|3.0|4.0|5.0|6.0|7.0|8.0|9.0|Strongly like',\n",
      "       'Strongly dislike|1.0|2.0|3.0|4.0|5.0|6.0|7.0|8.0|9.0|Strongly like',\n",
      "       'Got a lot worse|Got a little worse|Stayed the same|Got a little better|Got a lot better',\n",
      "       'Got a lot worse|Got a little worse|Stayed the same|Got a little better|Got a lot better',\n",
      "       'Very unlikely|Fairly unlikely|Neither likely nor unlikely|Fairly likely|Very likely',\n",
      "       'Very unlikely|Fairly unlikely|Neither likely nor unlikely|Fairly likely|Very likely',\n",
      "       'Getting a lot worse|Getting a little worse|Staying about the same|Getting a little better|Getting a lot better',\n",
      "       'Unite fully with the European Union|1.0|2.0|3.0|4.0|5.0|6.0|7.0|8.0|9.0|Protect our independence',\n",
      "       'Unite fully with the European Union|1.0|2.0|3.0|4.0|5.0|6.0|7.0|8.0|9.0|Protect our independence',\n",
      "       'Unite fully with the European Union|1.0|2.0|3.0|4.0|5.0|6.0|7.0|8.0|9.0|Protect our independence',\n",
      "       'Unite fully with the European Union|1.0|2.0|3.0|4.0|5.0|6.0|7.0|8.0|9.0|Protect our independence',\n",
      "       'Unite fully with the European Union|1.0|2.0|3.0|4.0|5.0|6.0|7.0|8.0|9.0|Protect our independence',\n",
      "       'Unite fully with the European Union|1.0|2.0|3.0|4.0|5.0|6.0|7.0|8.0|9.0|Protect our independence',\n",
      "       'Bad for economy|2.0|3.0|4.0|5.0|6.0|Good for economy',\n",
      "       'Rejoin the EU|Stay out of the EU',\n",
      "       'Government should try to make incomes equal|1.0|2.0|3.0|4.0|5.0|6.0|7.0|8.0|9.0|Government should be less concerned about equal incomes',\n",
      "       'Government should try to make incomes equal|1.0|2.0|3.0|4.0|5.0|6.0|7.0|8.0|9.0|Government should be less concerned about equal incomes',\n",
      "       'Government should try to make incomes equal|1.0|2.0|3.0|4.0|5.0|6.0|7.0|8.0|9.0|Government should be less concerned about equal incomes',\n",
      "       'Government should try to make incomes equal|1.0|2.0|3.0|4.0|5.0|6.0|7.0|8.0|9.0|Government should be less concerned about equal incomes',\n",
      "       'Government should try to make incomes equal|1.0|2.0|3.0|4.0|5.0|6.0|7.0|8.0|9.0|Government should be less concerned about equal incomes',\n",
      "       'Government should try to make incomes equal|1.0|2.0|3.0|4.0|5.0|6.0|7.0|8.0|9.0|Government should be less concerned about equal incomes',\n",
      "       'Economic growth should have priority|1.0|2.0|3.0|4.0|5.0|6.0|7.0|8.0|9.0|Protecting the environment should have priority',\n",
      "       'No trust|2.0|3.0|4.0|5.0|6.0|A great deal of trust',\n",
      "       'Allow many fewer|1.0|2.0|3.0|4.0|5.0|6.0|7.0|8.0|9.0|Allow many more',\n",
      "       'Allow many fewer|1.0|2.0|3.0|4.0|5.0|6.0|7.0|8.0|9.0|Allow many more',\n",
      "       'Allow many fewer|1.0|2.0|3.0|4.0|5.0|6.0|7.0|8.0|9.0|Allow many more',\n",
      "       'Allow many fewer|1.0|2.0|3.0|4.0|5.0|6.0|7.0|8.0|9.0|Allow many more',\n",
      "       'Allow many fewer|1.0|2.0|3.0|4.0|5.0|6.0|7.0|8.0|9.0|Allow many more',\n",
      "       'Allow many fewer|1.0|2.0|3.0|4.0|5.0|6.0|7.0|8.0|9.0|Allow many more',\n",
      "       'Not at all British|2.0|3.0|4.0|5.0|6.0|Very strongly British',\n",
      "       'Not at all Scottish|2.0|3.0|4.0|5.0|6.0|Very strongly Scottish',\n",
      "       'Not at all Welsh|2.0|3.0|4.0|5.0|6.0|Very strongly Welsh',\n",
      "       'Not at all English|2.0|3.0|4.0|5.0|6.0|Very strongly English',\n",
      "       'Not at all European|2.0|3.0|4.0|5.0|6.0|Very strongly European',\n",
      "       \"I would vote 'No' (stay in the UK)|I would vote 'Yes' (leave the UK)|Would not vote\",\n",
      "       \"Will vote no|Will vote 'Yes'\",\n",
      "       'Strongly disapprove|Disapprove|Neither approve nor disapprove|Approve|Strongly approve',\n",
      "       'Strongly disapprove|Disapprove|Neither approve nor disapprove|Approve|Strongly approve',\n",
      "       'Strongly disapprove|Disapprove|Neither approve nor disapprove|Approve|Strongly approve',\n",
      "       'Strongly disagree|Disagree|Neither agree nor disagree|Agree|Strongly agree',\n",
      "       'Strongly disagree|Disagree|Neither agree nor disagree|Agree|Strongly agree',\n",
      "       'Strongly disagree|Disagree|Neither agree nor disagree|Agree|Strongly agree',\n",
      "       'No|Yes, middle class|Yes, working class',\n",
      "       'No|Yes, but not fluently|Yes, fluently',\n",
      "       'Employers in large organisations and higher managerial|Higher professional occupations|Lower professional and managerial and higher supervisory|Intermediate occupations|Employers in small organisations and own account workers|Lower supervisory and technical occupations|Semi-routine occupations|Routine occupations',\n",
      "       \"Aberafan Maesteg|Aberdeen North|Aberdeen South|Aberdeenshire North and Moray East|Airdrie and Shotts|Aldershot|Aldridge-Brownhills|Alloa and Grangemouth|Altrincham and Sale West|Alyn and Deeside|Amber Valley|Angus and Perthshire Glens|Arbroath and Broughty Ferry|Argyll, Bute and South Lochaber|Arundel and South Downs|Ashfield|Ashford|Ashton-under-Lyne|Aylesbury|Ayr, Carrick and Cumnock|Banbury|Bangor Aberconwy|Barking|Barnsley North|Barnsley South|Barrow and Furness|Basildon and Billericay|Basingstoke|Bassetlaw|Bath|Bathgate and Linlithgow|Battersea|Beaconsfield|Beckenham and Penge|Bedford|Bermondsey and Old Southwark|Berwickshire, Roxburgh and Selkirk|Bethnal Green and Stepney|Beverley and Holderness|Bexhill and Battle|Bexleyheath and Crayford|Bicester and Woodstock|Birkenhead|Birmingham Edgbaston|Birmingham Erdington|Birmingham Hall Green and Moseley|Birmingham Hodge Hill and Solihull North|Birmingham Ladywood|Birmingham Northfield|Birmingham Perry Barr|Birmingham Selly Oak|Birmingham Yardley|Bishop Auckland|Blackburn|Blackley and Middleton South|Blackpool North and Fleetwood|Blackpool South|Blaenau Gwent and Rhymney|Blaydon and Consett|Blyth and Ashington|Bognor Regis and Littlehampton|Bolsover|Bolton North East|Bolton South and Walkden|Bolton West|Bootle|Boston and Skegness|Bournemouth East|Bournemouth West|Bracknell|Bradford East|Bradford South|Bradford West|Braintree|Brecon, Radnor and Cwm Tawe|Brent East|Brent West|Brentford and Isleworth|Brentwood and Ongar|Bridgend|Bridgwater|Bridlington and The Wolds|Brigg and Immingham|Brighton Kemptown and Peacehaven|Brighton Pavilion|Bristol Central|Bristol East|Bristol North East|Bristol North West|Bristol South|Broadland and Fakenham|Bromley and Biggin Hill|Bromsgrove|Broxbourne|Broxtowe|Buckingham and Bletchley|Burnley|Burton and Uttoxeter|Bury North|Bury South|Bury St Edmunds and Stowmarket|Caerfyrddin|Caerphilly|Caithness, Sutherland and Easter Ross|Calder Valley|Camborne and Redruth|Cambridge|Cannock Chase|Canterbury|Cardiff East|Cardiff North|Cardiff South and Penarth|Cardiff West|Carlisle|Carshalton and Wallington|Castle Point|Central Ayrshire|Central Devon|Central Suffolk and North Ipswich|Ceredigion Preseli|Chatham and Aylesford|Cheadle|Chelmsford|Chelsea and Fulham|Cheltenham|Chesham and Amersham|Chester North and Neston|Chester South and Eddisbury|Chesterfield|Chichester|Chingford and Woodford Green|Chippenham|Chipping Barnet|Chorley|Christchurch|Cities of London and Westminster|City of Durham|Clacton|Clapham and Brixton Hill|Clwyd East|Clwyd North|Coatbridge and Bellshill|Colchester|Colne Valley|Congleton|Corby and East Northamptonshire|Coventry East|Coventry North West|Coventry South|Cowdenbeath and Kirkcaldy|Cramlington and Killingworth|Crawley|Crewe and Nantwich|Croydon East|Croydon South|Croydon West|Cumbernauld and Kirkintilloch|Dagenham and Rainham|Darlington|Dartford|Daventry|Derby North|Derby South|Derbyshire Dales|Dewsbury and Batley|Didcot and Wantage|Doncaster Central|Doncaster East and the Isle of Axholme|Doncaster North|Dorking and Horley|Dover and Deal|Droitwich and Evesham|Dudley|Dulwich and West Norwood|Dumfries and Galloway|Dumfriesshire, Clydesdale and Tweeddale|Dundee Central|Dunfermline and Dollar|Dunstable and Leighton Buzzard|Dwyfor Meirionnydd|Ealing Central and Acton|Ealing North|Ealing Southall|Earley and Woodley|Easington|East Grinstead and Uckfield|East Ham|East Hampshire|East Kilbride and Strathaven|East Renfrewshire|East Surrey|East Thanet|East Wiltshire|East Worthing and Shoreham|Eastbourne|Eastleigh|Edinburgh East and Musselburgh|Edinburgh North and Leith|Edinburgh South|Edinburgh South West|Edinburgh West|Edmonton and Winchmore Hill|Ellesmere Port and Bromborough|Eltham and Chislehurst|Ely and East Cambridgeshire|Enfield North|Epping Forest|Epsom and Ewell|Erewash|Erith and Thamesmead|Esher and Walton|Exeter|Exmouth and Exeter East|Falkirk|Fareham and Waterlooville|Farnham and Bordon|Faversham and Mid Kent|Feltham and Heston|Filton and Bradley Stoke|Finchley and Golders Green|Folkestone and Hythe|Forest of Dean|Frome and East Somerset|Fylde|Gainsborough|Gateshead Central and Whickham|Gedling|Gillingham and Rainham|Glasgow East|Glasgow North|Glasgow North East|Glasgow South|Glasgow South West|Glasgow West|Glastonbury and Somerton|Glenrothes and Mid Fife|Gloucester|Godalming and Ash|Goole and Pocklington|Gordon and Buchan|Gorton and Denton|Gosport|Gower|Grantham and Bourne|Gravesham|Great Grimsby and Cleethorpes|Great Yarmouth|Greenwich and Woolwich|Guildford|Hackney North and Stoke Newington|Hackney South and Shoreditch|Halesowen|Halifax|Hamble Valley|Hamilton and Clyde Valley|Hammersmith and Chiswick|Hampstead and Highgate|Harborough, Oadby and Wigston|Harlow|Harpenden and Berkhamsted|Harrogate and Knaresborough|Harrow East|Harrow West|Hartlepool|Harwich and North Essex|Hastings and Rye|Havant|Hayes and Harlington|Hazel Grove|Hemel Hempstead|Hendon|Henley and Thame|Hereford and South Herefordshire|Herne Bay and Sandwich|Hertford and Stortford|Hertsmere|Hexham|Heywood and Middleton North|High Peak|Hinckley and Bosworth|Hitchin|Holborn and St Pancras|Honiton and Sidmouth|Hornchurch and Upminster|Hornsey and Friern Barnet|Horsham|Houghton and Sunderland South|Hove and Portslade|Huddersfield|Huntingdon|Hyndburn|Ilford North|Ilford South|Inverclyde and Renfrewshire West|Inverness, Skye and West Ross-shire|Ipswich|Isle of Wight East|Isle of Wight West|Islington North|Islington South and Finsbury|Jarrow and Gateshead East|Keighley and Ilkley|Kenilworth and Southam|Kensington and Bayswater|Kettering|Kilmarnock and Loudoun|Kingston and Surbiton|Kingston upon Hull East|Kingston upon Hull North and Cottingham|Kingston upon Hull West and Haltemprice|Kingswinford and South Staffordshire|Knowsley|Lancaster and Wyre|Leeds Central and Headingley|Leeds East|Leeds North East|Leeds North West|Leeds South|Leeds South West and Morley|Leeds West and Pudsey|Leicester East|Leicester South|Leicester West|Leigh and Atherton|Lewes|Lewisham East|Lewisham North|Lewisham West and East Dulwich|Leyton and Wanstead|Lichfield|Lincoln|Liverpool Garston|Liverpool Riverside|Liverpool Walton|Liverpool Wavertree|Liverpool West Derby|Livingston|Llanelli|Lothian East|Loughborough|Louth and Horncastle|Lowestoft|Luton North|Luton South and South Bedfordshire|Macclesfield|Maidenhead|Maidstone and Malling|Makerfield|Maldon|Manchester Central|Manchester Rusholme|Manchester Withington|Mansfield|Melksham and Devizes|Melton and Syston|Meriden and Solihull East|Merthyr Tydfil and Aberdare|Mid and South Pembrokeshire|Mid Bedfordshire|Mid Buckinghamshire|Mid Cheshire|Mid Derbyshire|Mid Dorset and North Poole|Mid Dunbartonshire|Mid Leicestershire|Mid Norfolk|Mid Sussex|Middlesbrough and Thornaby East|Middlesbrough South and East Cleveland|Midlothian|Milton Keynes Central|Milton Keynes North|Mitcham and Morden|Monmouthshire|Montgomeryshire and Glyndwr|Moray West, Nairn and Strathspey|Morecambe and Lunesdale|Motherwell, Wishaw and Carluke|Na h-Eileanan an Iar|Neath and Swansea East|New Forest East|New Forest West|Newark|Newbury|Newcastle upon Tyne Central and West|Newcastle upon Tyne East and Wallsend|Newcastle upon Tyne North|Newcastle-under-Lyme|Newport East|Newport West and Islwyn|Newton Abbot|Newton Aycliffe and Spennymoor|Normanton and Hemsworth|North Ayrshire and Arran|North Bedfordshire|North Cornwall|North Cotswolds|North Devon|North Dorset|North Durham|North East Cambridgeshire|North East Derbyshire|North East Fife|North East Hampshire|North East Hertfordshire|North East Somerset and Hanham|North Herefordshire|North Norfolk|North Northumberland|North Shropshire|North Somerset|North Warwickshire and Bedworth|North West Cambridgeshire|North West Essex|North West Hampshire|North West Leicestershire|North West Norfolk|Northampton North|Northampton South|Norwich North|Norwich South|Nottingham East|Nottingham North and Kimberley|Nottingham South|Nuneaton|Old Bexley and Sidcup|Oldham East and Saddleworth|Oldham West, Chadderton and Royton|Orkney and Shetland|Orpington|Ossett and Denby Dale|Oxford East|Oxford West and Abingdon|Paisley and Renfrewshire North|Paisley and Renfrewshire South|Peckham|Pendle and Clitheroe|Penistone and Stocksbridge|Penrith and Solway|Perth and Kinross-shire|Peterborough|Plymouth Moor View|Plymouth Sutton and Devonport|Pontefract, Castleford and Knottingley|Pontypridd|Poole|Poplar and Limehouse|Portsmouth North|Portsmouth South|Preston|Putney|Queen's Park and Maida Vale|Rawmarsh and Conisbrough|Rayleigh and Wickford|Reading Central|Reading West and Mid Berkshire|Redcar|Redditch|Reigate|Rhondda and Ogmore|Ribble Valley|Richmond and Northallerton|Richmond Park|Rochdale|Rochester and Strood|Romford|Romsey and Southampton North|Rossendale and Darwen|Rother Valley|Rotherham|Rugby|Ruislip, Northwood and Pinner|Runcorn and Helsby|Runnymede and Weybridge|Rushcliffe|Rutherglen|Rutland and Stamford|Salford|Salisbury|Scarborough and Whitby|Scunthorpe|Sefton Central|Selby|Sevenoaks|Sheffield Brightside and Hillsborough|Sheffield Central|Sheffield Hallam|Sheffield Heeley|Sheffield South East|Sherwood Forest|Shipley|Shrewsbury|Sittingbourne and Sheppey|Skipton and Ripon|Sleaford and North Hykeham|Slough|Smethwick|Solihull West and Shirley|South Basildon and East Thurrock|South Cambridgeshire|South Cotswolds|South Derbyshire|South Devon|South Dorset|South East Cornwall|South Holland and The Deepings|South Leicestershire|South Norfolk|South Northamptonshire|South Ribble|South Shields|South Shropshire|South Suffolk|South West Devon|South West Hertfordshire|South West Norfolk|South West Wiltshire|Southampton Itchen|Southampton Test|Southend East and Rochford|Southend West and Leigh|Southgate and Wood Green|Southport|Spelthorne|Spen Valley|St Albans|St Austell and Newquay|St Helens North|St Helens South and Whiston|St Ives|St Neots and Mid Cambridgeshire|Stafford|Staffordshire Moorlands|Stalybridge and Hyde|Stevenage|Stirling and Strathallan|Stockport|Stockton North|Stockton West|Stoke-on-Trent Central|Stoke-on-Trent North|Stoke-on-Trent South|Stone, Great Wyrley and Penkridge|Stourbridge|Stratford and Bow|Stratford-on-Avon|Streatham and Croydon North|Stretford and Urmston|Stroud|Suffolk Coastal|Sunderland Central|Surrey Heath|Sussex Weald|Sutton and Cheam|Sutton Coldfield|Swansea West|Swindon North|Swindon South|Tamworth|Tatton|Taunton and Wellington|Telford|Tewkesbury|The Wrekin|Thirsk and Malton|Thornbury and Yate|Thurrock|Tipton and Wednesbury|Tiverton and Minehead|Tonbridge|Tooting|Torbay|Torfaen|Torridge and Tavistock|Tottenham|Truro and Falmouth|Tunbridge Wells|Twickenham|Tynemouth|Uxbridge and South Ruislip|Vale of Glamorgan|Vauxhall and Camberwell Green|Wakefield and Rothwell|Wallasey|Walsall and Bloxwich|Walthamstow|Warrington North|Warrington South|Warwick and Leamington|Washington and Gateshead South|Watford|Waveney Valley|Weald of Kent|Wellingborough and Rushden|Wells and Mendip Hills|Welwyn Hatfield|West Aberdeenshire and Kincardine|West Bromwich|West Dorset|West Dunbartonshire|West Ham and Beckton|West Lancashire|West Suffolk|West Worcestershire|Westmorland and Lonsdale|Weston-super-Mare|Wetherby and Easingwold|Whitehaven and Workington|Widnes and Halewood|Wigan|Wimbledon|Winchester|Windsor|Wirral West|Witham|Witney|Woking|Wokingham|Wolverhampton North East|Wolverhampton South East|Wolverhampton West|Worcester|Worsley and Eccles|Worthing West|Wrexham|Wycombe|Wyre Forest|Wythenshawe and Sale East|Yeovil|Ynys Mon|York Central|York Outer\",\n",
      "       'Europe|Immigration|Economy|Health|Terrorism|Inequality|Environment|Austerity/spending|Negativity|Other lib-auth|Other left-right',\n",
      "       '16.0|17.0|18.0|19.0|20.0|21.0|22.0|23.0|24.0|25.0|26.0|27.0|28.0|29.0|30.0|31.0|32.0|33.0|34.0|35.0|36.0|37.0|38.0|39.0|40.0|41.0|42.0|43.0|44.0|45.0|46.0|47.0|48.0|49.0|50.0|51.0|52.0|53.0|54.0|55.0|56.0|57.0|58.0|59.0|60.0|61.0|62.0|63.0|64.0|65.0|66.0|67.0|68.0|69.0|70.0|71.0|72.0|73.0|74.0|75.0|76.0|77.0|78.0|79.0|80.0|81.0|82.0|83.0|84.0|85.0|86.0|87.0|88.0|89.0|90.0|91.0|92.0|93.0|94.0|95.0|96.0|97.0|98.0|100.0|101.0|105.0|109.0|110.0',\n",
      "       'North East|North West|Yorkshire and the Humber|East Midlands|West Midlands|East of England|London|South East|South West|Wales|Scotland|Northern Ireland',\n",
      "       'Aldershot|Aldridge-Brownhills|Altrincham and Sale West|Amber Valley|Arundel and South Downs|Ashfield|Ashford|Ashton-under-Lyne|Aylesbury|Banbury|Barking|Barnsley Central|Barnsley East|Barrow and Furness|Basildon and Billericay|Basingstoke|Bassetlaw|Bath|Batley and Spen|Battersea|Beaconsfield|Beckenham|Bedford|Bermondsey and Old Southwark|Berwick-upon-Tweed|Bethnal Green and Bow|Beverley and Holderness|Bexhill and Battle|Bexleyheath and Crayford|Birkenhead|Birmingham, Edgbaston|Birmingham, Erdington|Birmingham, Hall Green|Birmingham, Hodge Hill|Birmingham, Ladywood|Birmingham, Northfield|Birmingham, Perry Barr|Birmingham, Selly Oak|Birmingham, Yardley|Bishop Auckland|Blackburn|Blackley and Broughton|Blackpool North and Cleveleys|Blackpool South|Blaydon|Blyth Valley|Bognor Regis and Littlehampton|Bolsover|Bolton North East|Bolton South East|Bolton West|Bootle|Boston and Skegness|Bosworth|Bournemouth East|Bournemouth West|Bracknell|Bradford East|Bradford South|Bradford West|Braintree|Brent Central|Brent North|Brentford and Isleworth|Brentwood and Ongar|Bridgwater and West Somerset|Brigg and Goole|Brighton, Kemptown|Brighton, Pavilion|Bristol East|Bristol North West|Bristol South|Bristol West|Broadland|Bromley and Chislehurst|Bromsgrove|Broxbourne|Broxtowe|Buckingham|Burnley|Burton|Bury North|Bury South|Bury St Edmunds|Calder Valley|Camberwell and Peckham|Camborne and Redruth|Cambridge|Cannock Chase|Canterbury|Carlisle|Carshalton and Wallington|Castle Point|Central Devon|Central Suffolk and North Ipswich|Charnwood|Chatham and Aylesford|Cheadle|Chelmsford|Chelsea and Fulham|Cheltenham|Chesham and Amersham|Chesterfield|Chichester|Chingford and Woodford Green|Chippenham|Chipping Barnet|Chorley|Christchurch|Cities of London and Westminster|City of Chester|City of Durham|Clacton|Cleethorpes|Colchester|Colne Valley|Congleton|Copeland|Corby|Coventry North East|Coventry North West|Coventry South|Crawley|Crewe and Nantwich|Croydon Central|Croydon North|Croydon South|Dagenham and Rainham|Darlington|Dartford|Daventry|Denton and Reddish|Derby North|Derby South|Derbyshire Dales|Devizes|Dewsbury|Don Valley|Doncaster Central|Doncaster North|Dover|Dudley North|Dudley South|Dulwich and West Norwood|Ealing Central and Acton|Ealing North|Ealing, Southall|Easington|East Devon|East Ham|East Hampshire|East Surrey|East Worthing and Shoreham|East Yorkshire|Eastbourne|Eastleigh|Eddisbury|Edmonton|Ellesmere Port and Neston|Elmet and Rothwell|Eltham|Enfield North|Enfield, Southgate|Epping Forest|Epsom and Ewell|Erewash|Erith and Thamesmead|Esher and Walton|Exeter|Fareham|Faversham and Mid Kent|Feltham and Heston|Filton and Bradley Stoke|Finchley and Golders Green|Folkestone and Hythe|Forest of Dean|Fylde|Gainsborough|Garston and Halewood|Gateshead|Gedling|Gillingham and Rainham|Gloucester|Gosport|Grantham and Stamford|Gravesham|Great Grimsby|Great Yarmouth|Greenwich and Woolwich|Guildford|Hackney North and Stoke Newington|Hackney South and Shoreditch|Halesowen and Rowley Regis|Halifax|Haltemprice and Howden|Halton|Hammersmith|Hampstead and Kilburn|Harborough|Harlow|Harrogate and Knaresborough|Harrow East|Harrow West|Hartlepool|Harwich and North Essex|Hastings and Rye|Havant|Hayes and Harlington|Hazel Grove|Hemel Hempstead|Hemsworth|Hendon|Henley|Hereford and South Herefordshire|Hertford and Stortford|Hertsmere|Hexham|Heywood and Middleton|High Peak|Hitchin and Harpenden|Holborn and St Pancras|Hornchurch and Upminster|Hornsey and Wood Green|Horsham|Houghton and Sunderland South|Hove|Huddersfield|Huntingdon|Hyndburn|Ilford North|Ilford South|Ipswich|Isle of Wight|Islington North|Islington South and Finsbury|Jarrow|Keighley|Kenilworth and Southam|Kensington|Kettering|Kingston and Surbiton|Kingston upon Hull East|Kingston upon Hull North|Kingston upon Hull West and Hessle|Kingswood|Knowsley|Lancaster and Fleetwood|Leeds Central|Leeds East|Leeds North East|Leeds North West|Leeds West|Leicester East|Leicester South|Leicester West|Leigh|Lewes|Lewisham East|Lewisham West and Penge|Lewisham, Deptford|Leyton and Wanstead|Lichfield|Lincoln|Liverpool, Riverside|Liverpool, Walton|Liverpool, Wavertree|Liverpool, West Derby|Loughborough|Louth and Horncastle|Ludlow|Luton North|Luton South|Macclesfield|Maidenhead|Maidstone and The Weald|Makerfield|Maldon|Manchester Central|Manchester, Gorton|Manchester, Withington|Mansfield|Meon Valley|Meriden|Mid Bedfordshire|Mid Derbyshire|Mid Dorset and North Poole|Mid Norfolk|Mid Sussex|Mid Worcestershire|Middlesbrough|Middlesbrough South and East Cleveland|Milton Keynes North|Milton Keynes South|Mitcham and Morden|Mole Valley|Morecambe and Lunesdale|Morley and Outwood|New Forest East|New Forest West|Newark|Newbury|Newcastle upon Tyne Central|Newcastle upon Tyne East|Newcastle upon Tyne North|Newcastle-under-Lyme|Newton Abbot|Normanton, Pontefract and Castleford|North Cornwall|North Devon|North Dorset|North Durham|North East Bedfordshire|North East Cambridgeshire|North East Derbyshire|North East Hampshire|North East Hertfordshire|North East Somerset|North Herefordshire|North Norfolk|North Shropshire|North Somerset|North Swindon|North Thanet|North Tyneside|North Warwickshire|North West Cambridgeshire|North West Durham|North West Hampshire|North West Leicestershire|North West Norfolk|North Wiltshire|Northampton North|Northampton South|Norwich North|Norwich South|Nottingham East|Nottingham North|Nottingham South|Nuneaton|Old Bexley and Sidcup|Oldham East and Saddleworth|Oldham West and Royton|Orpington|Oxford East|Oxford West and Abingdon|Pendle|Penistone and Stocksbridge|Penrith and The Border|Peterborough|Plymouth, Moor View|Plymouth, Sutton and Devonport|Poole|Poplar and Limehouse|Portsmouth North|Portsmouth South|Preston|Pudsey|Putney|Rayleigh and Wickford|Reading East|Reading West|Redcar|Redditch|Reigate|Ribble Valley|Richmond (Yorks)|Richmond Park|Rochdale|Rochester and Strood|Rochford and Southend East|Romford|Romsey and Southampton North|Rossendale and Darwen|Rother Valley|Rotherham|Rugby|Ruislip, Northwood and Pinner|Runnymede and Weybridge|Rushcliffe|Rutland and Melton|Saffron Walden|Salford and Eccles|Salisbury|Scarborough and Whitby|Scunthorpe|Sedgefield|Sefton Central|Selby and Ainsty|Sevenoaks|Sheffield Central|Sheffield South East|Sheffield, Brightside and Hillsborough|Sheffield, Hallam|Sheffield, Heeley|Sherwood|Shipley|Shrewsbury and Atcham|Sittingbourne and Sheppey|Skipton and Ripon|Sleaford and North Hykeham|Slough|Solihull|Somerton and Frome|South Basildon and East Thurrock|South Cambridgeshire|South Derbyshire|South Dorset|South East Cambridgeshire|South East Cornwall|South Holland and The Deepings|South Leicestershire|South Norfolk|South Northamptonshire|South Ribble|South Shields|South Staffordshire|South Suffolk|South Swindon|South Thanet|South West Bedfordshire|South West Devon|South West Hertfordshire|South West Norfolk|South West Surrey|South West Wiltshire|Southampton, Itchen|Southampton, Test|Southend West|Southport|Spelthorne|St Albans|St Austell and Newquay|St Helens North|St Helens South and Whiston|St Ives|Stafford|Staffordshire Moorlands|Stalybridge and Hyde|Stevenage|Stockport|Stockton North|Stockton South|Stoke-on-Trent Central|Stoke-on-Trent North|Stoke-on-Trent South|Stone|Stourbridge|Stratford-on-Avon|Streatham|Stretford and Urmston|Stroud|Suffolk Coastal|Sunderland Central|Surrey Heath|Sutton and Cheam|Sutton Coldfield|Tamworth|Tatton|Taunton Deane|Telford|Tewkesbury|The Cotswolds|The Wrekin|Thirsk and Malton|Thornbury and Yate|Thurrock|Tiverton and Honiton|Tonbridge and Malling|Tooting|Torbay|Torridge and West Devon|Totnes|Tottenham|Truro and Falmouth|Tunbridge Wells|Twickenham|Tynemouth|Uxbridge and South Ruislip|Vauxhall|Wakefield|Wallasey|Walsall North|Walsall South|Walthamstow|Wansbeck|Wantage|Warley|Warrington North|Warrington South|Warwick and Leamington|Washington and Sunderland West|Watford|Waveney|Wealden|Weaver Vale|Wellingborough|Wells|Welwyn Hatfield|Wentworth and Dearne|West Bromwich East|West Bromwich West|West Dorset|West Ham|West Lancashire|West Suffolk|West Worcestershire|Westminster North|Westmorland and Lonsdale|Weston-Super-Mare|Wigan|Wimbledon|Winchester|Windsor|Wirral South|Wirral West|Witham|Witney|Woking|Wokingham|Wolverhampton North East|Wolverhampton South East|Wolverhampton South West|Worcester|Workington|Worsley and Eccles South|Worthing West|Wycombe|Wyre and Preston North|Wyre Forest|Wythenshawe and Sale East|Yeovil|York Central|York Outer|Ynys Mon|Delyn|Alyn and Deeside|Wrexham|Llanelli|Gower|Swansea West|Swansea East|Aberavon|Cardiff Central|Cardiff North|Rhondda|Torfaen|Monmouth|Newport East|Newport West|Arfon|Aberconwy|Clwyd West|Vale of Clwyd|Dwyfor Meirionnydd|Clwyd South|Montgomeryshire|Ceredigion|Preseli Pembrokeshire|Carmarthen West and South Pembrokeshire|Carmarthen East and Dinefwr|Brecon and Radnorshire|Neath|Cynon Valley|Merthyr Tydfil and Rhymney|Blaenau Gwent|Bridgend|Ogmore|Pontypridd|Caerphilly|Islwyn|Vale of Glamorgan|Cardiff West|Cardiff South and Penarth|Aberdeen North|Aberdeen South|Airdrie and Shotts|Angus|Argyll and Bute|Ayr, Carrick and Cumnock|Banff and Buchan|Berwickshire, Roxburgh and Selkirk|Caithness, Sutherland and Easter Ross|Central Ayrshire|Coatbridge, Chryston and Bellshill|Cumbernauld, Kilsyth and Kirkintilloch East|Dumfries and Galloway|Dumfriesshire, Clydesdale and Tweeddale|Dundee East|Dundee West|Dunfermline and West Fife|East Dunbartonshire|East Kilbride, Strathaven and Lesmahagow|East Lothian|East Renfrewshire|Edinburgh East|Edinburgh North and Leith|Edinburgh South|Edinburgh South West|Edinburgh West|Falkirk|Glasgow Central|Glasgow East|Glasgow North|Glasgow North East|Glasgow North West|Glasgow South|Glasgow South West|Glenrothes|Gordon|Inverclyde|Inverness, Nairn, Badenoch and Strathspey|Kilmarnock and Loudoun|Kirkcaldy and Cowdenbeath|Lanark and Hamilton East|Linlithgow and East Falkirk|Livingston|Midlothian|Moray|Motherwell and Wishaw|Na h-Eileanan an Iar|North Ayrshire and Arran|North East Fife|Ochil and South Perthshire|Orkney and Shetland|Paisley and Renfrewshire North|Paisley and Renfrewshire South|Perth and North Perthshire|Ross, Skye and Lochaber|Rutherglen and Hamilton West|Stirling|West Aberdeenshire and Kincardine|West Dunbartonshire|Belfast West|South Down',\n",
      "       'Working full time (30 or more hours per week)|Working part time (8-29 hours a week)|Working part time (Less than 8 hours a week)|Full time student|Retired|Unemployed|Not working',\n",
      "       'under £5,000 per year|£5,000 to £9,999 per year|£10,000 to £14,999 per year|£15,000 to £19,999 per year|£20,000 to £24,999 per year|£25,000 to £29,999 per year|£30,000 to £34,999 per year|£35,000 to £39,999 per year|£40,000 to £44,999 per year|£45,000 to £49,999 per year|£50,000 to £59,999 per year|£60,000 to £69,999 per year|£70,000 to £99,999 per year|£100,000 to £149,999 per year|£150,000 and over',\n",
      "       'Own - outright|Own - with a mortgage|Own (part-own) - through shared ownership scheme (i.e. pay part mortgage, part rent)|Rent - from a private landlord|Rent - from my local authority|Rent - from a housing association|Neither - I live with my parents, family or friends but pay some rent to them|Neither - I live rent-free with my parents, family or friends',\n",
      "       'Private sector - profit seeking|Public sector - government owned or funded|Third sector - non-profit, non-government|98.0',\n",
      "       'Married|In a civil partnership|Separated but still legally married or in a civil partnership|Living with a partner but neither married nor in a civil partnership|In a relationship, but not living together|Single|Divorced|Widowed',\n",
      "       'Yes, limited a lot|Yes, limited a little|No',\n",
      "       'No, I do not regard myself as belonging to any particular religion|Yes - Church of England/Anglican/Episcopal|Yes - Roman Catholic|Yes - Presbyterian/Church of Scotland|Yes - Methodist|Yes - Baptist|Yes - United Reformed Church|Yes - Free Presbyterian| Yes - Brethren|Yes - Judaism|Yes - Hinduism|Yes - Islam|Yes - Sikhism|Yes - Buddhism|Yes - Other|16.0|Yes - Orthodox Christian|Yes - Pentecostal (e.g. Assemblies of God, Elim Pentecostal Church, New Testament Church of God, Redeemed Christian Church of God)|Yes - Evangelical - independent/non-denominational (e.g. FIEC, Pioneer, Vineyard, Newfrontiers)',\n",
      "       'Heterosexual|Gay or lesbian|Bisexual',\n",
      "       'White British|Any other white background|White and Black Caribbean|White and Black African|White and Asian|Any other mixed background|Indian|Pakistani|Bangladeshi|Any other Asian background|Black Caribbean|Black African|Any other black background|Chinese|Other ethnic group',\n",
      "       'No qualifications|Below GCSE|GCSE|A-level|Undergraduate|Postgrad',\n",
      "       'Left|0.5|1.0|1.5|2.0|2.5|3.0|3.5|4.0|4.5|5.0|5.5|6.0|6.5|7.0|7.5|8.0|8.5|9.0|9.5|Right',\n",
      "       'Libertarian|0.5|1.0|1.5|2.0|2.5|3.0|3.5|4.0|4.5|5.0|5.5|6.0|6.5|7.0|7.5|8.0|8.5|9.0|9.5|Authoritarian',\n",
      "       'Men|Female'], dtype=object), array(['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
      "       '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
      "       '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
      "       '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
      "       '', '', '', '', '', '', '', '', '', '', '', '', '', ''],\n",
      "      dtype=object), array(['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
      "       '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
      "       '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
      "       '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
      "       '', '', '', '', '99.0', '', '', '', '', '', '', '', '', ''],\n",
      "      dtype=object), array(['', '', '', \"Don't know\", \"Other|Don't know\", \"Don't know\",\n",
      "       \"Other|Don't know\", \"Don't know\", \"Don't know\", \"Don't know\",\n",
      "       \"Don't know\", \"Don't know\", \"Don't know\", \"Don't know\",\n",
      "       \"Don't know\", \"Don't know\", \"Don't know\", \"Don't know\",\n",
      "       \"Don't know\", \"Don't know\", \"Don't know\", \"Don't know\",\n",
      "       \"Don't know\", \"Don't know\", \"Don't know\", \"Don't know\",\n",
      "       \"Don't know\", \"Don't know\", \"Don't know\", \"Don't know\",\n",
      "       \"Don't know\", \"Don't know\", \"Don't know\",\n",
      "       \"I would not vote|Don't know\", \"Don't know\", \"Don't know\",\n",
      "       \"Don't know\", \"Don't know\", \"Don't know\", \"Don't know\",\n",
      "       \"Don't know\", \"Don't know\", \"Don't know\", \"Don't know\",\n",
      "       \"Don't know\", \"Don't know\", \"Don't know\", \"Don't know\",\n",
      "       \"Don't know\", \"Don't know\", \"Don't know\", \"Don't know\",\n",
      "       \"Don't know\", \"Don't know\", \"Will not vote|Don't know\",\n",
      "       \"Don't know\", \"Don't know\", \"Don't know\", \"Don't know\",\n",
      "       \"Don't know\", \"Don't know\", \"Yes, other|Don't know\", \"Don't know\",\n",
      "       '', '', 'Other', '', '', '', 'Other',\n",
      "       \"Prefer not to answer|Don't know\", 'Other', '', '', '', '',\n",
      "       'Other|Prefer not to say', 'Prefer not to say', '', '', '', ''],\n",
      "      dtype=object), array(['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
      "       '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
      "       '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
      "       '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
      "       '', '', '',\n",
      "       'Own – outright|Own – with a mortgage|Own (part-own) – through shared ownership scheme (i.e. pay part mortgage, part rent)|Rent – from a private landlord|Rent – from my local authority|Rent – from a housing association|Neither – I live with my parents, family or friends but pay some rent to them|Neither – I live rent-free with my parents, family or friends|Other',\n",
      "       '', '', '',\n",
      "       'No, I do not regard myself as belonging to any particular religion|Yes - Church of England/Anglican/Episcopal|Yes - Roman Catholic|Yes - Presbyterian/Church of Scotland|Yes - Methodist|Yes - Baptist|Yes - United Reformed Church|Yes - Free Presbyterian| Yes - Brethren|Yes - Judaism|Yes - Hinduism|Yes - Islam|Yes - Sikhism|Yes - Buddhism|Yes - Other|16.0|Yes – Orthodox Christian|Yes - Pentecostal (e.g. Assemblies of God, Elim Pentecostal Church, New Testament Church of God, Redeemed Christian Church of God)|Yes - Evangelical – independent/non-denominational (e.g. FIEC, Pioneer, Vineyard, Newfrontiers)',\n",
      "       '', '', '', '', '', ''], dtype=object)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipdb> [x for x in data if '\\u2013' in x]\n",
      "[]\n",
      "ipdb> quit\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>dtype</th>\n",
       "      <th>cat_all_strings</th>\n",
       "      <th>type</th>\n",
       "      <th>pruned</th>\n",
       "      <th>original_cat_list</th>\n",
       "      <th>renamed_cat_list</th>\n",
       "      <th>reordered_cat_list</th>\n",
       "      <th>final_cat_list</th>\n",
       "      <th>dataset_specific_hardcoded_fix</th>\n",
       "      <th>numerical_dont_knows</th>\n",
       "      <th>weasel_words</th>\n",
       "      <th>typos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>W26_only</td>\n",
       "      <td>int32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wave</th>\n",
       "      <td>W26_only</td>\n",
       "      <td>int8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight</th>\n",
       "      <td>W26_only</td>\n",
       "      <td>float64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>turnoutUKGeneral</th>\n",
       "      <td>W26_only</td>\n",
       "      <td>category</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>turnoutUKGeneral</td>\n",
       "      <td>Very unlikely that I would vote|Fairly unlikel...</td>\n",
       "      <td>Very unlikely that I would vote|Fairly unlikel...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Very unlikely that I will vote|Fairly unlikely...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Don't know</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>generalElectionVote</th>\n",
       "      <td>W26_only</td>\n",
       "      <td>category</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>generalElectionVote</td>\n",
       "      <td>I would/did not vote|Conservative|Labour|Liber...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I would/did not vote|Conservative|Labour|Liber...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Other|Don't know</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_ethnicity</th>\n",
       "      <td>W26_only</td>\n",
       "      <td>category</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>p_ethnicity</td>\n",
       "      <td>White British|Any other white background|White...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>White British|Any other white background|White...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Prefer not to say</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_edlevel</th>\n",
       "      <td>W26_only</td>\n",
       "      <td>category</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>p_edlevel</td>\n",
       "      <td>No qualifications|Below GCSE|GCSE|A-level|Unde...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No qualifications|Below GCSE|GCSE|A-level|Unde...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lr_scale</th>\n",
       "      <td>W26_only</td>\n",
       "      <td>category</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>lr_scale</td>\n",
       "      <td>Left|0.5|1.0|1.5|2.0|2.5|3.0|3.5|4.0|4.5|5.0|5...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Left|0.5|1.0|1.5|2.0|2.5|3.0|3.5|4.0|4.5|5.0|5...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>al_scale</th>\n",
       "      <td>W26_only</td>\n",
       "      <td>category</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>al_scale</td>\n",
       "      <td>Libertarian|0.5|1.0|1.5|2.0|2.5|3.0|3.5|4.0|4....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Libertarian|0.5|1.0|1.5|2.0|2.5|3.0|3.5|4.0|4....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <td>W26_only</td>\n",
       "      <td>category</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>gender</td>\n",
       "      <td>Men|Female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Men|Female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    dataset_name     dtype cat_all_strings  type  \\\n",
       "id                      W26_only     int32             NaN    -5   \n",
       "wave                    W26_only      int8             NaN    -1   \n",
       "weight                  W26_only   float64             NaN    -1   \n",
       "turnoutUKGeneral        W26_only  category            True     1   \n",
       "generalElectionVote     W26_only  category            True     3   \n",
       "...                          ...       ...             ...   ...   \n",
       "p_ethnicity             W26_only  category            True     3   \n",
       "p_edlevel               W26_only  category            True     1   \n",
       "lr_scale                W26_only  category           False     1   \n",
       "al_scale                W26_only  category           False     1   \n",
       "gender                  W26_only  category            True     1   \n",
       "\n",
       "                                  pruned  \\\n",
       "id                                   NaN   \n",
       "wave                                 NaN   \n",
       "weight                               NaN   \n",
       "turnoutUKGeneral        turnoutUKGeneral   \n",
       "generalElectionVote  generalElectionVote   \n",
       "...                                  ...   \n",
       "p_ethnicity                  p_ethnicity   \n",
       "p_edlevel                      p_edlevel   \n",
       "lr_scale                        lr_scale   \n",
       "al_scale                        al_scale   \n",
       "gender                            gender   \n",
       "\n",
       "                                                     original_cat_list  \\\n",
       "id                                                                 NaN   \n",
       "wave                                                               NaN   \n",
       "weight                                                             NaN   \n",
       "turnoutUKGeneral     Very unlikely that I would vote|Fairly unlikel...   \n",
       "generalElectionVote  I would/did not vote|Conservative|Labour|Liber...   \n",
       "...                                                                ...   \n",
       "p_ethnicity          White British|Any other white background|White...   \n",
       "p_edlevel            No qualifications|Below GCSE|GCSE|A-level|Unde...   \n",
       "lr_scale             Left|0.5|1.0|1.5|2.0|2.5|3.0|3.5|4.0|4.5|5.0|5...   \n",
       "al_scale             Libertarian|0.5|1.0|1.5|2.0|2.5|3.0|3.5|4.0|4....   \n",
       "gender                                                      Men|Female   \n",
       "\n",
       "                                                      renamed_cat_list  \\\n",
       "id                                                                 NaN   \n",
       "wave                                                               NaN   \n",
       "weight                                                             NaN   \n",
       "turnoutUKGeneral     Very unlikely that I would vote|Fairly unlikel...   \n",
       "generalElectionVote                                                NaN   \n",
       "...                                                                ...   \n",
       "p_ethnicity                                                        NaN   \n",
       "p_edlevel                                                          NaN   \n",
       "lr_scale                                                           NaN   \n",
       "al_scale                                                           NaN   \n",
       "gender                                                             NaN   \n",
       "\n",
       "                    reordered_cat_list  \\\n",
       "id                                 NaN   \n",
       "wave                               NaN   \n",
       "weight                             NaN   \n",
       "turnoutUKGeneral                   NaN   \n",
       "generalElectionVote                NaN   \n",
       "...                                ...   \n",
       "p_ethnicity                        NaN   \n",
       "p_edlevel                          NaN   \n",
       "lr_scale                           NaN   \n",
       "al_scale                           NaN   \n",
       "gender                             NaN   \n",
       "\n",
       "                                                        final_cat_list  \\\n",
       "id                                                                 NaN   \n",
       "wave                                                               NaN   \n",
       "weight                                                             NaN   \n",
       "turnoutUKGeneral     Very unlikely that I will vote|Fairly unlikely...   \n",
       "generalElectionVote  I would/did not vote|Conservative|Labour|Liber...   \n",
       "...                                                                ...   \n",
       "p_ethnicity          White British|Any other white background|White...   \n",
       "p_edlevel            No qualifications|Below GCSE|GCSE|A-level|Unde...   \n",
       "lr_scale             Left|0.5|1.0|1.5|2.0|2.5|3.0|3.5|4.0|4.5|5.0|5...   \n",
       "al_scale             Libertarian|0.5|1.0|1.5|2.0|2.5|3.0|3.5|4.0|4....   \n",
       "gender                                                      Men|Female   \n",
       "\n",
       "                    dataset_specific_hardcoded_fix numerical_dont_knows  \\\n",
       "id                                             NaN                  NaN   \n",
       "wave                                           NaN                  NaN   \n",
       "weight                                         NaN                  NaN   \n",
       "turnoutUKGeneral                               NaN                  NaN   \n",
       "generalElectionVote                            NaN                  NaN   \n",
       "...                                            ...                  ...   \n",
       "p_ethnicity                                    NaN                  NaN   \n",
       "p_edlevel                                      NaN                  NaN   \n",
       "lr_scale                                       NaN                  NaN   \n",
       "al_scale                                       NaN                  NaN   \n",
       "gender                                         NaN                  NaN   \n",
       "\n",
       "                          weasel_words typos  \n",
       "id                                 NaN   NaN  \n",
       "wave                               NaN   NaN  \n",
       "weight                             NaN   NaN  \n",
       "turnoutUKGeneral            Don't know   NaN  \n",
       "generalElectionVote   Other|Don't know   NaN  \n",
       "...                                ...   ...  \n",
       "p_ethnicity          Prefer not to say   NaN  \n",
       "p_edlevel                          NaN   NaN  \n",
       "lr_scale                           NaN   NaN  \n",
       "al_scale                           NaN   NaN  \n",
       "gender                             NaN   NaN  \n",
       "\n",
       "[82 rows x 13 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_type#.to_csv( data_subfolder + \"var_type.csv\", encoding = encoding )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dataset_name                      False\n",
       "dtype                             False\n",
       "cat_all_strings                   False\n",
       "type                              False\n",
       "pruned                            False\n",
       "original_cat_list                 False\n",
       "renamed_cat_list                  False\n",
       "reordered_cat_list                False\n",
       "final_cat_list                    False\n",
       "dataset_specific_hardcoded_fix    False\n",
       "numerical_dont_knows              False\n",
       "weasel_words                      False\n",
       "typos                             False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_type.apply(lambda x: '\\u2013' in x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['genElecTurnoutRetro', 'likeUKIP', 'likeUKIPLeader', 'cvEconSelf',\n",
       "       'euRefVote', 'govtHandleVaccine', 'govtHandlelockdown', 'immigCultural',\n",
       "       'welshgovtHandleVaccine', 'welshgovtHandlelockdown',\n",
       "       'scotgovtHandleVaccine', 'scotgovtHandlelockdown'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_fixing_advice_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "BES_Panel[col].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BES_numeric[col].cat.rename_categories( BES_numeric[col].cat.categories.map(str), inplace=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_categories[variable_categories[\"column_name\"].apply(lambda x: \"turnoutUKGeneral\" in x if not pd.isna(x) else False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_range = set(variable_categories[\"type\"].values)\n",
    "# for typ in type_range:\n",
    "#     pruned_variable_name = prune2( prune(col) )\n",
    "#     if pruned_variable_name in var_cat_dict_pruned_2[typ]:\n",
    "#         var_type.loc[col,\"type\"] = typ\n",
    "#         var_type.loc[col,\"pruned\"] = pruned_variable_name\n",
    "#         not_found = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_categories = pd.read_csv( BES_small_data_files + \"question_categories_correct.csv\",\n",
    "                                   encoding = encoding,index_col=False,\n",
    "#                                   usecols=[\"question\",\"frequency\",\"question_length\",\n",
    "#                                                                                \"question_options\",\"column_name\",\"type\"]\n",
    "                                 )\n",
    "variable_categories.drop('Unnamed: 0', axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_categories.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_type.loc['age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
