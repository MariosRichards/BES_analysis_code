{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Nice clean supervised learning setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "import re\n",
    "\n",
    "from itertools import cycle\n",
    "from IPython.display import display\n",
    "import pickle, os\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "encoding = \"ISO-8859-1\"\n",
    "\n",
    "import Jupyter_module_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# you should clone this git to this subdirectory (in some directory - I call it BES_analysis - doesn't matter though)\n",
    "\n",
    "if os.getcwd().split(os.sep)[-1] != 'BES_analysis_code':\n",
    "    raise Exception(\"Stop! You're in the wrong directory - should be in 'BES_analysis_code'\")\n",
    "\n",
    "BES_code_folder   = \"../BES_analysis_code/\" # we should be here!\n",
    "BES_small_data_files = BES_code_folder + \"small data files\" + os.sep\n",
    "if not os.path.exists( BES_small_data_files ):\n",
    "    os.makedirs( BES_small_data_files )\n",
    "\n",
    "# we should create these if they don't already exist\n",
    "BES_data_folder   = \"../BES_analysis_data/\"\n",
    "if not os.path.exists( BES_data_folder ):\n",
    "    os.makedirs( BES_data_folder )\n",
    "\n",
    "BES_output_folder = \"../BES_analysis_output/\"\n",
    "if not os.path.exists( BES_output_folder ):\n",
    "    os.makedirs( BES_output_folder )\n",
    "    \n",
    "BES_file_manifest = pd.read_csv( BES_small_data_files + \"BES_file_manifest.csv\" )\n",
    "\n",
    "BES_R_data_files = BES_data_folder + \"R_data\" + os.sep\n",
    "if not os.path.exists( BES_R_data_files ):\n",
    "    os.makedirs( BES_R_data_files )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.decomposition import PCA, IncrementalPCA, NMF, TruncatedSVD, FastICA, FactorAnalysis, SparsePCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "from gaussian_kde import gaussian_kde\n",
    "from utility import display_components, display_pca_data, weighted_kde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-23ca4012ddde>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxgb_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXGBRegressor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDMatrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplot_tree\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "# del xgboost\n",
    "xgb_dir = \"C:\\\\Users\\\\Marios\\\\AppData\\\\Local\\\\conda\\\\conda\\\\envs\\\\BES_analysis\\\\Lib\\\\site-packages\\\\xgboost\"\n",
    "import sys, os\n",
    "sys.path.append(xgb_dir)\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier, XGBRegressor, DMatrix, cv, plot_tree\n",
    "\n",
    "# First XGBoost model for Pima Indians dataset\n",
    "import graphviz\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, mean_absolute_error, explained_variance_score, r2_score\n",
    "from sklearn import cross_validation, metrics   #Additional scklearn functions\n",
    "from sklearn.grid_search import GridSearchCV   #Perforing grid search\n",
    "\n",
    "from boostaroota import BoostARoota\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from boruta import BorutaPy\n",
    "\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "import shap\n",
    "shap.initjs()\n",
    "\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 4\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from xgboost_tuner.tuner import tune_xgb_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# conda install -c anaconda py-xgboost\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_name = \"W13_comb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BES_Panel (68625, 5150)\n",
      "Wall time: 6.72 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "manifest = BES_file_manifest[ BES_file_manifest[\"Name\"] == dataset_name ]\n",
    "\n",
    "data_subfolder = BES_data_folder + dataset_name + os.sep\n",
    "\n",
    "dataset_filename = manifest[\"Stata_Filename\"].values[0]\n",
    "# dataset_description = manifest[\"Friendlier_Description\"].values[0]\n",
    "# dataset_citation = manifest[\"Citation\"].values[0]\n",
    "# dataset_start = manifest[\"Date_Start\"].values[0]\n",
    "# dataset_stop = manifest[\"Date_Stop\"].values[0]\n",
    "# dataset_wave = manifest[\"Wave No\"].values[0]\n",
    "\n",
    "BES_Panel  = pd.read_msgpack(data_subfolder + dataset_filename.replace('.dta','.msgpack'))\n",
    "print(\"BES_Panel\", BES_Panel.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var_type (5173, 8)\n"
     ]
    }
   ],
   "source": [
    "####\n",
    "\n",
    "# BES_numeric = pd.read_hdf( data_subfolder + \"BESnumeric.hdf\", \"BESnumeric\" )\n",
    "# print(\"BES_numeric\",  BES_numeric.shape )\n",
    "try:\n",
    "    var_type    = pd.read_hdf( data_subfolder + \"var_type.hdf\", encoding=encoding)\n",
    "except:\n",
    "    var_type    = pd.read_csv( data_subfolder + \"var_type.csv\", encoding=encoding)\n",
    "    var_type.set_index(\"Unnamed: 0\", inplace=True)\n",
    "print(\"var_type\",  var_type.shape )\n",
    "\n",
    "fname = data_subfolder + \"cat_dictionary.pkl\"\n",
    "with open(fname, \"rb\") as f:\n",
    "    cat_dictionary = pickle.load( f )\n",
    "    \n",
    "####\n",
    "\n",
    "# BES_non_numeric = pd.read_hdf( data_subfolder + \"BESnon_numeric.hdf\", \"BESnon_numeric\" )\n",
    "# print(\"BES_non_numeric\",  BES_non_numeric.shape )\n",
    "\n",
    "# BES_reduced = pd.read_hdf( data_subfolder + \"BES_reduced.hdf\", \"BES_reduced\" )\n",
    "# print(\"BES_reduced\",  BES_reduced.shape )\n",
    "\n",
    "# BES_reduced_with_na = pd.read_hdf( data_subfolder + \"BES_reduced_with_na.hdf\", \"BES_reduced_with_na\")\n",
    "# print(\"BES_reduced_with_na\", BES_reduced_with_na.shape )\n",
    "\n",
    "# fname = data_subfolder + \"new_old_col_names.pkl\"\n",
    "# with open(fname, \"rb\") as f:\n",
    "#     new_old_col_names = pickle.load(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduction process\n",
    "\n",
    "# median imputation\n",
    "\n",
    "# many_cat_drop_list\n",
    "\n",
    "# high_corr_drop_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:BES_analysis]",
   "language": "python",
   "name": "conda-env-BES_analysis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
