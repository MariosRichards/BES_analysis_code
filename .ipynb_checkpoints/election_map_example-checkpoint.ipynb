{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Election Maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook (which is *subject to change*) provides some early sketches of generating maps that can be used to support election reporting for the UK General Election 2015."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install --upgrade folium\n",
    "#Use the latest version of folium pulled directly from github\n",
    "# !pip3 install --upgrade  git+git://github.com/python-visualization/folium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to work in *pandas* wherever possible and use the *folium* package (which employs the *leaflet* library) to support the mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've found *folium*'s notebook support to be flakey at time. This approach from the early days of folium still seems robust?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inline_map(map):\n",
    "    \"\"\"\n",
    "    Embeds the HTML source of the map directly into the IPython notebook.\n",
    "    \n",
    "    This method will not work if the map depends on any files (json data). Also this uses\n",
    "    the HTML5 srcdoc attribute, which may not be supported in all browsers.\n",
    "    \"\"\"\n",
    "    map._build_map()\n",
    "    return HTML('<iframe srcdoc=\"{srcdoc}\" style=\"width: 100%; height: 510px; border: none\"></iframe>'.format(srcdoc=map.HTML.replace('\"', '&quot;')))\n",
    "\n",
    "def embed_map(map, path=\"map.html\"):\n",
    "    \"\"\"\n",
    "    Embeds a linked iframe to the map into the IPython notebook.\n",
    "    \n",
    "    Note: this method will not capture the source of the map into the notebook.\n",
    "    This method should work for all maps (as long as they use relative urls).\n",
    "    \"\"\"\n",
    "    map.create_map(path=path)\n",
    "    return HTML('<iframe src=\"files/{path}\" style=\"width: 100%; height: 510px; border: none\"></iframe>'.format(path=path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Electoral Boundaries - Shapefiles\n",
    "\n",
    "Martin Chorley has collected together a range of useful shapefiles in geojson and TopoJSON formats  that describe various electoral boundaries ([martinjc/UK-GeoJSON](https://github.com/martinjc/UK-GeoJSON))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "url='https://github.com/martinjc/UK-GeoJSON/blob/master/json/electoral/gb/wpc.json?raw=true'\n",
    "r = requests.get(url)\n",
    "with open(\"wpc.json\", \"wb\") as code:\n",
    "    code.write(r.content)\n",
    "r=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chris Hanretty *et al.* are making election forecasts based on aggregated poll data available at [electionforecast.co.uk](http://www.electionforecast.co.uk/).\n",
    "\n",
    "We can grab the data into a data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "lxml not found, please install it",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-868ca60d6461>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_html\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'http://www.electionforecast.co.uk/tables/predicted_probability_by_seat.html'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\ANACON~1\\envs\\BES_analysis\\lib\\site-packages\\pandas\\io\\html.py\u001b[0m in \u001b[0;36mread_html\u001b[0;34m(io, match, flavor, header, index_col, skiprows, attrs, parse_dates, tupleize_cols, thousands, encoding)\u001b[0m\n\u001b[1;32m    872\u001b[0m     \u001b[0m_validate_header_arg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m     return _parse(flavor, io, match, header, index_col, skiprows,\n\u001b[0;32m--> 874\u001b[0;31m                   parse_dates, tupleize_cols, thousands, attrs, encoding)\n\u001b[0m",
      "\u001b[0;32mC:\\ANACON~1\\envs\\BES_analysis\\lib\\site-packages\\pandas\\io\\html.py\u001b[0m in \u001b[0;36m_parse\u001b[0;34m(flavor, io, match, header, index_col, skiprows, parse_dates, tupleize_cols, thousands, attrs, encoding)\u001b[0m\n\u001b[1;32m    724\u001b[0m     \u001b[0mretained\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mflav\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mflavor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 726\u001b[0;31m         \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parser_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflav\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    727\u001b[0m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompiled_match\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ANACON~1\\envs\\BES_analysis\\lib\\site-packages\\pandas\\io\\html.py\u001b[0m in \u001b[0;36m_parser_dispatch\u001b[0;34m(flavor)\u001b[0m\n\u001b[1;32m    683\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_HAS_LXML\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"lxml not found, please install it\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_valid_parsers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mflavor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: lxml not found, please install it"
     ]
    }
   ],
   "source": [
    "df=pd.read_html('http://www.electionforecast.co.uk/tables/predicted_probability_by_seat.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-586703022608>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If necessary, grab a local copy... (really should add a timestamp to the filename...)\n",
    "df[0].to_csv('data/pred.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp=pd.DataFrame({'val':[100],'const':['Aldershot']})\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head data/pred.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Mapping\n",
    "\n",
    "We can use a choropleth map to display the forecast percentage for a particular party.\n",
    "\n",
    "The *folium* `map` object will accept a path to a geojson file, associating each polygon with a key value into the geojson object specified in the `key-on` parameter.\n",
    "\n",
    "In this case we want to match on Westminster Parliamentary constituency names as described in the `seat` column of the *electionforecast* data. Inspection of the the geojson file shows that the seat name is available as a key value along the path `feature.properties.PCON13NM`.\n",
    "\n",
    "![](https://farm8.staticflickr.com/7653/16764352245_6a0535028a_b.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "//example image screenshot (maps won't work in previewer...)\n",
    "\n",
    "![](https://farm8.staticflickr.com/7653/16578653199_8bc1428433_b.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map = folium.Map(location=[53, 0],zoom_start=6)\n",
    "map.geo_json(geo_path='wpc.json', data=df[0],data_out='data.json', columns=['Seat', 'Labour'],\n",
    "             key_on='feature.properties.PCON13NM',threshold_scale=[0, 20, 40, 60, 80, 100],\n",
    "             fill_color='OrRd')\n",
    "embed_map(map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inline_map(map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Who's the Favourite?\n",
    "\n",
    "We can find the favourite party for each seat by transforming the *electionforecast* data to a long format, grouping by seat, sorting in a descending order the parties by forecast value and then picking the first in each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wpc_long=pd.melt(df[0],id_vars=['Seat','Region','2010'])\n",
    "#http://stackoverflow.com/a/19818942\n",
    "wpc_favourite=wpc_long.sort('value', ascending=False).groupby('Seat', as_index=False).first()\n",
    "wpc_favourite[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wpc_favourite[ wpc_favourite['Seat']=='Isle of Wight' ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##How's the Betting?\n",
    "\n",
    "As well as the *electionforecast* predictions, we can also look to see what the betting markets predict. The [tellmetheodds](http://tellmetheodds.co.uk/odds) site is currently running a prediction showing the likelihood of Labour or the Conservatives winning the largest number of seats. This site looks like it could be an output of Swansea University's AHRC funded ['What are the odds?  Capturing and exploring data created by online political gambling markets'](http://www.swansea.ac.uk/riah/research-projects/what-are-the-odds/) project?\n",
    "\n",
    "I can't find the data collected as part of that project anywhere obvious, so in an unfunded act I threw together a quick daily scraper of election betting odds offered by a variety of bookmakers on a per-seat basis grabbed once a day from [oddschecker](http://www.oddschecker.com/politics/british-politics) (if they can scrape, so can I...;-). You can find it here: [UK general election 2015 daily seat odds scraper *on morhp.io*](https://morph.io/psychemedia/electionodds).\n",
    "\n",
    "So for example, I can run commands like:\n",
    "\n",
    "`SELECT * FROM 'IW2015GE' iw, (SELECT MAX(time) AS maxt FROM 'IW2015GE' LIMIT 1) WHERE time=maxt GROUP BY bookie`\n",
    "\n",
    "against the *morph.io* SQLite API to pull back the latest odds for the Isle of Wight constituency grouped by bookie.\n",
    "\n",
    "Or I can download the complete database and plot the time series evolution of the odds being ofference for different parties by different bookmakers for different seats over time.\n",
    "\n",
    "One things I was wondering whether I'd be able to run automatic breakout detection scripts over all the separate candidates/parties in each constituency once a day to see wheteher there were any step changes which could perhaps signal local news...\n",
    "\n",
    "I'll try to put together some demos of using the betting data in the next couple of weeks...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:BES_analysis]",
   "language": "python",
   "name": "conda-env-BES_analysis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
