{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "import re\n",
    "\n",
    "from itertools import cycle\n",
    "from IPython.display import display\n",
    "import pickle, os\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from IPython.core.debugger import set_trace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you should clone this git to this subdirectory (in some directory - I call it BES_analysis - doesn't matter though)\n",
    "\n",
    "if os.getcwd().split(os.sep)[-1] != 'BES_analysis_code':\n",
    "    raise Exception(\"Stop! You're in the wrong directory - should be in 'BES_analysis_code'\")\n",
    "\n",
    "BES_code_folder   = \"../BES_analysis_code/\" # we should be here!\n",
    "BES_small_data_files = BES_code_folder + \"small data files\" + os.sep\n",
    "if not os.path.exists( BES_small_data_files ):\n",
    "    os.makedirs( BES_small_data_files )\n",
    "\n",
    "# we should create these if they don't already exist\n",
    "BES_data_folder   = \"../BES_analysis_data/\"\n",
    "if not os.path.exists( BES_data_folder ):\n",
    "    os.makedirs( BES_data_folder )\n",
    "\n",
    "BES_output_folder = \"../BES_analysis_output/\"\n",
    "if not os.path.exists( BES_output_folder ):\n",
    "    os.makedirs( BES_output_folder )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Jupyter_module_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = \"ISO-8859-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "## HELPER FUNCTIONS / REPLACEMENT VALUE DICTIONARIES\n",
    "\n",
    "# Rename -> Reorder\n",
    "\n",
    "# changing the order of some sets of categories\n",
    "change_cat_dict = {\"Bad time to buy|Good time to buy|Neither good nor bad time to buy|Don't know\": [\"Bad time to buy\",\n",
    "                                                                                                    \"Neither good nor bad time to buy\",\n",
    "                                                                                                    \"Good time to buy\",\n",
    "                                                                                                    \"Don't know\"],\n",
    "                   \"Larger|Smaller|About the same|Don't know\": [\"Larger\", \"About the same\", \"Smaller\",\"Don't know\"],\n",
    "                   \"Yes|No|99.0\":       ['No', 'Yes', '99.0'],\n",
    "                   \"Yes|No|Don't know\": ['No', 'Yes', \"Don't know\"],\n",
    "                   \"Yes|No\" :           ['No', 'Yes'],                   \n",
    "                   \"Yes|No|Did not vote|Don't know\" : [\"No\",\"Yes\",\"Did not vote\",\"Don't know\"],\n",
    "                   \"Yes, voted|No, did not vote|Don't know\" : [\"No, did not vote\", \"Yes, voted\", \"Don't know\"],\n",
    "                   \"I would/will not vote|Leave the EU|Stay in the EU|Don't know\":\n",
    "                       ['Stay in the EU', 'Leave the EU', 'I would/will not vote', \"Don't know\"],\n",
    "                   \"Mainly leave|Mainly remain|Fairly evenly divided|Don't know\": [\"Mainly remain\",\n",
    "                                                                                   \"Fairly evenly divided\", \"Mainly leave\", \"Don't know\"],\n",
    "                   \"An individual share in a company|A portfolio of different company shares|The risk is the same|Don't know|Prefer not to say\":\n",
    "                       ['An individual share in a company', 'The risk is the same', 'A portfolio of different company shares',\"Prefer not to say\",\"Don't know\"],\n",
    "                   \"No, I have never been a member|Yes, I am a member of a party|I am not a member now but I used to be|Don't know\":\n",
    "                       ['No, I have never been a member', 'I am not a member now but I used to be', 'Yes, I am a member of a party', \"Don't know\"],\n",
    "                   \"Never or practically never|Less often than once a year|Less often but at least once a year|Less often but at least twice a year|Less often but at least once a month|Less often but at least once in two weeks|Once a week or more|Varies too much to say|I am not religious|Don't know\":\n",
    "                       ['I am not religious', 'Never or practically never', 'Less often than once a year',\n",
    "                        'Less often but at least once a year', 'Less often but at least twice a year',\n",
    "                        'Less often but at least once a month', 'Less often but at least once in two weeks',\n",
    "                        'Once a week or more', \"Varies too much to say\",\"Don't know\"],\n",
    "                   \"under £5,000 per year|£5,000 to £9,999 per year|£10,000 to £14,999 per year|£15,000 to £19,999 per year|£20,000 to £24,999 per year|£25,000 to £29,999 per year|£30,000 to £34,999 per year|£35,000 to £39,999 per year|£40,000 to £44,999 per year|£45,000 to £49,999 per year|£50,000 to £59,999 per year|£60,000 to £69,999 per year|£70,000 to £99,999 per year|£100,000 to £149,999 per year|£150,000 and over|Don't know|Prefer not to answer\":\n",
    "                       [ 'under £5,000 per year',\n",
    "                         '£5,000 to £9,999 per year',\n",
    "                         '£10,000 to £14,999 per year',\n",
    "                         '£15,000 to £19,999 per year',\n",
    "                         '£20,000 to £24,999 per year',\n",
    "                         '£25,000 to £29,999 per year',\n",
    "                         '£30,000 to £34,999 per year',\n",
    "                         '£35,000 to £39,999 per year',\n",
    "                         '£40,000 to £44,999 per year',\n",
    "                         '£45,000 to £49,999 per year',\n",
    "                         '£50,000 to £59,999 per year',\n",
    "                         '£60,000 to £69,999 per year',\n",
    "                         '£70,000 to £99,999 per year',\n",
    "                         '£100,000 to £149,999 per year',\n",
    "                         '£150,000 and over',                         \n",
    "                         'Prefer not to answer',\n",
    "                         \"Don't know\",], # change order of \"don't know\" and \"prefer not to answer\" to keep don't knows last\n",
    "                   \"1|2|3|4|5|6|7|8 or more|Don't know|Prefer not to say\":\n",
    "                       [\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8 or more\",\"Prefer not to say\",\"Don't know\"],\n",
    "                   \"The Yes side|The No side|Neither|Don't know\":\n",
    "                       [\"The Yes side\",\"Neither\",\"The No side\",\"Don't know\"], # is this ordinal - meh?\n",
    "                   \"1|2|3|4|5|6|7|8|9|Right  10|Don't know|Left  0\":\n",
    "                       [\"Left  0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"Right  10\",\"Don't know\"], # lrMayW12\n",
    "                   \"No|Yes, received a dose|Yes, booked an appointment|Don't know\":\n",
    "                       [\"No\",\"Yes, booked an appointment\",\"Yes, received a dose\",\"Don't know\"],#\n",
    "\n",
    "                   \n",
    "                  }\n",
    "\n",
    "reorder_variable_dict = pd.DataFrame.from_dict({k : \"|\".join(v) for k, v in change_cat_dict.items()},orient='index').reset_index()\n",
    "reorder_variable_dict.columns = [\"original_cat_list\",\"reordered_cat_list\"]\n",
    "reorder_variable_dict.to_csv( BES_small_data_files + \"reorder_variable_dict.csv\" )\n",
    "\n",
    "# reorder categories\n",
    "def re_order(ques):\n",
    "    if ques in change_cat_dict.keys():\n",
    "        return \"|\".join( change_cat_dict[ques] )\n",
    "    else:\n",
    "        return ques\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "## typos - more directly useful for the BES!\n",
    "# typos = set(['Do\\x92t know', 'Dont know', 'Donât know', 'Don??t know','DonaÂ€Â™t know'])# ,\n",
    "#          \"9999.0\", \"997.0\", \"222.0\", \"99.0\", \"0.0\", \"1.0\", \"2.0\"   ]) # problem here, is this picks up numeric sequences ...\n",
    "\n",
    "\n",
    "\n",
    "# Big set of actual answers **I interpet** as non-answers (and set to NaN)\n",
    "# REALLY MERITS RECHECKING WHAT THE IMPACT OF THIS IS!\n",
    "Weasel_answers = [\"Don't know\",\"Donâ€™t know\",\n",
    "                  \"Prefer not to say\", \"Prefer not to answer\", \"Refused\", \"Unknown\",\n",
    "                  \"Neither\", \"Other\", \"I would/will not vote\", \"Will not vote\",\n",
    "                  \"I would not vote\", \"It depends\", \"Other\",\n",
    "                  \"Don't follow politics on twitter\",\n",
    "                  \"Yes, other\", \"Haven't thought about it\",\n",
    "                  \"There wasn't a local election in my area\", \"No, haven't received it\",\n",
    "                  \"I don't know what was negotiated\", \"I never received a response\",\n",
    "                  \"There are not local elections in my area\", \"Can't remember\",\n",
    "                  \"Varies too much to say\", \"Will not state a choice\",\n",
    "                  \"All leaders equally good\", \"They are not eligible to vote\",\n",
    "                  \"There are not local elections in my area\", \"Both/neither\",\n",
    "                  \"Did not vote\",\"Can't remember\",\n",
    "                  \"Not sure\",\"Did not choose a candidate\",\"There wasn't a Mayoral Election in my area\",\n",
    "                  \"NA\",\"They did not vote\",\"They were not eligible to vote\",\"Don't know / Prefer not to say\"\n",
    "]\n",
    "\n",
    "# BES codes for NaN/other/misc/none of the above\n",
    "Weasel_number_answers = [ \"9999.0\", \"997.0\", \"222.0\", \"99.0\", \"0.0\", \"9999\", \"98.0\" ]\n",
    "\n",
    "# non-answer answers\n",
    "Weasel_set = set(Weasel_answers) # gets rid of duplicates!\n",
    "\n",
    "\n",
    "## define 'de_Weasel' function to remove Weasel Words from lists of options\n",
    "## ie. \"Yes|No|Don't know\" -> \"Yes|No\"\n",
    "\n",
    "# Weasel_answers = [\"Don't know\", 'Don?t know', 'Donâ??t know', 'Do\\x92t know', 'Dont know', 'Donât know',\n",
    "#                   \"Prefer not to say\", \"Prefer not to answer\", \"Refused\", \"Unknown\", \"Neither\", \"Other\",\n",
    "#                   \"I would/will not vote\", \"Will not vote\", \"No - not decided\", \"I would not vote\", \"It depends\",\n",
    "#                   \"Other\", \"Don’t follow politics on Facebook\", \"Don't follow politics on twitter\", \"9999.0\", \"997.0\",\n",
    "#                   \"222.0\", \"Yes, other\", \"Haven't thought about it\", \"There wasn't a local election in my area\",\n",
    "#                   \"No, haven't received it\", \"I don't know what was negotiated\", \"I never received a response\",\n",
    "#                   \"There are not local elections in my area\", \"Can't remember\", \"Varies too much to say\" ]\n",
    "\n",
    "# # non-answer answers\n",
    "# Weasel_set = set(Weasel_answers) # gets rid of duplicates!\n",
    "\n",
    "# remove weasel phrases\n",
    "def de_weasel(ques): \n",
    "    return \"|\".join( [x for x in ques.split(\"|\") if x not in Weasel_answers] )\n",
    "\n",
    "def de_num_el(el):\n",
    "    if el.isdigit():\n",
    "        el = \"%.1f\" % int( el )\n",
    "    return el\n",
    "\n",
    "def de_number(ques):\n",
    "    return \"|\".join( [de_num_el(x) for x in ques.split(\"|\")] )\n",
    "\n",
    "def de_num(ques):\n",
    "    return [de_num_el(x) for x in ques]\n",
    "\n",
    "def floatable(flt):\n",
    "    try:\n",
    "        float(flt)\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "# Weasel_number_answers\n",
    "# Remove 'weasel' numbers\n",
    "# but only if they are the last element\n",
    "# or not the last element, but the next is not a number\n",
    "# to avoid catching parts of sequential numerical categories\n",
    "def de_weasel_numbers(ques):\n",
    "    el_list = ques.split(\"|\")\n",
    "    el_list_len = len(el_list)\n",
    "    remove_list = []\n",
    "    for el_pos in range( 0, el_list_len ):\n",
    "        if el_list[el_pos] in Weasel_number_answers:\n",
    "            # last element, or not last element but next element is a not a number\n",
    "            if el_pos==(el_list_len-1) or not floatable(el_list[el_pos+1]):\n",
    "                remove_list.append(el_list[el_pos])\n",
    "\n",
    "    return \"|\".join( [x for x in el_list if x not in remove_list] )\n",
    "\n",
    "\n",
    "# version to act directly on cat.categories array\n",
    "def de_weasel_nums(el_list):\n",
    "\n",
    "    el_list_len = len(el_list)\n",
    "    remove_list = []\n",
    "    for el_pos in range( 0, el_list_len ):\n",
    "        if el_list[el_pos] in Weasel_number_answers:\n",
    "            # last element, or not last element but next element is a not a number\n",
    "            if el_pos==(el_list_len-1) or not floatable(el_list[el_pos+1]):\n",
    "                remove_list.append(el_list[el_pos])\n",
    "\n",
    "    return remove_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s.cat.rename_categories([1,2,3])\n",
    "# EUContactRemainConW8|EUContactRemainLabW8|EUContactRemainLDW8|\n",
    "# EUContactRemainSNPW8|EUContactRemainPCW8|EUContactRemainUKIPW8|\n",
    "# EUContactRemainGreenW8|EUContactRemainOthW8|EUContactRemainNoneW8|\n",
    "# EUContactRemainDKW8|EUContactLeaveConW8|EUContactLeaveLabW8|\n",
    "# EUContactLeaveLDW8|EUContactLeaveSNPW8|EUContactLeavePCW8|\n",
    "# EUContactLeaveUKIPW8|EUContactLeaveGreenW8|EUContactLeaveOthW8|\n",
    "# EUContactLeaveNoneW8|EUContactLeaveDKW8\n",
    "\n",
    "# pattern match \"EUContact*****W8\"\n",
    "# debateOneWatchW8|debateTwoWatchW8\n",
    "\n",
    "# \"1.0|2.0|99.0\" -> \n",
    "\n",
    "# euRefVoteSqueezeW7 \"Will not vote|Yes - Leave|Yes - Remain|No - not decided\"\n",
    "#    -> Stay/remain in the EU|Leave the EU|I would/will not vote|Don't know\n",
    "#    HMM - RENAME AND REORDER!\n",
    "\n",
    "# miieuW7\n",
    "# \"Issue stated|Nothing|Don't know\" -> \"Issue stated|None|Don't know\"\n",
    "# MIIEUW8\n",
    "# \"1.0|Nothing|Don't know\" -> \"Issue stated|None|Don't know\"\n",
    "# partyIdEUW7|partyIdEUW8\n",
    "# \"Mainly leave|Mainly remain|Fairly evenly split|Don't know\" -> \"Mainly remain|Fairly evenly divided|Mainly leave|Don't know\"\n",
    "#    HMM - RENAME AND REORDER!\n",
    "\n",
    "# 1. campaignVisionYesW3|campaignVisionNoW3, govtNatSecuritySuccessW4\n",
    "# Very unsuccessful|Fairly unsuccessful|Neither successful nor unsuccessful|Fairly successful|Very successful|Don't know\n",
    "# Very unsuccessful|Somewhat unsuccessful|Neither successful or unsuccessful|Somewhat successful|Very successful|Don't know\n",
    "\n",
    "# Fairly <-> Somewhat\n",
    "\n",
    "# 2. euroTurnoutW1, scotReferendumTurnoutW1|scotReferendumTurnoutW2|welshTurnoutW7|scotTurnoutW7, turnoutUKGeneralW1|turnoutUKGeneralW2|turnoutUKGeneralW3|turnoutUKGeneralW4|turnoutUKGeneralW5|euRefTurnoutW7|euRefTurnoutW8\n",
    "# Very unlikely that I vote|Fairly unlikely|Neither likely nor unlikely|Fairly likely|Very likely that I vote|Don't know\n",
    "# Very unlikely that I would vote|Fairly unlikely|Neither likely nor unlikely|Fairly likely|Very likely that I would vote|Don't know\n",
    "# There are not local elections in my area\n",
    "    #|Very unlikely that I will vote|Fairly unlikely|Neither likely nor unlikely|Fairly likely|Very likely that I will vote|Don't know\n",
    "# Very unlikely that I will vote|Fairly unlikely|Neither likely nor unlikely|Fairly likely|Very likely that I will vote|Don't know\n",
    "\n",
    "# \"Very unlikely that I vote\", \"Very unlikely that I would vote\" ->  \"Very unlikely that I will vote\" \n",
    "\n",
    "rename_cat_dict = {\"North East|North West\": [ \"No\", \"Yes\" ],\n",
    "                   \"1.0|2.0|99.0\": [\"No\", \"Yes\", \"99.0\"],\n",
    "                   \"Will not vote|Yes - Leave|Yes - Remain|No - not decided\":\n",
    "                       ['I would/will not vote', 'Leave the EU','Stay in the EU', \"Don't know\"], \n",
    "                   \"Stay/remain in the EU|Leave the EU|I would/will not vote|Don't know\":\n",
    "                       ['Stay in the EU','Leave the EU',  'I would/will not vote', \"Don't know\"],   # euRefVote    \n",
    "                   \"Stay/remain in the EU|Leave the EU|Don't know\":\n",
    "                       ['Stay in the EU','Leave the EU', \"Don't know\"],   # profile_eurefvote                    \n",
    "                   \"Issue stated|Nothing|Don't know\":  ['Issue stated', 'None', \"Don't know\"],\n",
    "                   \"1.0|Nothing|Don't know\":           ['Issue stated', 'None', \"Don't know\"],\n",
    "                   \"a|b|C1|C2|d|e|Refused|Unknown\" : ['A', 'B', 'C1', 'C2', 'D', 'E', 'Refused', 'Unknown'],\n",
    "                   \"Mainly leave|Mainly remain|Fairly evenly split|Don't know\":\n",
    "                       ['Mainly leave','Mainly remain', 'Fairly evenly divided', \"Don't know\"],\n",
    "                   \"Very unsuccessful|Somewhat unsuccessful|Neither successful or unsuccessful|Somewhat successful|Very successful|Don't know\":\n",
    "                       ['Very unsuccessful', 'Fairly unsuccessful', 'Neither successful nor unsuccessful',\n",
    "                        'Fairly successful', 'Very successful', \"Don't know\"],\n",
    "                   \"Very unlikely that I vote|Fairly unlikely|Neither likely nor unlikely|Fairly likely|Very likely that I vote|Don't know\":\n",
    "                       ['Very unlikely that I will vote', 'Fairly unlikely', 'Neither likely nor unlikely',\n",
    "                        'Fairly likely', 'Very likely that I will vote', \"Don't know\"],\n",
    "                   \"Very unlikely that I would vote|Fairly unlikely|Neither likely nor unlikely|Fairly likely|Very likely that I would vote|Don't know\":\n",
    "                       ['Very unlikely that I will vote', 'Fairly unlikely', 'Neither likely nor unlikely',\n",
    "                        'Fairly likely', 'Very likely that I will vote', \"Don't know\"],\n",
    "                   \"No, did not vote|Yes, voted|3.0|4.0|5.0|Don't know\":   \n",
    "                       [\"Very unlikely that I will vote\", \"Fairly unlikely\", 'Neither likely nor unlikely',\n",
    "                        \"Fairly likely\", \"Very likely that I will vote\", \"Don't know\"], #londonTurnoutW7\n",
    "                   'No, I do not regard myself as belonging to any particular religion.|Yes - Church of England/Anglican/Episcopal|Yes - Roman Catholic|Yes - Presbyterian/Church of Scotland|Yes - Methodist|Yes - Baptist|Yes - United Reformed Church|Yes - Free Presbyterian|Yes - Brethren|Yes - Judaism|Yes - Hinduism|Yes - Islam|Yes - Sikhism|Yes - Buddhism|Yes - Other|Prefer not to say|Yes Orthodox Christian|Yes - Pentecostal (e.g. Assemblies of God, Elim Pentecostal Church, New Testament Church of God, Redeemed Christian Chur|Yes - Evangelical independent/non-denominational (e.g. FIEC, Pioneer, Vineyard, Newfrontiers)':\n",
    "                       [\"No, I do not regard myself as belonging to any particular religion.\",\"Yes - Church of England/Anglican/Episcopal\",\n",
    "                        \"Yes - Roman Catholic\",\"Yes - Presbyterian/Church of Scotland\",\"Yes - Methodist\",\"Yes - Baptist\",\n",
    "                        \"Yes - United Reformed Church\",\"Yes - Free Presbyterian\",\"Yes - Brethren\",\"Yes - Judaism\",\"Yes - Hinduism\",\n",
    "                        \"Yes - Islam\",\"Yes - Sikhism\",\"Yes - Buddhism\",\"Yes - Other\",\"Prefer not to say\",\"Yes - Orthodox Christian\",\n",
    "                        \"Yes - Pentecostal\",\"Yes - Evangelical /independent/non-denominational\"], #xprofile_religionW10\n",
    "                   'No, I do not regard myself as belonging to any particular religion.|Yes - Church of England/Anglican/Episcopal|Yes - Roman Catholic|Yes - Presbyterian/Church of Scotland|Yes - Methodist|Yes - Baptist|Yes - United Reformed Church|Yes - Free Presbyterian|Yes - Brethren|Yes - Judaism|Yes - Hinduism|Yes - Islam|Yes - Sikhism|Yes - Buddhism|Yes - Other|Prefer not to say|Yes - Orthodox Christian|Yes - Pentecostal (e.g. Assemblies of God, Elim Pentecostal Church, New Testament Church of God, Redeemed Christian Chur|Yes - Evangelical - independent/non-denominational (e.g. FIEC, Pioneer, Vineyard, Newfrontiers)':\n",
    "                       [\"No, I do not regard myself as belonging to any particular religion.\",\"Yes - Church of England/Anglican/Episcopal\",\n",
    "                        \"Yes - Roman Catholic\",\"Yes - Presbyterian/Church of Scotland\",\"Yes - Methodist\",\"Yes - Baptist\",\n",
    "                        \"Yes - United Reformed Church\",\"Yes - Free Presbyterian\",\"Yes - Brethren\",\"Yes - Judaism\",\"Yes - Hinduism\",\n",
    "                        \"Yes - Islam\",\"Yes - Sikhism\",\"Yes - Buddhism\",\"Yes - Other\",\"Prefer not to say\",\"Yes - Orthodox Christian\",\n",
    "                        \"Yes - Pentecostal\",\"Yes - Evangelical /independent/non-denominational\"], #xprofile_religionW10                   \n",
    "                   'Own - outright|Own - with a mortgage|Own (part-own) - through shared ownership scheme (i.e. pay part mortgage, part rent)|Rent - from a private landlord|Rent - from my local authority|Rent - from a housing association|Neither - I live with my parents, family or friends but pay some rent to them|Neither - I live rent-free with my parents, family or friends|Other|9999':\n",
    "                       [ 'Own outright',\n",
    "                         'Own with a mortgage',\n",
    "                         'Own (part-own) through shared ownership scheme (i.e. pay part mortgage, part rent)',\n",
    "                         'Rent from a private landlord',\n",
    "                         'Rent from my local authority',\n",
    "                         'Rent from a housing association',\n",
    "                         'Neither I live with my parents, family or friends but pay some rent to them',\n",
    "                         'Neither I live rent-free with my parents, family or friends',\n",
    "                         'Other',\n",
    "                         '9999'], #profile_house_tenureW11|profile_house_tenureW12|profile_house_tenureW13\n",
    "                   \"I voted 'No' (Scotland should not be an independent country)|I voted 'Yes' (Scotland should be an independent country)|111.0|Don't know\":\n",
    "                       [\"No\",\"Yes\",\"Did not vote\",\"Don't know\"], # referendumrecall\n",
    "                   \"Voted Yes|Voted No|Did not vote|Can't remember\":\n",
    "                       [\"Yes\",\"No\",\"Did not vote\",\"Don't know\"], # scotRefVoteW4_\n",
    "                   \"No|Yes|3.0|Don't know\":\n",
    "                       [\"No\",\"Yes\",\"Did not vote\",\"Don't know\"], # regretsIHaveAFewEUW10|regretsIHaveAFewEUW11   \n",
    "                   \"No|Yes|3|Don't know\":\n",
    "                       [\"No\",\"Yes\",\"Did not vote\",\"Don't know\"], # regretsIHaveAFewEU W11_only|regretsIHaveAFew W10_only \n",
    "                   \"Professional or higher technical work - work that requires at least degree-level qualifications (e.g. doctor, accountant|Manager or Senior Administrator (e.g. company director, finance manager, personnel manager, senior sales manager, senior|Clerical (e.g. clerk, secretary)|Sales or Services (e.g. commercial traveller, shop assistant, nursery nurse, care assistant, paramedic)|Foreman or Supervisor of Other Workers (e.g building site foreman, supervisor of cleaning workers)|Skilled Manual Work (e.g. plumber, electrician, fitter)|Semi-Skilled or Unskilled Manual Work (e.g. machine operator, assembler, postman, waitress, cleaner, labourer, driver, b|Other|Have never worked\":\n",
    "                       ['Professional or higher technical work / higher managerial - work that requires at least degree-level qualifications (e.g',\n",
    "                        'Manager or Senior Administrator / intermediate managerial / professional (e.g. company director, finance manager, person',\n",
    "                        'Clerical/junior managerial/professional/administrator (e.g. office worker, student doctor, sales person, clerk, secretar',\n",
    "                        'Sales or Services (e.g. commercial traveller, shop assistant, nursery nurse, care assistant, paramedic)',\n",
    "                        'Foreman or Supervisor of Other Workers (e.g. building site foreman, supervisor of cleaning workers)',\n",
    "                        'Skilled Manual Work (e.g. plumber, electrician, fitter)',\n",
    "                        'Semi-Skilled or Unskilled Manual Work (e.g. machine operator, assembler, postman, waitress, cleaner, labourer, driver, b',\n",
    "                        'Other',\n",
    "                        'Have never worked'], # work_type -> profile_work_typeW7\n",
    "                   \"No formal qualifications|Youth training certificate/skillseekers|Recognised trade apprenticeship completed|Clerical and commercial|City & Guilds certificate|City & Guilds certificate - advanced|onc|CSE grades 2-5|CSE grade 1, GCE O level, GCSE, School Certificate|Scottish Ordinary/ Lower Certificate|GCE A level or Higher Certificate|Scottish Higher Certificate|Nursing qualification (eg SEN, SRN, SCM, RGN)|Teaching qualification (not degree)|University diploma|University or CNAA first degree (eg BA, B.Sc, B.Ed)|University or CNAA higher degree (eg M.Sc, Ph.D)|Other technical, professional or higher qualification|Don't know|Prefer not to say\":\n",
    "                       ['No formal qualifications','Youth training certificate/skillseekers','Recognised trade apprenticeship completed',\n",
    "                        'Clerical and commercial','City and Guild certificate','City and Guild certificate - advanced','onc','CSE grades 2-5',\n",
    "                        'CSE grade 1, GCE O level, GCSE, School Certificate','Scottish Ordinary/ Lower Certificate','GCE A level or Higher Certificate',\n",
    "                        'Scottish Higher Certificate','Nursing qualification (eg SEN, SRN, SCM, RGN)','Teaching qualification (not degree)',\n",
    "                        'University diploma','University or CNAA first degree (eg BA, B.Sc, B.Ed)','University or CNAA higher degree (eg M.Sc, Ph.D)',\n",
    "                        'Other technical, professional or higher qualification',\"Don't know\",'Prefer not to say'], # W6_comb: qeducationW6\n",
    "                   \"Strongly disapprove|Disapprove|Don't know\":\n",
    "                       [\"Approve\",\"Disapprove\",\"Don't know\"], # approveEUW2 # W7_comb, W10_comb, W13_comb, W8_comb, W9_comb\n",
    "                   '1 to 24 employees|25 to 499 employees|500 or more employees|':\n",
    "                       ['1 to 24 employees','25 to 499 employees','500 or more employees',\"Don't know\"], #fatherNumEmployees,motherNumEmployees #W6_comb,W5_comb,W5_only,W3_comb\n",
    "                   \"Yes, voted|No, did not vote|Don't know\":\n",
    "                       ['Yes',\"No\",\"Don't know\"],\n",
    "                   \"No, did not vote|Yes, voted|Don't know\":\n",
    "                       ['No','Yes',\"Don't know\"],\n",
    "                   \"No, did not vote|Yes, voted|2.0\":\n",
    "                       ['No','Yes',\"Don't know\"],\n",
    "                   \"Strongly disagree|Disagree|Neither nor disagree|Agree|Strongly agree|Don't know\":\n",
    "                       [\"Strongly disagree\",\"Disagree\",\"Neither agree nor disagree\",\"Agree\",\"Strongly agree\",\"Don't know\"],# euFinancialHelpW2 W3-6_comb\n",
    "                   \"I am very unsure what will happen|I am quite unsure what will happen|I am quite sure what will happen|I am very sure what will happen|Don't know\":\n",
    "                       [\"I am very unsure what would happen\",\"I am quite unsure what would happen\",\"I am quite sure what would happen\",\"I am very sure what would happen\",\"Don't know\"], # certaintyScotUnionW3 W3-5_comb\n",
    "                   \"0.0|1.0|2.0|3.0|4.0|5.0|6.0|7.0|997.0\":\n",
    "                       [\"0 days\",\"1 day\",\"2 days\",\"3 days\",\"4 days\",\"5 days\",\"6 days\",\"7 days\",\"Don't know\"], # discussPolDaysW5\tW5_comb\n",
    "                   \"A major transfer of powers from Westminster to the Scottish Parliament (\\\"devo-max\\\")|Some powers will be transferred but well short of \\\"devo-max\\\"|No change to the relationship between Westminster and the Scottish Parliament\":\n",
    "                       [\"A major transfer of powers from Westminster to the Scottish Parliament (devo-max)\",\"Some powers will be transferred but well short of devo-max\",\"No change to the relationship between Westminster and the Scottish Parliament\"], # expectationManipCheckW1 # W13,10,9,8,7 vs W6-3_comb\n",
    "                   \"No, I did not vote|Yes, I voted|There wasn't a local election in my area|Don't know\":\n",
    "                       [\"No, did not vote\",\"Yes, voted\",\"There wasn't a local election in my area\",\"Don't know\"], # localTurnoutRetroW2 W3-6_comb\n",
    "                   \"Focuses mainly on criticising other parties|2.0|3.0|4.0|Focuses mainly on putting forward their own policies and personalities|Don't know\":\n",
    "                       [\"1 - Focused mainly on criticising other parties\",\"2.0\",\"3.0\",\"4.0\",\"5 - Focused mainly on putting forward their own policies and personalities\",\"Don't know\"], # <party>ToneW5 # W5-6_comb, W5_only\n",
    "                   \"Environmental Policy|Defence|Education|Pensions\":\n",
    "                       [\"No, I think they *will not* vote\",\"Yes, I think they *will* vote\",\"They are not eligible to vote\",\"Don't know\"], # discussantturnoutName1-3W4 # W4-5_comb\n",
    "                   \"Employers in large organisations and higher managerial|Higher professional occupations|Lower professional and managerial and higher supervisory|Intermediate occupations|Employers in small organisations and own account workers|Lower suprivsory and technical occupations|Semi-routine occupations|Routine occupations\":\n",
    "                       ['Employers in large organisations and higher managerial', 'Higher professional occupations',\n",
    "                        'Lower professional and managerial and higher supervisory', 'Intermediate occupations',\n",
    "                        'Employers in small organisations and own account workers', 'Lower supervisory and technical occupations',\n",
    "                        'Semi-routine occupations', 'Routine occupations'], # ns_sec_analytic\t W5_only, W3-6_comb                   \n",
    "                   \"Employers in large organisations and higher managerial|Higher professional occupations|Lower professional and managerail and higher supervisory|Intermediate occupations|Employers in small organisations and own account workers|Lower suprivsory and technical occupations|Semi-routine occupations|Routine occupations\":\n",
    "                       ['Employers in large organisations and higher managerial', 'Higher professional occupations',\n",
    "                        'Lower professional and managerial and higher supervisory', 'Intermediate occupations',\n",
    "                        'Employers in small organisations and own account workers', 'Lower supervisory and technical occupations',\n",
    "                        'Semi-routine occupations', 'Routine occupations'], # ns_sec_analytic\t W5_only, W3-6_comb    # v slight typo!\n",
    "                   \"A major transfer of powers from Westminster to the Scottish Parliament (\\\"devo-max\\\")|Some powers will be transferred but well short of \\\"devo-max\\\"|No change to the relationship between Westminster and the Scottish Parliament|Don't know\":\n",
    "                       ['A major transfer of powers from Westminster to the Scottish Parliament (devo-max)',\n",
    "                        'Some powers will be transferred but well short of devo-max',\n",
    "                        'No change to the relationship between Westminster and the Scottish Parliament',\"Don't know\"], # expectationManipCheckW1 W3-6_comb\n",
    "                   \"Employers in large establishments|Higher managerial and administrative occupations|L3.1 'Traditional' employees|L3.2 'New' employees|L3.3 'Traditional' self-employed|L3.4 'New' self-employed|L4.1 'Traditional' employees|L4.2 'New' employees|L4.3 'Traditional' self-employed|L4.4 'New' self-employed|Lower managerial and administrative occupations|Higher supervisory occupations|L7.1 Intermediate clerical and administrative occupations|L7.2 Intermediate sales and service occupations|L7.3 Intermediate technical and auxiliary occupations|L7.4 Intermediate engineering occupations|L8.1 Employers in small establishments in industry, commerce, services etc.|L8.2 Employers in small establishments in agriculture|L9.1 Own account workers (non-professional)|L9.2 Own account workers (agriculture)|Lower supervisory occupations|L11.1 Lower technical craft occupations|L11.2 Lower technical process operative occupations|L12.1 Semi-routine sales occupations|L12.2 Semi-routine service occupations|L12.3 Semi-routine technical occupations|L12.4 Semi-routine operative occupations|L12.5 Semi-routine agricultural occupations|L12.6 Semi-routine clerical occupations|L12.7 Semi routine childcare occupations|L13.1 Routine sales and service occupations|L13.2 Routine production occupations|L13.3 Routine technical occupations|L13.4 Routine operative occupations|L13.5 Routine agricultural occupations\":\n",
    "                       ['Employers in large establishments', 'Higher managerial and administrative occupations',\n",
    "                        'L3.1 Traditional employees', 'L3.2 New employees', 'L3.3 Traditional self-employed',\n",
    "                        'L3.4 New self-employed', 'L4.1 Traditional employees', 'L4.2 New employees',\n",
    "                        'L4.3 Traditional self-employed', 'L4.4 New self-employed', 'Lower managerial and administrative occupations',\n",
    "                        'Higher supervisory occupations', 'L7.1 Intermediate clerical and administrative occupations',\n",
    "                        'L7.2 Intermediate sales and service occupations', 'L7.3 Intermediate technical and auxiliary occupations',\n",
    "                        'L7.4 Intermediate engineering occupations', 'L8.1 Employers in small establishments in industry, commerce, services etc.',\n",
    "                        'L8.2 Employers in small establishments in agriculture', 'L9.1 Own account workers (non-professional)',\n",
    "                        'L9.2 Own account workers (agriculture)', 'Lower supervisory occupations', 'L11.1 Lower technical craft occupations',\n",
    "                        'L11.2 Lower technical process operative occupations', 'L12.1 Semi-routine sales occupations',\n",
    "                        'L12.2 Semi-routine service occupations', 'L12.3 Semi-routine technical occupations', 'L12.4 Semi-routine operative occupations',\n",
    "                        'L12.5 Semi-routine agricultural occupations', 'L12.6 Semi-routine clerical occupations', 'L12.7 Semi routine childcare occupations',\n",
    "                        'L13.1 Routine sales and service occupations', 'L13.2 Routine production occupations', 'L13.3 Routine technical occupations',\n",
    "                        'L13.4 Routine operative occupations', 'L13.5 Routine agricultural occupations'],\n",
    "                   \"Employers in large establishments|Higher managerial and administrative occupations|L3.1 ?Traditional? employees|L3.2 ?New? employees|L3.3 ?Traditional? self-employed|L3.4 ?New? self-employed|L4.1 ?Traditional? employees|L4.2 ?New? employees|L4.3 ?Traditional? self-employed|L4.4 ?New? self-employed|Lower managerial and administrative occupations|Higher supervisory occupations|L7.1 Intermediate clerical and administrative occupations|L7.2 Intermediate sales and service occupations|L7.3 Intermediate technical and auxiliary occupations|L7.4 Intermediate engineering occupations|L8.1 Employers in small establishments in industry, commerce, services etc.|L8.2 Employers in small establishments in agriculture|L9.1 Own account workers (non-professional)|L9.2 Own account workers (agriculture)|Lower supervisory occupations|L11.1 Lower technical craft occupations|L11.2 Lower technical process operative occupations|L12.1 Semi-routine sales occupations|L12.2 Semi-routine service occupations|L12.3 Semi-routine technical occupations|L12.4 Semi-routine operative occupations|L12.5 Semi-routine agricultural occupations|L12.6 Semi-routine clerical occupations|L12.7 Semi routine childcare occupations|L13.1 Routine sales and service occupations|L13.2 Routine production occupations|L13.3 Routine technical occupations|L13.4 Routine operative occupations|L13.5 Routine agricultural occupations\":\n",
    "                       ['Employers in large establishments', 'Higher managerial and administrative occupations',\n",
    "                        'L3.1 Traditional employees', 'L3.2 New employees', 'L3.3 Traditional self-employed',\n",
    "                        'L3.4 New self-employed', 'L4.1 Traditional employees', 'L4.2 New employees',\n",
    "                        'L4.3 Traditional self-employed', 'L4.4 New self-employed', 'Lower managerial and administrative occupations',\n",
    "                        'Higher supervisory occupations', 'L7.1 Intermediate clerical and administrative occupations',\n",
    "                        'L7.2 Intermediate sales and service occupations', 'L7.3 Intermediate technical and auxiliary occupations',\n",
    "                        'L7.4 Intermediate engineering occupations', 'L8.1 Employers in small establishments in industry, commerce, services etc.',\n",
    "                        'L8.2 Employers in small establishments in agriculture', 'L9.1 Own account workers (non-professional)',\n",
    "                        'L9.2 Own account workers (agriculture)', 'Lower supervisory occupations', 'L11.1 Lower technical craft occupations',\n",
    "                        'L11.2 Lower technical process operative occupations', 'L12.1 Semi-routine sales occupations',\n",
    "                        'L12.2 Semi-routine service occupations', 'L12.3 Semi-routine technical occupations', 'L12.4 Semi-routine operative occupations',\n",
    "                        'L12.5 Semi-routine agricultural occupations', 'L12.6 Semi-routine clerical occupations', 'L12.7 Semi routine childcare occupations',\n",
    "                        'L13.1 Routine sales and service occupations', 'L13.2 Routine production occupations', 'L13.3 Routine technical occupations',\n",
    "                        'L13.4 Routine operative occupations', 'L13.5 Routine agricultural occupations'],\n",
    "                   \"1|2\":\n",
    "                       [\"No\",\"Yes\"], # tryReduceImmigDKW4, achieveReduceImmigUKIPW4, achieveReduceImmigGrnW4, achieveReduceImmigDKW4, tryReduceInequalityDKW4, successReduceInequalityDKW4 # W4-5_comb # sharedContentOnline_1-5W4 W5_comb # voteMethodEurope_dkW2, discussantsAskedYouToVote_DKW2 ,discussantsAccompaniedVote_dkW2, referendumContact_dkW2 # W3_comb\n",
    "                   \"1.0|2.0\":\n",
    "                       [\"No\",\"Yes\"], # tryReduceImmigDKW4, achieveReduceImmigUKIPW4, achieveReduceImmigGrnW4, achieveReduceImmigDKW4, tryReduceInequalityDKW4, successReduceInequalityDKW4 # W4-5_comb # sharedContentOnline_1-5W4 W5_comb # voteMethodEurope_dkW2, discussantsAskedYouToVote_DKW2 ,discussantsAccompaniedVote_dkW2, referendumContact_dkW2 # W3_comb\n",
    "                   \"Should definitely be illegal|Should probably be illegal|Should probably be legal|Should definitely be legal|5.0\":\n",
    "                       [\"Should definitely be illegal\",\"Should probably be illegal\",\"Should probably be legal\",\"Should definitely be legal\",\"Don't know\"], # zeroHourContractW6\n",
    "                  }\n",
    "\n",
    "\n",
    "rename_variable_dict = pd.DataFrame.from_dict( {k : \"|\".join(v) for k, v in rename_cat_dict.items()} , orient='index' ).reset_index()\n",
    "rename_variable_dict.columns = [\"original_cat_list\",\"renameed_cat_list\"]\n",
    "rename_variable_dict.to_csv( BES_small_data_files + \"rename_variable_dict.csv\" )\n",
    "\n",
    "def re_name(ques):\n",
    "    if ques in rename_cat_dict.keys():\n",
    "        return \"|\".join( rename_cat_dict[ques] )\n",
    "    else:\n",
    "        return ques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "## COLUMNS THAT EITHER LACK ALL DATA OR HAVE ACTUAL ERRORS\n",
    "# check back on these periodically - one assumes they will get fixed!\n",
    "# maybe tell them about them so that they can?\n",
    "\n",
    "# {'changeIssue1W9', 'conLeaderLikeW9'}\n",
    "# these variables appear to have disappeared! Fixed in an updated version?\n",
    "\n",
    "ignore_list = ['whichPartiesHelped_99W6',\n",
    "               'partyContactGrnW1',\n",
    "               'partyContactGrnW2',\n",
    "               'partyContactGrnW3',\n",
    "               'reasonNotRegistered_noneW2',               \n",
    "               'reasonNotRegistered_noneW3',\n",
    "               'reasonNotRegistered_noneW4',\n",
    "               'reasonNotRegistered_noneW6',\n",
    "               'reasonNotRegistered_noneW7',\n",
    "               'reasonNotRegistered_noneW8',\n",
    "               'reasonNotRegistered_none',\n",
    "               'partyContactSNPW1',\n",
    "               'partyContactSNPW2',\n",
    "               \"locusControlW9\",\n",
    "               \"generalElecCertaintyW1\", # wave 10 forwards\n",
    "               \"generalElecCertaintyW2\",\n",
    "               \"generalElecCertaintyW3\",\n",
    "               \"londonMayorVoteW7\",\n",
    "               \"fatherNumEmployeesW4\",\n",
    "               \"motherNumEmployeesW4\",\n",
    "               \"profile_pcon_2010_newW3\", # W3_comb: this is parl. constit. ... but by number!\n",
    "               \"euroElectionVoteYoungW2\", # W3_comb: all NaNs!\n",
    "               \"profile_GOR_pdlW4\", # W4_comb: misnamed selection, probably fixable \n",
    "               \"participation_111W5\", ### -->\n",
    "               \"sharedContentOnline_111W5\",\n",
    "               \"sharedContentOnline_99W5\", ### <-- W5_comb \"Got a lot worse|Got a little worse\" doesn't look right (indicator vars?)\n",
    "               \"csplScotRefW3\", ### W5_comb: \"North East\" - just broken!\n",
    "              ]\n",
    "\n",
    "#- approveEUW2 'Strongly disapprove|Disapprove|Don't know' - should be \"approve|disapprove|don't know\"??? NOT SURE (distribution weird)\n",
    "#- whichPartiesHelped_99W6 - answer set = [\"No\"]\n",
    "#- partyContactGrnW1 ... reasonNotRegistered_noneW8 answer set = [\"No\", \"Don't know\"]\n",
    "# -partyContactSNPW1, partyContactSNPW2 - answer set = [\"Don't know\"]\n",
    "# -changeIssue1W9|conLeaderLikeW9|locusControlW9 - answer set = [\"No formal qualifications\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define 'prune' function to prune wave indicators and return question stubs\n",
    "## ie. \"ptvConW1|ptvLabW1\" -> \"ptvCon|ptvLab\"\n",
    "\n",
    "def prune(x):\n",
    "    \n",
    "    y= []\n",
    "    for el in x.split(\"|\"):\n",
    "        match_attempt = re.match('(\\w*?)_?(W[0-9]+)+' , el )   \n",
    "        if match_attempt:\n",
    "            el = match_attempt.groups()[0]\n",
    "        y.append(el)\n",
    "    # should we ditch identical repeats?\n",
    "    # return \"|\".join(set(y)) NEEDS TO BE TESTED\n",
    "    return \"|\".join(y)\n",
    "\n",
    "               \n",
    "def prune2(x):\n",
    "    \n",
    "    y= []\n",
    "    for el in x.split(\"|\"):\n",
    "        # fgdfhfghg_5, fgdfhfghg_4, fgdfhfghg_3 -> fgdfhfghg\n",
    "        # problem - indicator variables fgdfhfghg_99, fgdfhfghg_111 really are different!\n",
    "        # solution - leave them distinct\n",
    "        indicator_variable = re.match('(\\w*?)_?(99|111)' , el )       \n",
    "        match_attempt = re.match('(\\w*?)_?[0-9]+' , el )   \n",
    "        if (not indicator_variable) and (match_attempt):\n",
    "            el = match_attempt.groups()[0]\n",
    "        y.append(el)\n",
    "    # should we ditch identical repeats?\n",
    "    # return \"|\".join(set(y)) NEEDS TO BE TESTED\n",
    "    return \"|\".join(y)\n",
    "\n",
    "\n",
    "def hardcoded_fix(col,cat_list):\n",
    "    \n",
    "    var_type.loc[ col , \"dtype\" ]           = BES_Panel[col].dtype.name\n",
    "    if (var_type.loc[ col , \"dtype\" ] == 'category'):\n",
    "        var_type.loc[ col , \"cat_all_strings\" ] = np.all([isinstance(x,str) for x in BES_Panel[ col ].cat.categories])\n",
    "        \n",
    "    BES_Panel[col] = \\\n",
    "        BES_Panel[col].astype(\"category\").cat.rename_categories( cat_list.split(\"|\") )\n",
    "        \n",
    "    var_type.loc[ col , \"dataset_specific_hardcoded_fix\" ] = \"|\".join( BES_Panel[col].cat.categories.values )\n",
    "    \n",
    "# \"Â–\" -> \"-\"\n",
    "# \"Â£\" -> \"£\"\n",
    "\n",
    "# \" â€“ \" -> \" \"\n",
    "# \" Â‘\" -> \" \"\n",
    "# \"Â’ \" -> \" \"\n",
    "\n",
    "# \"Â‘\" -> \"'\"\n",
    "# \"Â’\" -> \"'\"\n",
    "# \"Â€Â™\" -> \"'\"\n",
    "# \"â??\" -> \"'\"\n",
    "# \"â€™\" -> \"'\"    \n",
    "\n",
    "# detect any matching pattern of weird Â stuff in cat1|cat2|cat3... string\n",
    "# return the fixed version of string if present\n",
    "# return None if not\n",
    "def fix_a_hat_chars(cat_string):\n",
    "    cat_array = cat_string.split(\"|\")\n",
    "    a_hat_present = False\n",
    "    for el_no in range( 0, len(cat_array) ):\n",
    "        el = cat_array[el_no]\n",
    "        el = re.sub( \"SiÃƒÂ¢n C. Jame|SiÃ¢n C. James|SiÃ¢n C. Jame|Siân C. James\", \"Sian C. James\", el)\n",
    "        el = re.sub( \"ThÃ©rÃ¨se  Coff|Thérèse  Coffey\", \"Therese  Coffey\", el)\n",
    "        el = re.sub( \"RA©union|RÃ©union|RAÂ©union|RÃƒÂ©union\", \"Reunion\", el)\n",
    "        el = re.sub( \"\\xa0Lower supervisory occupations\", \"Lower supervisory occupations\", el)\n",
    "        el = re.sub( \"Don‘t know|Don?t know|Dona??t know|Dona€™t know|Donâ€™t know|Don’t know|Don‘t know|Don\\x91t know|Don\\x92t know|Dona\\x80\\x99t know|Do\\x92t know\",\"Don't know\", el  )\n",
    "        el = re.sub( \"Â–|\\x96|–\", \"-\", el )\n",
    "        el = re.sub( \"Â£|\\xc2£\", \"£\", el )\n",
    "        el = re.sub( \"\\xa0|\\sâ€“\\s|\\s\\xe2\\x80\\x93\\s|\\sÂ‘|Â’\\s\" , \" \", el )\n",
    "        el = re.sub( \"Â‘|Â’|Â€Â™|â\\?\\?|\\x80\\x99|â€™|\\xe2\\x80\\x99|â|â\\x80\\x99|\\?\\?|\\x92|‘|\\x91|’\", \"'\", el )\n",
    "        el = re.sub( \"\\u2013\", \"-\", el )\n",
    "        \n",
    "        \n",
    "        \n",
    "        if el != cat_array[el_no]:\n",
    "            a_hat_present = True\n",
    "            cat_array[el_no] = el\n",
    "            \n",
    "    if a_hat_present:\n",
    "        return cat_array\n",
    "    else:\n",
    "        return None\n",
    "        \n",
    "## typos - more directly useful for the BES!\n",
    "# typos = set(['Do\\x92t know', 'Dont know', 'Donât know', 'Don??t know','DonaÂ€Â™t know'])# ,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_var_list( variable_categories ):\n",
    "    # load question_categories_correct (it could have been updated)\n",
    "    # input: \n",
    "    # output:\n",
    "    # var_cat_dict_pruned, var_cat_dict_pruned_2\n",
    "\n",
    "    # flipping list\n",
    "    var_cat_dict = dict()\n",
    "    # range defined by types that exist in question_categories_correct.csv\n",
    "    type_range = set(variable_categories[\"type\"].values)\n",
    "\n",
    "    for typ in type_range:\n",
    "\n",
    "        e = variable_categories[variable_categories.type==typ][\"column_name\"].values\n",
    "        var_cat_dict[typ] = [item for sublist in [i.split(\"|\") for i in e] for item in sublist]\n",
    "        var_cat_dict[typ] = [item for item in var_cat_dict[typ] if item not in ignore_list]\n",
    "\n",
    "    # dictionary comprehension to prune column-names to wave non-specific stubs\n",
    "    # list(set()) gets rid of repetitions\n",
    "    var_cat_dict_pruned   = {k: list(set([prune(x)  for x in v])) for k, v in var_cat_dict.items()}\n",
    "    var_cat_dict_pruned_2 = {k: list(set([prune2(x) for x in v])) for k, v in var_cat_dict_pruned.items()}\n",
    "    \n",
    "    return ( var_cat_dict_pruned , var_cat_dict_pruned_2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def careful_isnan(x):\n",
    "    return ( (not isinstance(x,str)) and np.isnan(x) )\n",
    "\n",
    "def careful_replace( col,replace_dict ):\n",
    "    var_type.loc[col,\"dtype\"] = BES_Panel[col].dtype.name\n",
    "    if (var_type.loc[ col , \"dtype\" ] == 'category'):\n",
    "        var_type.loc[ col , \"cat_all_strings\" ] = np.all([isinstance(x,str) for x in BES_Panel[ col ].cat.categories])     \n",
    "    \n",
    "    BES_Panel[col] = BES_Panel[col]\\\n",
    "        .apply(lambda x: x if careful_isnan(x) else replace_dict[x] )\\\n",
    "        .astype('category').cat.set_categories( replace_dict.values() , ordered = True)\n",
    "        \n",
    "    var_type.loc[ col , \"dataset_specific_hardcoded_fix\" ] = \"|\".join( BES_Panel[col].cat.categories.values )\n",
    "\n",
    "def careful_replace_and_set_cats( col, replace_dict, final_cats ):\n",
    "    var_type.loc[col,\"dtype\"] = BES_Panel[col].dtype.name\n",
    "    if (var_type.loc[ col , \"dtype\" ] == 'category'):\n",
    "        var_type.loc[ col , \"cat_all_strings\" ] = np.all([isinstance(x,str) for x in BES_Panel[ col ].cat.categories])     \n",
    "    \n",
    "    BES_Panel[col] = BES_Panel[col]\\\n",
    "        .apply(lambda x: x if x not in replace_dict.keys() else replace_dict[x] )\\\n",
    "        .astype('category').cat.set_categories( final_cats , ordered = True)\n",
    "        \n",
    "    var_type.loc[ col , \"dataset_specific_hardcoded_fix\" ] = \"|\".join( BES_Panel[col].cat.categories.values )    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if ( dataset_name in [\"W25_comb\"] ):\n",
    "#     print(\"!!!!!!!!!!!!!!!!!!!!\")\n",
    "#     col = 'riskScaleW8' \n",
    "#     replace_dict = {'Most risk averse':0, '2':1,'3':2 ,'4':3,\n",
    "#                     '5':4,'6':5,'7':6,'8':7,'9':8,'10':9,'11':10,'12':11,\n",
    "#                     '13':12,'14':13,'15':14, 'Most risk inclined':15}\n",
    "\n",
    "# BES_Panel[col].replace(replace_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hard_coded_fixes( dataset_name ):\n",
    "\n",
    "    ## dataset specific issues\n",
    "    # (i.e. probably what I should have done all along!)\n",
    "    \n",
    "    col = \"age\"\n",
    "    if dataset_name==\"W22_only\":\n",
    "        BES_Panel[col]= BES_Panel[col].astype('category')\n",
    "        \n",
    "    if ( dataset_name in [\"W25_comb\"] ):\n",
    "        print(\"!!!!!!!!!!!!!!!!!!!!\")\n",
    "        col = 'riskScaleW8' \n",
    "        replace_dict = {'Most risk averse':0, '2':1,'3':2 ,'4':3,\n",
    "                        '5':4,'6':5,'7':6,'8':7,'9':8,'10':9,'11':10,'12':11,\n",
    "                        '13':12,'14':13,'15':14, 'Most risk inclined':15}\n",
    "    \n",
    "        BES_Panel[col] = BES_Panel[col].replace(replace_dict)\n",
    "        col = 'riskScaleW20' \n",
    "        replace_dict = {'Most risk averse':0, '2':1,'3':2 ,'4':3,\n",
    "                        '5':4,'6':5,'7':6,'8':7,'9':8,'10':9,'11':10,'12':11,\n",
    "                        '13':12,'14':13,'15':14, 'Most risk inclined':15}\n",
    "    \n",
    "        BES_Panel[col] = BES_Panel[col].replace(replace_dict)        \n",
    "\n",
    "    if ( dataset_name in [\"W23_only\"] ):\n",
    "        col = 'preschoolKidsInHouseW21_'\n",
    "        replace = {0.0:\"No\",1.0:\"Yes\",9.0:\"Don't know\"}\n",
    "        final_cats = [\"No\", \"Yes\", \"Don't know\"]\n",
    "        careful_replace_and_set_cats( col, replace, final_cats )        \n",
    "        BES_Panel[col] = BES_Panel[col].astype('category')\n",
    "\n",
    "    if ( dataset_name in [\"W23_only\"] ):\n",
    "        col = 'schoolKidsInHouseW21_'\n",
    "        replace = {0.0:\"No\",1.0:\"Yes\",9.0:\"Don't know\"}\n",
    "        final_cats = [\"No\", \"Yes\", \"Don't know\"]\n",
    "        careful_replace_and_set_cats( col, replace, final_cats )        \n",
    "        BES_Panel[col] = BES_Panel[col].astype('category')        \n",
    "        \n",
    "    if ( dataset_name in [\"W23_only\"] ):\n",
    "        col = 'sickElderlyInHouseW21_'\n",
    "        replace = {0.0:\"No\",1.0:\"Yes\",9.0:\"Don't know\"}\n",
    "        final_cats = [\"No\", \"Yes\", \"Don't know\"]\n",
    "        careful_replace_and_set_cats( col, replace, final_cats )        \n",
    "        BES_Panel[col] = BES_Panel[col].astype('category')           \n",
    "        \n",
    "    if ( dataset_name in [\"W23_only\"] ):\n",
    "        col = 'noDependentsInHouseW21_'\n",
    "        replace = {0.0:\"No\",1.0:\"Yes\",9.0:\"Don't know\"}\n",
    "        final_cats = [\"No\",  \"Yes\", \"Don't know\"]\n",
    "        careful_replace_and_set_cats( col, replace, final_cats )        \n",
    "        BES_Panel[col] = BES_Panel[col].astype('category')           \n",
    "        \n",
    "    if ( dataset_name in [\"W23_only\"] ):\n",
    "        col = 'privPrimSchlW1_'\n",
    "        replace = {0.0:\"No\",1.0:\"Yes\",9.0:\"Don't know\"}\n",
    "        final_cats = [\"No\",  \"Yes\", \"Don't know\"]\n",
    "        careful_replace_and_set_cats( col, replace, final_cats )        \n",
    "        BES_Panel[col] = BES_Panel[col].astype('category')           \n",
    "        \n",
    "    if ( dataset_name in [\"W23_only\"] ):\n",
    "        col = 'privScndSchlW1_'\n",
    "        replace = {0.0:\"No\",1.0:\"Yes\",9.0:\"Don't know\"}\n",
    "        final_cats = [\"No\",  \"Yes\", \"Don't know\"]\n",
    "        careful_replace_and_set_cats( col, replace, final_cats )        \n",
    "        BES_Panel[col] = BES_Panel[col].astype('category')         \n",
    "        \n",
    "    if ( dataset_name in [\"W23_only\"] ):\n",
    "        col = 'privScndSchlW1_'\n",
    "        replace = {0.0:\"No\",1.0:\"Yes\",9.0:\"Don't know\"}\n",
    "        final_cats = [\"No\",  \"Yes\", \"Don't know\"]\n",
    "        careful_replace_and_set_cats( col, replace, final_cats )        \n",
    "        BES_Panel[col] = BES_Panel[col].astype('category')   \n",
    "        \n",
    "    if ( dataset_name in [\"W23_only\"] ):\n",
    "        col = 'privScndSchlW1_'\n",
    "        replace = {0.0:\"No\",1.0:\"Yes\",9.0:\"Don't know\"}\n",
    "        final_cats = [\"No\",  \"Yes\", \"Don't know\"]\n",
    "        careful_replace_and_set_cats( col, replace, final_cats )        \n",
    "        BES_Panel[col] = BES_Panel[col].astype('category')   \n",
    "\n",
    "    if ( dataset_name in [\"W23_only\"] ):\n",
    "        col = 'neverPrivSchlW1_'\n",
    "        replace = {0.0:\"No\",1.0:\"Yes\",9.0:\"Don't know\",9999.0:\"Don't know\"}\n",
    "        final_cats = [\"No\", \"Yes\", \"Don't know\"]\n",
    "        careful_replace_and_set_cats( col, replace, final_cats )        \n",
    "        BES_Panel[col] = BES_Panel[col].astype('category')         \n",
    "                \n",
    "    if ( dataset_name in [\"W23_only\"] ):\n",
    "        col = 'speakWelshW1_'\n",
    "        replace = {0.0:\"No\",1.0:\"Yes, but not fluently\",2.0:\"Yes, fluently\",9999.0:\"Don't know\"}\n",
    "        final_cats = [\"No\", \"Yes\", \"Don't know\"]\n",
    "        careful_replace_and_set_cats( col, replace, final_cats )        \n",
    "        BES_Panel[col] = BES_Panel[col].astype('category')         \n",
    "\n",
    "        \n",
    "        \n",
    "    # \"BES2017_W13_v1.0.dta\"\n",
    "\n",
    "    ## Should I make this *filename specific* or *wave specific*?\n",
    "    ## Comes down to a question of whether it's safer to assume that things get fixed\n",
    "    ## or that they probably won't get fixed\n",
    "\n",
    "\n",
    "    # gor W3_only, W2_only (3->-4, category -> object)\n",
    "    # # grr - some point BES switched from ONS codes to text names\n",
    "    # # I feel like percolating the change backwards would have been a good idea\n",
    "    # ONS codes available here:\n",
    "    # http://webarchive.nationalarchives.gov.uk/20160128190831/http://www.ons.gov.uk/ons/guide-method/geography/beginner-s-guide/administrative/england/government-office-regions/index.html\n",
    "\n",
    "    # variable name collision (BES 'disability' (wave 6 variable) and yougov profile 'disability)\n",
    "    if (\"disability\" in BES_Panel.columns) and (dataset_name != \"W6_only\"):\n",
    "        BES_Panel.rename(columns={\"disability\":\"profile_disability\"}, inplace=True)\n",
    "    # similar collision \n",
    "#     if (\"housing\" in BES_Panel.columns) and (dataset_name == \"W13_only\"):\n",
    "#         BES_Panel.rename(columns={\"housing\":\"profile_house_tenure\"}, inplace=True)  \n",
    "\n",
    "    # whole column is NaN!\n",
    "    col = \"profile_socialgrade_cie\"\n",
    "    if (col in BES_Panel.columns) and (dataset_name in [ \"W6_only\", \"W4_only\", \"W3_only\", \"W2_only\", \"W1_only\" ]):\n",
    "        var_type.loc[col,\"type\"] = -2 # set to ignore\n",
    "\n",
    "    # whole column is NaN!\n",
    "    col = 'discussPolDays'\n",
    "    if (col in BES_Panel.columns) and (dataset_name in [ \"W3_only\" ]):\n",
    "        var_type.loc[col,\"type\"] = -2 # set to ignore\n",
    "        \n",
    "    # whole column is NaN!\n",
    "    col = 'partyContactSNP'\n",
    "    if (col in BES_Panel.columns) and (dataset_name in [ \"W2_only\",\"W1_only\" ]):\n",
    "        var_type.loc[col,\"type\"] = -2 # set to ignore        \n",
    "\n",
    "        \n",
    "        \n",
    "    # now we have actual categories that don't match different versions *of that exact same variable*\n",
    "    # and can't even be attributed to weasel terms (e.g. 99 -> Don't know, 98 -> Other)\n",
    "    # so, I'll try just replacing them with NaNs\n",
    "    \n",
    "    if ( dataset_name in [\"W13_comb\"] ):\n",
    "        col = 'scotRefVoteW4_W13'\n",
    "        replace = {99.0:\"Don't know\",111.0:\"Don't know\"}\n",
    "        final_cats = ['Not at all certain', 'Somewhat certain', 'Very certain', \"Don't know\"]\n",
    "        careful_replace_and_set_cats( col,  replace, final_cats )        \n",
    "    \n",
    "\n",
    "    if ( dataset_name in [\"W13_comb\",\"W10_comb\"] ):\n",
    "        col = \"profile_turnout_2015\"\n",
    "        \n",
    "        replace = {}\n",
    "        final_cats = ['No, did not vote',\n",
    "                      'Yes, voted',\n",
    "                      \"Don't know\"]\n",
    "        careful_replace_and_set_cats( col,  replace, final_cats )\n",
    "\n",
    "\n",
    "    if ( dataset_name in [\"W6_comb\"] ):\n",
    "        col = \"zeroHourContractW6\"\n",
    "        \n",
    "        replace = {}\n",
    "        final_cats = ['Should definitely be illegal',\n",
    "                     'Should probably be illegal',\n",
    "                     'Should probably be legal',\n",
    "                     'Should definitely be legal',\n",
    "                     \"Don't know\"]\n",
    "        careful_replace_and_set_cats( col,  replace, final_cats )\n",
    "\n",
    "    if ( dataset_name in [\"W6_comb\",\"W5_comb\",\"W4_comb\",\"W3_comb\"] ):\n",
    "        col = \"certaintyEUGreenW2\"\n",
    "        \n",
    "        replace = {99.0:\"Don't know\"}\n",
    "        final_cats = ['Not at all certain', 'Somewhat certain', 'Very certain', \"Don't know\"]\n",
    "        careful_replace_and_set_cats( col,  replace, final_cats )\n",
    "        \n",
    "    if ( dataset_name in [\"W6_comb\"] ):\n",
    "        col = \"certaintyEUGreenW4\"\n",
    "        \n",
    "        replace = {99.0:\"Don't know\"}\n",
    "        final_cats = ['Not at all certain', 'Somewhat certain', 'Very certain', \"Don't know\"]\n",
    "        careful_replace_and_set_cats( col,  replace, final_cats )\n",
    "        \n",
    "        col = \"certaintyEUGreenW6\"\n",
    "        \n",
    "        replace = {99.0:\"Don't know\"}\n",
    "        final_cats = ['Not at all certain', 'Somewhat certain', 'Very certain', \"Don't know\"]\n",
    "        careful_replace_and_set_cats( col,  replace, final_cats )        \n",
    "\n",
    "        \n",
    "    if ( dataset_name in [\"W10_only\"] ):\n",
    "        col = \"econPersonalProsp\"\n",
    "        \n",
    "        replace = {}\n",
    "        final_cats = ['Get a lot worse',\n",
    "                     'Get a little worse',\n",
    "                     'Stay the same',\n",
    "                     'Get a little better',\n",
    "                     'Get a lot better',\n",
    "                     \"Don't know\"]\n",
    "        careful_replace_and_set_cats( col,  replace, final_cats )        \n",
    "\n",
    "    if ( dataset_name in [\"W13_comb\",\"W10_comb\"] ):\n",
    "        col = \"econPersonalProspW10\"\n",
    "        \n",
    "        replace = {}\n",
    "        final_cats = ['Get a lot worse',\n",
    "                     'Get a little worse',\n",
    "                     'Stay the same',\n",
    "                     'Get a little better',\n",
    "                     'Get a lot better',\n",
    "                     \"Don't know\"]\n",
    "        careful_replace_and_set_cats( col,  replace, final_cats )\n",
    "\n",
    "    if ( dataset_name in [\"W6_comb\",\"W5_only\"] ):\n",
    "        col = \"noDependentsInHousehold\"\n",
    "        \n",
    "        replace = {}\n",
    "        final_cats = ['No',\n",
    "                     'Yes']\n",
    "        careful_replace_and_set_cats( col,  replace, final_cats )            \n",
    "        \n",
    "        \n",
    "    if ( dataset_name in [\"W2_only\"] ):\n",
    "        col = \"gor\"\n",
    "\n",
    "        ons_gor_dict = {\"E12000001\":\"North East\",\n",
    "                        \"E12000002\":\"North West\",\n",
    "                        \"E12000003\":\"Yorkshire and The Humber\",\n",
    "                        \"E12000004\":\"East Midlands\",\n",
    "                        \"E12000005\":\"West Midlands\",\n",
    "                        \"E12000006\":\"East of England\",\n",
    "                        \"E12000007\":\"London\",\n",
    "                        \"E12000008\":\"South East\",\n",
    "                        \"E12000009\":\"South West\",\n",
    "                        \"N99999999\":\"Northern Ireland\",\n",
    "                        \"S99999999\":\"Scotland\",\n",
    "                        \"W99999999\":\"Wales\",\n",
    "                        \"\":\"Non UK & Invalid\"}\n",
    "\n",
    "        careful_replace(  col , ons_gor_dict )\n",
    "        \n",
    "    if ( dataset_name in [\"W21_only\"] ):\n",
    "        col = \"gor\"\n",
    "        \n",
    "        ons_gor_dict = {1:\"North East\",\n",
    "                        2:\"North West\",\n",
    "                        3:\"Yorkshire and The Humber\",\n",
    "                        4:\"East Midlands\",\n",
    "                        5:\"West Midlands\",\n",
    "                        6:\"East of England\",\n",
    "                        7:\"London\",\n",
    "                        8:\"South East\",\n",
    "                        9:\"South West\",\n",
    "                        10:\"Wales\",\n",
    "                        11:\"Scotland\",\n",
    "                }\n",
    "\n",
    "        careful_replace(  col , ons_gor_dict )   \n",
    "        \n",
    "    if ( dataset_name in [\"W21_only\"] ):\n",
    "        col = \"p_country_birth\"\n",
    "        \n",
    "        ons_gor_dict = {1.0:\"UK\",\n",
    "                        2.0:\"Ireland\",\n",
    "                        3.0:\"EU: pre-2004\",\n",
    "                        4.0:\"EU: post-2004\",\n",
    "                        5.0:\"European outside EU\",\n",
    "                        6.0:\"Africa\",\n",
    "                        7.0:\"East Asia\",\n",
    "                        8.0:\"South-East/Central Asia\",\n",
    "                        9.0:\"South Asia\",\n",
    "                        10.0:\"North America\",\n",
    "                        11.0:\"Caribbean/Central America\",\n",
    "                        12.0:\"South America\",\n",
    "                        13.0:\"Oceania & Antarctica\",\n",
    "                        14.0:\"Middle East\",\n",
    "                        9999.0:\"Not coded\",\n",
    "                }\n",
    "\n",
    "        careful_replace(  col , ons_gor_dict )          \n",
    "\n",
    "    if ( dataset_name in [\"W3_comb\",\"W4_comb\",\"W5_comb\"] ):\n",
    "        col = \"mapNamesW3\"\n",
    "\n",
    "        BES_Panel[col] = \\\n",
    "            BES_Panel[col].astype('float64')\n",
    "        var_type.loc[col,\"dtype\"] = BES_Panel[col].dtype.name        \n",
    "        var_type.loc[ col , \"dataset_specific_hardcoded_fix\" ] = list(BES_Panel[col].unique())\n",
    "    \n",
    "\n",
    "    if ( dataset_name in [\"W12_only\",\"W11_only\",\"W3_only\",\"W2_only\",\"W1_only\"] ):\n",
    "        partyContact = {1.0:\"No\",\n",
    "                        2.0:\"Yes\",\n",
    "                        9999.0:\"Don't know\"}\n",
    "        col = \"partyContactGrn\"\n",
    "        careful_replace( col , {el:el for el in partyContact.values()} )     \n",
    "\n",
    "#                    'Own - outright|Own - with a mortgage|Own (part-own) - through shared ownership scheme (i.e. pay part mortgage, part rent)|Rent - from a private landlord|Rent - from my local authority|Rent - from a housing association|Neither - I live with my parents, family or friends but pay some rent to them|Neither - I live rent-free with my parents, family or friends|Other|9999':\n",
    "#                        [ 'Own outright',\n",
    "#                          'Own with a mortgage',\n",
    "#                          'Own (part-own) through shared ownership scheme (i.e. pay part mortgage, part rent)',\n",
    "#                          'Rent from a private landlord',\n",
    "#                          'Rent from my local authority',\n",
    "#                          'Rent from a housing association',\n",
    "#                          'Neither I live with my parents, family or friends but pay some rent to them',\n",
    "#                          'Neither I live rent-free with my parents, family or friends',\n",
    "#                          'Other',\n",
    "#                          '9999'], #profile_house_tenureW11|profile_house_tenureW12|profile_house_tenureW13\n",
    "        \n",
    "# housing\tW13_only\tW6_comb\tcategory\t3\thousing\tOwn the leasehold/freehold outright|Buying leasehold/freehold on a mortgage|Rented from local authority|Rented from private landlord|It belongs to a Housing Association\tOwn - outright|Own - with a mortgage|Own (part-own) - through shared ownership scheme (i.e. pay part mortgage, part rent)|Rent - from a private landlord|Rent - from my local authority|Neither - I live with my parents, family or friends but pay some rent to them|Neither - I live rent-free with my parents, family or friends\n",
    "\n",
    "        \n",
    "    if ( dataset_name in [\"W6_comb\"] ):\n",
    "        housing_replace = {'Own \\x96 outright': 'Own outright',\n",
    "                         'Own \\x96 with a mortgage': 'Own with a mortgage',\n",
    "                         'Own (part-own) \\x96 through shared ownership scheme (i.e. pay part mortgage, part rent)': 'Own (part-own) through shared ownership scheme (i.e. pay part mortgage, part rent)',\n",
    "                         'Rent \\x96 from a private landlord': 'Rent from a private landlord',\n",
    "                         'Rent \\x96 from my local authority': 'Rent from my local authority',\n",
    "                         'Neither \\x96 I live with my parents, family or friends but pay some rent to them': 'Neither I live with my parents, family or friends but pay some rent to them',\n",
    "                         'Neither \\x96 I live rent-free with my parents, family or friends': 'Neither I live rent-free with my parents, family or friends',\n",
    "                         'Other':'Other',\n",
    "                         '9999':'Rent from a housing association'}\n",
    "        \n",
    "        housing_final_cats = ['Own outright',\n",
    "                         'Own with a mortgage',\n",
    "                         'Own (part-own) through shared ownership scheme (i.e. pay part mortgage, part rent)',\n",
    "                         'Rent from a private landlord',\n",
    "                         'Rent from my local authority',\n",
    "                         'Rent from a housing association',\n",
    "                         'Neither I live with my parents, family or friends but pay some rent to them',\n",
    "                         'Neither I live rent-free with my parents, family or friends',\n",
    "                         'Other']\n",
    "        \n",
    "        col = \"housing\" \n",
    "        careful_replace_and_set_cats( col,  housing_replace, housing_final_cats )\n",
    "        \n",
    "# None/ No leader|David Cameron|Ed Miliband|Nick Clegg|Nicola Sturgeon|Leanne Wood|Nigel Farage|Natalie Bennett|222.0|Don't know\n",
    "# None/ No leader|David Cameron|Ed Miliband|Nick Clegg|Nicola Sturgeon|Leanne Wood|Nigel Farage|Natalie Bennett|222|Don't know\n",
    "# bestLeaderCampaign\tW6_only\n",
    "# worstLeaderCampaign\tW6_only\n",
    "        \n",
    "        \n",
    "\n",
    "    BestWorstLeader_replace = {\"None/ No leader\":\"None/No leader\",\n",
    "                               10.0:\"All leaders equally bad\",\n",
    "                               222.0:\"All leaders equally bad\",\n",
    "                               222:\"All leaders equally bad\"}\n",
    "    BestWorstLeader_final_cats = [\"None/No leader\",\"David Cameron\",\"Ed Miliband\",\"Nick Clegg\",\"Nicola Sturgeon\",\n",
    "                                  \"Leanne Wood\",\"Nigel Farage\",\"Natalie Bennett\",\"All leaders equally bad\"]\n",
    "    # run on all datasets - wait - only ones in which it exists\n",
    "    \n",
    "#     if ( dataset_name in [\"W6_comb\",\"W5_comb\"] ):\n",
    "    col = \"bestLeaderCampaignW5\"\n",
    "    if ( col in BES_Panel.columns ):\n",
    "        careful_replace_and_set_cats( col,  BestWorstLeader_replace, BestWorstLeader_final_cats )\n",
    "    col = \"worstLeaderCampaignW5\"        \n",
    "    if ( col in BES_Panel.columns ):  \n",
    "        careful_replace_and_set_cats( col, BestWorstLeader_replace, BestWorstLeader_final_cats )\n",
    "\n",
    "#     if ( dataset_name in [\"W5_only\",\"W6_only\"] ):\n",
    "    col = \"bestLeaderCampaign\"\n",
    "    if ( col in BES_Panel.columns ):\n",
    "        careful_replace_and_set_cats( col,  BestWorstLeader_replace, BestWorstLeader_final_cats )\n",
    "        \n",
    "    col = \"worstLeaderCampaign\"\n",
    "    if ( col in BES_Panel.columns ):\n",
    "        careful_replace_and_set_cats( col,  BestWorstLeader_replace, BestWorstLeader_final_cats )        \n",
    "      \n",
    "\n",
    "    scotReferendumIntention_replace = {'Scotland should become an independent country':\"Will vote 'Yes'\",\n",
    "                                       111.0:'Will vote no',\n",
    "                                       99.0:\"Don't know\",\n",
    "                                       2.0:\"Will not vote\",}\n",
    "    scotReferendumIntention_final_cats = ['Will vote no', \"Will vote 'Yes'\", 'Will not vote', \"Don't know\"]\n",
    "        \n",
    "    if ( dataset_name in [\"W6_comb\"] ):\n",
    "        careful_replace_and_set_cats( \"scotReferendumIntentionW6\",  scotReferendumIntention_replace, scotReferendumIntention_final_cats )\n",
    "\n",
    "        \n",
    "    \n",
    "    Religion = {'No, I do not regard myself as belonging to any particular religion.': 'No, I do not regard myself as belonging to any particular religion.',\n",
    "         'Yes - Church of England/Anglican/Episcopal': 'Yes - Church of England/Anglican/Episcopal',\n",
    "         'Yes - Roman Catholic': 'Yes - Roman Catholic',\n",
    "         'Yes - Presbyterian/Church of Scotland': 'Yes - Presbyterian/Church of Scotland',\n",
    "         'Yes - Methodist': 'Yes - Methodist',\n",
    "         'Yes - Baptist': 'Yes - Baptist',\n",
    "         'Yes - United Reformed Church': 'Yes - United Reformed Church',\n",
    "         'Yes - Free Presbyterian': 'Yes - Free Presbyterian',\n",
    "         'Yes - Brethren': 'Yes - Brethren',\n",
    "         'Yes - Judaism': 'Yes - Judaism',\n",
    "         'Yes - Hinduism': 'Yes - Hinduism',\n",
    "         'Yes - Islam': 'Yes - Islam',\n",
    "         'Yes - Sikhism': 'Yes - Sikhism',\n",
    "         'Yes - Buddhism': 'Yes - Buddhism',\n",
    "         'Yes - Other': 'Yes - Other',\n",
    "         16.0: 'Prefer not to say',\n",
    "         17.0: 'Yes - Orthodox Christian',\n",
    "         18.0: 'Yes - Pentecostal',\n",
    "         19.0: 'Yes - Evangelical /independent/non-denominational'}\n",
    "\n",
    "    \n",
    "    if ( dataset_name in [\"W6_comb\",\"W5_comb\",\"W5_only\",\"W4_comb\",\"W3_comb\"] ):\n",
    "\n",
    "        col = \"profile_religion\"\n",
    "        careful_replace( col , Religion )        \n",
    "\n",
    "    if ( dataset_name in [\"W1_only\"] ):\n",
    "\n",
    "        col = \"profile_religion\"\n",
    "        careful_replace( col , {el:el for el in Religion.values()} )            \n",
    "        \n",
    "    if ( dataset_name in [\"W7_only\"] ):\n",
    "        col = \"ns_sec\"\n",
    "        ns_sec = \"Employers in large establishments|Higher managerial and administrative occupations|L3.1 Traditional employees|L3.2 New employees|L3.3 Traditional self-employed|L3.4 New self-employed|L4.1 Traditional employees|L4.2 New employees|L4.3 Traditional self-employed|L4.4 New self-employed|Lower managerial and administrative occupations|Higher supervisory occupations|L7.1 Intermediate clerical and administrative occupations|L7.2 Intermediate sales and service occupations|L7.3 Intermediate technical and auxiliary occupations|L7.4 Intermediate engineering occupations|L8.1 Employers in small establishments in industry, commerce, services etc.|L8.2 Employers in small establishments in agriculture|L9.1 Own account workers (non-professional)|L9.2 Own account workers (agriculture)|Lower supervisory occupations|L11.1 Lower technical craft occupations|L11.2 Lower technical process operative occupations|L12.1 Semi-routine sales occupations|L12.2 Semi-routine service occupations|L12.3 Semi-routine technical occupations|L12.4 Semi-routine operative occupations|L12.5 Semi-routine agricultural occupations|L12.6 Semi-routine clerical occupations|L12.7 Semi routine childcare occupations|L13.1 Routine sales and service occupations|L13.2 Routine production occupations|L13.3 Routine technical occupations|L13.4 Routine operative occupations|L13.5 Routine agricultural occupations\"\n",
    "        \n",
    "        careful_replace( col , {el:el for el in ns_sec.split(\"|\")} )\n",
    "#         BES_Panel[col].cat.set_categories(ns_sec.split(\"|\"),inplace=True)\n",
    "        \n",
    "        \n",
    "    if ( dataset_name in [\"W1_only\"] ):\n",
    "        ageGroup = {1.0:\"Under 18\",\n",
    "                    2.0:\"18-25\",\n",
    "                    3.0:\"26-35\",\n",
    "                    4.0:\"36-45\",\n",
    "                    5.0:\"46-55\",\n",
    "                    6.0:\"56-65\",\n",
    "                    7.0:\"66+\"}\n",
    "        col = \"ageGroup\"\n",
    "        careful_replace( col , {el:el for el in ageGroup.values()})      \n",
    "        \n",
    "        \n",
    "    if ( dataset_name in [ \"W13_comb\" , \"W11_only\" ] ):\n",
    "        \n",
    "        # None|Church of England/Anglican/Episcopal|Roman Catholic|Presbyterian/Church of Scotland|Methodist|Baptist\n",
    "        # A|B|C1|C2|D|E|Refused|Unknown\n",
    "        # DOUBLE CHECK DISTRIBUTION\n",
    "        SocialGrades = {\"None\":\"A\",\n",
    "                        \"Church of England/Anglican/Episcopal\":\"B\",\n",
    "                        \"Roman Catholic\":\"C1\",\n",
    "                        \"Presbyterian/Church of Scotland\":\"C2\",\n",
    "                        \"Methodist\":\"D\",\n",
    "                        \"Baptist\":\"E\",\n",
    "                        \"<placeholder1>\":\"Refused\",\n",
    "                        \"<placeholder2>\":\"Unknown\"}\n",
    "        col = \"profile_socialgrade_cie\"        \n",
    "        careful_replace( col , SocialGrades )\n",
    "        \n",
    "    NumEmployees = {1.0:\"1 to 24 employees\",\n",
    "                    2.0:\"25 to 499 employees\",\n",
    "                    3.0:\"500 or more employees\",\n",
    "                    9999.0:\"Don't know\"}\n",
    "\n",
    "    if ( dataset_name in [\"W1_only\",\"W2_only\",\"W3_only\",\"W4_only\",\"W11_only\",\"W12_only\",\"W13_only\",\"W13_comb\", \"W10_only\"] ):\n",
    "        # necessary because motherNumEmployees lacks some categories!\n",
    "\n",
    "        col = \"fatherNumEmployees\"\n",
    "        careful_replace( col , NumEmployees )\n",
    "\n",
    "        col = \"motherNumEmployees\"\n",
    "        careful_replace( col , NumEmployees )\n",
    "        \n",
    "    if ( dataset_name in [\"W9_only\"] ):        \n",
    "        \n",
    "        col = \"motherNumEmployees\"\n",
    "        careful_replace( col , {el:el for el in NumEmployees.values()} )        \n",
    "\n",
    "    if ( dataset_name in [\"W6_comb\"] ):\n",
    "        # not entirely necessary to implement it this way, it's just a bit clearer\n",
    "\n",
    "        churchAttendance = {111.0:\"Never or practically never\",\n",
    "                            \"Less often than once a year\":\"Less often than once a year\",\n",
    "                            \"Less often but at least once a year\":\"Less often but at least once a year\",\n",
    "                            \"Less often but at least twice a year\":\"Less often but at least twice a year\",\n",
    "                            \"Less often but at least once a month\":\"Less often but at least once a month\",\n",
    "                            \"Less often but at least once in two weeks\":\"Less often but at least once in two weeks\",\n",
    "                            \"Once a week or more\":\"Once a week or more\",\n",
    "                            222.0:\"Varies too much to say\",\n",
    "                            98.0:\"I am not religious\",\n",
    "                            99.0:\"Don't know\"}\n",
    "\n",
    "        col = \"churchAttendanceW6\"\n",
    "        careful_replace( col , churchAttendance )\n",
    "\n",
    "\n",
    "        partyMember =      {0.0:\"No, I have never been a member\",\n",
    "                            \"I am not a member now but I used to be\":\"I am not a member now but I used to be\",\n",
    "                            \"Yes, I am a member of a party\":\"Yes, I am a member of a party\",\n",
    "                            9999.0:\"Don't know\"}\n",
    "\n",
    "        col = \"partyMemberW6\"\n",
    "        careful_replace( col , partyMember )       \n",
    "\n",
    "\n",
    "    headHouseholdPast_cat_list = \"My father|My mother|Someone else|No one in my house worked|Don't know\"\n",
    "    if ( dataset_name in [ \"W3_only\",\"W4_only\",\"W11_only\",\"W12_only\",\"W13_only\", \"W13_comb\",\"W10_only\" ] ):\n",
    "        hardcoded_fix(\"headHouseholdPast\",\n",
    "                      headHouseholdPast_cat_list)\n",
    "\n",
    "    generalElectionCertainty_cat_list = \"Not at all certain|2|3|4|5|6|Completely certain|Don't know\"\n",
    "    if ( dataset_name in [\"W4_comb\",\"W5_comb\"] ):\n",
    "        # array of floats, should be a categorical\n",
    "        hardcoded_fix(\"generalElectionCertaintyW1\",\n",
    "                      generalElectionCertainty_cat_list)\n",
    "        hardcoded_fix(\"generalElectionCertaintyW2\",\n",
    "                      generalElectionCertainty_cat_list)\n",
    "\n",
    "    if ( dataset_name in [\"W5_comb\"] ):\n",
    "        # array of floats, should be a categorical\n",
    "        hardcoded_fix(\"generalElectionCertaintyW3\",\n",
    "                      generalElectionCertainty_cat_list)        \n",
    "\n",
    "\n",
    "    scotReferendumIntention_cat_list = \"Will vote no|Will vote 'Yes'|Will not vote|Don't know\"\n",
    "    if ( dataset_name in [\"W4_comb\",\"W5_comb\",\"W6_comb\"] ):\n",
    "        # array of floats, should be a categorical  \n",
    "        hardcoded_fix(\"scotReferendumIntentionW4\",\n",
    "                      scotReferendumIntention_cat_list)  \n",
    "\n",
    "    selfNumEmployees_cat_list = \"1 to 24 employees|25 to 499 employees|500 or more employees|Don't know\"\n",
    "#     selfNumEmployeesW6_W12, selfNumEmployeesLastW6_W12\n",
    "    if ( dataset_name in [ 'W13_comb' ] ):\n",
    "        hardcoded_fix(\"selfNumEmployeesW6_W12\",\n",
    "                      selfNumEmployees_cat_list )\n",
    "        hardcoded_fix(\"selfNumEmployeesLastW6_W12\",\n",
    "                      selfNumEmployees_cat_list )    \n",
    "\n",
    "    if ( dataset_name in [ 'W12_only' ] ):\n",
    "        hardcoded_fix(\"selfNumEmployeesW6_\",\n",
    "                      selfNumEmployees_cat_list )\n",
    "        hardcoded_fix(\"selfNumEmployeesLastW6_\",\n",
    "                      selfNumEmployees_cat_list )          \n",
    "    \n",
    "    if ( dataset_name in [ \"W7_comb\" ] ):  \n",
    "        hardcoded_fix(\"selfNumEmployeesW6W7\",\n",
    "                      selfNumEmployees_cat_list )           \n",
    "        hardcoded_fix(\"selfNumEmployeesLastW6W7\",\n",
    "                      selfNumEmployees_cat_list )          \n",
    "\n",
    "    if ( dataset_name in [ \"W8_comb\" ] ):\n",
    "        hardcoded_fix(\"selfNumEmployeesW6W7W8\",\n",
    "                      selfNumEmployees_cat_list )           \n",
    "        hardcoded_fix(\"selfNumEmployeesLastW6W7W8\",\n",
    "                      selfNumEmployees_cat_list )  \n",
    "\n",
    "    if ( dataset_name in [ \"W10_comb\", \"W9_comb\", \"W9_only\" ] ): #\"W13_comb\", \n",
    "        hardcoded_fix(\"selfNumEmployeesW6W7W8W9\",\n",
    "                      selfNumEmployees_cat_list )\n",
    "        \n",
    "    if ( dataset_name in [ \"W10_comb\", \"W9_comb\", \"W9_only\" ] ): #\"W13_comb\",         \n",
    "        hardcoded_fix(\"selfNumEmployeesLastW6W7W8W9\",\n",
    "                      selfNumEmployees_cat_list )\n",
    "        \n",
    "#     if ( dataset_name in [ \"W12_only\",\"W11_only\",\"W10_only\",\"W13_comb\" ] ):\n",
    "        \n",
    "# #         careful_replace( \"selfNumEmployees\" , {el:el for el in NumEmployees.values()} )  \n",
    "# #         careful_replace( \"selfNumEmployeesLast\" , {el:el for el in NumEmployees.values()} )\n",
    "        \n",
    "#         careful_replace_and_set_cats( \"selfNumEmployees\", {}, NumEmployees.values() )\n",
    "#         careful_replace_and_set_cats( \"selfNumEmployeesLast\", {}, NumEmployees.values() )        \n",
    "\n",
    "\n",
    "    #    \"knowf2f2\",\"knowf2f3\", #  floats (0.0, 1.0, 99.0)  that should be categories True|False|Don't know\n",
    "    knowf2_cat_list = \"True|False|Don't know\"\n",
    "    if ( dataset_name in [\"W12_only\"]):\n",
    "        hardcoded_fix(\"knowf2f2\",\n",
    "                      knowf2_cat_list )            \n",
    "        hardcoded_fix(\"knowf2f3\",\n",
    "                      knowf2_cat_list )  \n",
    "\n",
    "    if ( dataset_name in [ \"W13_comb\" ] ):  \n",
    "        hardcoded_fix(\"knowf2f2W12\",\n",
    "                      knowf2_cat_list )             \n",
    "        hardcoded_fix(\"knowf2f3W12\",\n",
    "                      knowf2_cat_list )\n",
    "\n",
    "    likeSalmond_list = \"Strongly dislike|1.0|2.0|3.0|4.0|5.0|6.0|7.0|8.0|9.0|Strongly like|Don't know\"\n",
    "    if ( dataset_name in [ \"W4_comb\",\"W4_comb\",\"W5_comb\" ] ):\n",
    "        hardcoded_fix(\"likeSalmondW1\",\n",
    "                      likeSalmond_list )   \n",
    "        hardcoded_fix(\"likeSalmondW2\",\n",
    "                      likeSalmond_list )\n",
    "        hardcoded_fix(\"likeSalmondW3\",\n",
    "                      likeSalmond_list )\n",
    "\n",
    "    eesEUIntegration_list = \"Unification has already gone too far|1.0|2.0|3.0|4.0|5.0|6.0|7.0|8.0|9.0|Unification should be pushed further|Don't know\"    \n",
    "    if ( dataset_name in [ \"W3_comb\",\"W4_comb\",\"W4_comb\",\"W5_comb\" ] ):\n",
    "        hardcoded_fix(\"eesEUIntegrationGreenW2\",\n",
    "                      eesEUIntegration_list )    \n",
    "\n",
    "    likeSturgeon_list = \"Strongly dislike|1.0|2.0|3.0|4.0|5.0|6.0|7.0|8.0|9.0|Strongly like|Don't know\"    \n",
    "    if ( dataset_name in [ \"W4_comb\",\"W4_comb\",\"W5_comb\" ] ):\n",
    "        hardcoded_fix(\"likeSturgeonW4\",\n",
    "                      likeSturgeon_list )\n",
    "\n",
    "    # W5_comb\n",
    "    # No|Yes\tGot a lot worse|Got a little worse\n",
    "    # partyContactDKW5, participation_1-6W5, sharedContentOnline_1-5W5, participation_99W5\n",
    "    participation_list = \"No|Yes\"    \n",
    "    if ( dataset_name in [ \"W5_comb\" ] ):\n",
    "        hardcoded_fix(\"partyContactDKW5\",\n",
    "                      participation_list )    \n",
    "        hardcoded_fix(\"participation_1W5\",\n",
    "                      participation_list )   \n",
    "        hardcoded_fix(\"participation_2W5\",\n",
    "                      participation_list )   \n",
    "        hardcoded_fix(\"participation_3W5\",\n",
    "                      participation_list )   \n",
    "        hardcoded_fix(\"participation_4W5\",\n",
    "                      participation_list )   \n",
    "        hardcoded_fix(\"participation_5W5\",\n",
    "                      participation_list )   \n",
    "        hardcoded_fix(\"participation_6W5\",\n",
    "                      participation_list )   \n",
    "        hardcoded_fix(\"sharedContentOnline_1W5\",\n",
    "                      participation_list )  \n",
    "        hardcoded_fix(\"sharedContentOnline_2W5\",\n",
    "                      participation_list )      \n",
    "        hardcoded_fix(\"sharedContentOnline_3W5\",\n",
    "                      participation_list )      \n",
    "        hardcoded_fix(\"sharedContentOnline_4W5\",\n",
    "                      participation_list )  \n",
    "        hardcoded_fix(\"sharedContentOnline_5W5\",\n",
    "                      participation_list )      \n",
    "        hardcoded_fix(\"participation_99W5\",\n",
    "                      participation_list )       \n",
    "        \n",
    "    if ( dataset_name in [\"W26_only\"] ):\n",
    "        party_contact_freq_replace = {}\n",
    "        party_contact_freq_cat = [\"Never\",'1.0',\n",
    "         '2.0',\n",
    "         '3.0',\n",
    "         '4.0',\n",
    "         '5.0',\n",
    "         '6.0',\n",
    "         '7.0',\n",
    "         '8.0',\n",
    "         '9.0',\n",
    "         '10 or more times',\n",
    "         \"Don't know\"]\n",
    "        for col in ['partyContactConFreq1',\n",
    "         'partyContactConFreq2',\n",
    "         'partyContactConFreq3',\n",
    "         'partyContactConFreq4',\n",
    "         'partyContactConFreq5',\n",
    "         'partyContactConFreq6',\n",
    "         'partyContactConFreq7',\n",
    "         'partyContactLabFreq1',\n",
    "         'partyContactLabFreq2',\n",
    "         'partyContactLabFreq3',\n",
    "         'partyContactLabFreq4',\n",
    "         'partyContactLabFreq5',\n",
    "         'partyContactLabFreq6',\n",
    "         'partyContactLabFreq7',\n",
    "         'partyContactLDFreq1',\n",
    "         'partyContactLDFreq2',\n",
    "         'partyContactLDFreq3',\n",
    "         'partyContactLDFreq4',\n",
    "         'partyContactLDFreq5',\n",
    "         'partyContactLDFreq6',\n",
    "         'partyContactLDFreq7',\n",
    "         'partyContactSNPFreq2',\n",
    "         'partyContactSNPFreq3',\n",
    "         'partyContactSNPFreq4',\n",
    "         'partyContactSNPFreq5',\n",
    "         'partyContactSNPFreq6',\n",
    "         'partyContactPCFreq2',\n",
    "         'partyContactPCFreq5',\n",
    "         'partyContactPCFreq6',\n",
    "         'partyContactGreenFreq1',\n",
    "         'partyContactGreenFreq2',\n",
    "         'partyContactGreenFreq3',\n",
    "         'partyContactGreenFreq4',\n",
    "         'partyContactGreenFreq5',\n",
    "         'partyContactGreenFreq6',\n",
    "         'partyContactGreenFreq7',\n",
    "         'partyContactBrexitFreq1',\n",
    "         'partyContactBrexitFreq2',\n",
    "         'partyContactBrexitFreq3',\n",
    "         'partyContactBrexitFreq4',\n",
    "         'partyContactBrexitFreq5',\n",
    "         'partyContactBrexitFreq6',\n",
    "         'partyContactBrexitFreq7',\n",
    "         'partyContactIndFreq1',\n",
    "         'partyContactIndFreq2',\n",
    "         'partyContactIndFreq3',\n",
    "         'partyContactIndFreq4',\n",
    "         'partyContactIndFreq5',\n",
    "         'partyContactIndFreq6',\n",
    "         'partyContactIndFreq7',\n",
    "         'partyContactOtherFreq1',\n",
    "         'partyContactOtherFreq2',\n",
    "         'partyContactOtherFreq3',\n",
    "         'partyContactOtherFreq5',\n",
    "         'partyContactOtherFreq6',\n",
    "         'partyContactOtherFreq7']:\n",
    "\n",
    "            careful_replace_and_set_cats( col,  party_contact_freq_replace, party_contact_freq_cat )\n",
    "        \n",
    "\n",
    "        \n",
    "        col = \"buyHomeFuture\"\n",
    "        \n",
    "#         BES_Panel[\"buyHomeFuture\"].value_counts()\n",
    "\n",
    "        buyHomeFuture_replace = {1.0:\"I do not want to purchase a home\",\n",
    "                2.0:\"No, I will not be able to purchase a home\",\n",
    "                3.0:\"Yes, I will be able to buy with a mortgage\",\n",
    "                4.0:\"Yes, I will be able to buy a home outright\",\n",
    "                5.0:\"Other\",\n",
    "                9999.0:\"Don't know / Prefer not to say\"}\n",
    "        buyHomeFuture_cat = ['I do not want to purchase a home',\n",
    "             'No, I will not be able to purchase a home',\n",
    "             'Yes, I will be able to buy with a mortgage',\n",
    "             'Yes, I will be able to buy a home outright',\n",
    "             'Other',\n",
    "             \"Don't know / Prefer not to say\"]\n",
    "        careful_replace_and_set_cats( col,  buyHomeFuture_replace, buyHomeFuture_cat ) \n",
    "\n",
    "# Don't know / Prefer not to say - new non-answer string\n",
    "# Also \"I do not want to purchase a home\" doesn't fit with the otherwise linear scheme\n",
    "\n",
    "        col = \"homeFinance\"\n",
    "        homeFinance_replace = {1.0:\"No one in my family could lend me money\",\n",
    "                      2.0:\"Less than £5,000\",\n",
    "                      3.0:\"£5,000-£9,999\",\n",
    "                      4.0:\"£10,000-£24,999\",\n",
    "                      5.0:\"£25,000-£49,999\",\n",
    "                      6.0:\"£50,000-£74,999\",\n",
    "                      7.0:\"£75,000-£99,999\",\n",
    "                      8.0:\"£100,000-£149,999\",\n",
    "                      9.0:\"£150,000-£199,999\",\n",
    "                      10.0:\"£200,000 or above\",\n",
    "                      9999.0:\"Don't know / Prefer not to say\"}\n",
    "        homeFinance_cat = ['No one in my family could lend me money',\n",
    "                     'Less than £5,000',\n",
    "                     '£5,000-£9,999',\n",
    "                     '£10,000-£24,999',\n",
    "                     '£25,000-£49,999',\n",
    "                     '£50,000-£74,999',\n",
    "                     '£75,000-£99,999',\n",
    "                     '£100,000-£149,999',\n",
    "                     '£150,000-£199,999',\n",
    "                     '£200,000 or above',\n",
    "                     \"Don't know / Prefer not to say\"]\n",
    "        careful_replace_and_set_cats( col,  homeFinance_replace, homeFinance_cat ) \n",
    "        \n",
    "        col = \"inheritMoney\"\n",
    "        inheritMoney_replace = {0.0:\"No\", 1.0:\"Yes\", 9999.0:\"Don't know\" }        \n",
    "        inheritMoney_cat = [\"No\", \"Yes\", \"Don't know\" ]\n",
    "        careful_replace_and_set_cats( col,  inheritMoney_replace, inheritMoney_cat ) \n",
    "    \n",
    "        col = \"inheritChangeCircs\"\n",
    "        careful_replace_and_set_cats( col,  inheritMoney_replace, inheritMoney_cat )     \n",
    "     \n",
    "        col = \"age\"\n",
    "        BES_Panel[\"age\"] = BES_Panel[\"age\"].astype('category')\n",
    "        \n",
    "    if ( dataset_name in [\"W27_only\",\"W28_only\"] ):        \n",
    "        \n",
    "        BES_Panel[\"mii_cat_llm\"] = BES_Panel[\"mii_cat_llm\"].astype('category')       \n",
    "        \n",
    "    if ( dataset_name in [\"W26_only\",\"W27_only\"] ):          \n",
    "        \n",
    "        col = \"speakWelsh\"\n",
    "        speakWelsh_replace = {0.0:\"No\",1.0:\"Yes, but not fluently\",2.0:\"Yes, fluently\",9999.0:\"Don't know\"}    \n",
    "        speakWelsh_cat = [\"No\",\"Yes, but not fluently\",\"Yes, fluently\",\"Don't know\"]\n",
    "        careful_replace_and_set_cats( col,  speakWelsh_replace, speakWelsh_cat )         \n",
    "        \n",
    "    if ( dataset_name in [\"W29_only\"] ):           \n",
    "        for col in ['noDependentsInHouseW26','sickElderlyInHouseW26','schoolKidsInHouseW26','preschoolKidsInHouseW26',\n",
    "                    \"disabilityCensusW26\",\"disabilityChildW26\",\"careAdult_sickW26\",\"careAdult_elderlyW26\",\"careAdult_disabledW26\"]:\n",
    "            \n",
    "            disability_replace = {0.0:\"No\",1.0:\"Yes\"}  \n",
    "            disability_cat = [\"No\",\"Yes\"]\n",
    "            careful_replace_and_set_cats( col,  disability_replace, disability_cat )    \n",
    "            \n",
    "    if ( dataset_name in [\"W29_only\"] ):         \n",
    "        col = 'disabilityCensusImpactW26'\n",
    "        disabilityCensusImpact_replace = {1.0:\"Yes, a lot\",2.0:\"Yes, a little\",3.0:\"Not at all\"}\n",
    "        disabilityCensusImpact_cat = [\"No\",\"Yes\"]\n",
    "        careful_replace_and_set_cats( col,  disabilityCensusImpact_replace, disabilityCensusImpact_cat )  \n",
    "    \n",
    "    return BES_Panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # BES_Panel[\"homeFinance\"].value_counts()\n",
    "\n",
    "# homeFinance_replace = {1.0:\"No one in my family could lend me money\",\n",
    "#                       2.0:\"Less than £5,000\",\n",
    "#                       3.0:\"£5,000-£9,999\",\n",
    "#                       4.0:\"£10,000-£24,999\",\n",
    "#                       5.0:\"£25,000-£49,999\",\n",
    "#                       6.0:\"£50,000-£74,999\",\n",
    "#                       7.0:\"£75,000-£99,999\",\n",
    "#                       8.0:\"£100,000-£149,999\",\n",
    "#                       9.0:\"£150,000-£199,999\",\n",
    "#                       10.0:\"£200,000 or above\",\n",
    "#                       9999.0:\"Don't know / Prefer not to say\"}\n",
    "\n",
    "# list(homeFinance_replace.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_100_seq(col, start, finish, weasel, rng=100):\n",
    "    lst = list([weasel,start, finish])\n",
    "    lst_dict = {\"0\":start,str(rng):finish}\n",
    "\n",
    "    fullseq = [start]\n",
    "    [fullseq.append(str(x)) for x in range(1,rng)]\n",
    "    fullseq.append(finish)\n",
    "    fullseq.append(weasel)\n",
    "    # make sure all numbers in same format (string integers)\n",
    "    BES_Panel[col] = BES_Panel[col].cat.rename_categories( [str(int(x)) if x not in lst else x for x in BES_Panel[col].cat.categories ] )\n",
    "    BES_Panel[col] = BES_Panel[col].cat.rename_categories( [lst_dict[x] if x in lst_dict.keys() else x for x in BES_Panel[col].cat.categories ] )\n",
    "    \n",
    "    # change categories to correct range\n",
    "    BES_Panel[col] = BES_Panel[col].cat.set_categories(fullseq)\n",
    "    if len( BES_Panel[col].cat.categories ) != rng+2:\n",
    "        raise Exception(\"wrong number of categories!\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def number_and_string_sequences(  ):\n",
    "\n",
    "# How to deal with large sequences of numbers (e.g. %)\n",
    "# Which have some values missing (presumably because no entries)\n",
    "# But also have strings at the ends\n",
    "\n",
    "# Want to keep the string categories (because they're useful for clarification)\n",
    "# But also want the numeric coding to be remain accurate\n",
    "# e.g. \"0% no support for X, 1% ... 45%, 83%, 100% complete support for X\" -> would normally turn into [0,1...45,46,47]\n",
    "# should turn into [0,1...45,83,100]\n",
    "\n",
    "# It's *POSSIBLE* that question answerers don't think this way - might get cleaner results by just assuming positional placement\n",
    "# Would be useful to have a switch to test that\n",
    "\n",
    "\n",
    "\n",
    "# run on everything like this\n",
    "\n",
    "#\n",
    "\n",
    "# re.match( \"(winConstituency[a-zA-Z0-9_]+)\", \"winConstituencyConW4\").groups()[0]\n",
    "\n",
    "# maybe simply run this on all variables marked 6?\n",
    "# tweak the ends, drop the DKS, then turn to floats?\n",
    "\n",
    "\n",
    "    str_float_0_100_cats = [str(float(x)) for x in range(0,101)] # ['0.0', '1.0', '2.0', '3.0' ... '98.0', '99.0', '100.0']\n",
    "\n",
    "    ### this isn't an error so much as a matter of practicality\n",
    "    # if I make all these values integers then we don't have to\n",
    "    # worry about missing categories\n",
    "    # (assuming they're only missing because of legit. lack of entries)\n",
    "    col = \"scotRefExpectationTurnout\"\n",
    "\n",
    "    if ( col in  BES_Panel.columns ):    \n",
    "\n",
    "        start = \"0% of people will vote\"\n",
    "        finish = \"100% of people will vote\"\n",
    "        weasel = \"Don't know\"        \n",
    "        fix_100_seq(col, start, finish, weasel)         \n",
    "        \n",
    "#         scotRefExpectationTurnout_list = [\"100.0\" if x==\"100% of people will vote\" else x for x in BES_Panel[col].cat.categories]\n",
    "#         BES_Panel[col].cat.rename_categories( scotRefExpectationTurnout_list, inplace=True )\n",
    "#         add_categories()\n",
    "\n",
    "\n",
    "    col = \"winConstituencyPC\"    \n",
    "    if ( col in  BES_Panel.columns ):\n",
    "        \n",
    "        start = \"0 - Very unlikely to win\"\n",
    "        finish = \"100 - Very likely to win\"\n",
    "        weasel = \"Don't know\"        \n",
    "        fix_100_seq(col, start, finish, weasel)          \n",
    "        \n",
    "#         winConstituencyPC_list = [\"100.0\" if x==\"100 - Very likely to win\" else x for x in BES_Panel[col].cat.categories]\n",
    "#         winConstituencyPC_list = [\"0.0\" if x==\"0 - Very unlikely to win\" else x for x in winConstituencyPC_list]\n",
    "#         BES_Panel[col].cat.rename_categories( winConstituencyPC_list, inplace=True )\n",
    "\n",
    "    col = \"winConstituencySNP\"\n",
    "    if ( col in  BES_Panel.columns ):    \n",
    "        start = \"0 - Very unlikely to win\"\n",
    "        finish = \"100 - Very likely to win\"\n",
    "        weasel = \"Don't know\"        \n",
    "        fix_100_seq(col, start, finish, weasel)   \n",
    "\n",
    "    col = \"winConstituencyGreen\"\n",
    "    if ( col in  BES_Panel.columns ):    \n",
    "        start = \"0 - Very unlikely to win\"\n",
    "        finish = \"100 - Very likely to win\"\n",
    "        weasel = \"Don't know\"        \n",
    "        fix_100_seq(col, start, finish, weasel)    \n",
    "        \n",
    "        \n",
    "# Allow many fewer|2|4|5|6|7|8|9|Allow many more|Don't know        \n",
    "\n",
    "    col = \"immigSNP\"\n",
    "    if ( col in  BES_Panel.columns ):    \n",
    "        start = \"Allow many fewer\"\n",
    "        finish = \"Allow many more\"\n",
    "        weasel = \"Don't know\"        \n",
    "        fix_100_seq(col, start, finish, weasel,10)       \n",
    "\n",
    "\n",
    "    col = \"immigPC\"\n",
    "    if ( col in  BES_Panel.columns ):    \n",
    "        start = \"Allow many fewer\"\n",
    "        finish = \"Allow many more\"\n",
    "        weasel = \"Don't know\"        \n",
    "        fix_100_seq(col, start, finish, weasel,10)      \n",
    "## NEED TO SET THESE AS TYPE 6!    \n",
    "    \n",
    "    for col in [\"brexitEconImpactScot\",\"ukraineEconImpactScot\",\"pandemicEconImpactScot\",\"ukraineEconImpactWales\",\"pandemicEconImpactWales\"]:\n",
    "        if ( col in  BES_Panel.columns ): \n",
    "            start = \"Large negative impact\"\n",
    "            finish = \"Large positive impact\"\n",
    "            weasel = \"Don't know\"        \n",
    "            # default sequence 100 long (other than weasel)\n",
    "            fix_100_seq(col, start, finish, weasel) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_name = \"W1_only\"\n",
    "# BES_file_manifest = pd.read_csv( BES_small_data_files + \"BES_file_manifest.csv\" )\n",
    "# manifest = BES_file_manifest[ BES_file_manifest[\"Name\"] == dataset_name ]\n",
    "\n",
    "# data_subfolder = BES_data_folder + dataset_name + os.sep\n",
    "\n",
    "# filename = manifest[\"Stata_Filename\"].values[0]\n",
    "\n",
    "# BES_Panel = pd.read_stata( data_subfolder + filename)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# col = \"fatherNumEmployees\"\n",
    "# careful_replace( col , NumEmployees )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# col = \"motherNumEmployees\"\n",
    "# careful_replace( col , NumEmployees )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset(dataset_name):\n",
    "\n",
    "    BES_file_manifest = pd.read_csv( BES_small_data_files + \"BES_file_manifest.csv\" )\n",
    "    manifest = BES_file_manifest[ BES_file_manifest[\"Name\"] == dataset_name ]\n",
    "\n",
    "    data_subfolder = BES_data_folder + dataset_name + os.sep\n",
    "\n",
    "    filename = manifest[\"Stata_Filename\"].values[0]\n",
    "\n",
    "    global BES_Panel\n",
    "    BES_Panel = pd.read_stata( data_subfolder + filename)\n",
    "    ####################################################\n",
    "\n",
    "    # use this dataframe to store *everything* we're doing to transform/ignore variables!\n",
    "    global var_type\n",
    "    var_type = pd.DataFrame(columns = [\"dataset_name\",\"dtype\",\"cat_all_strings\",\"type\",\"pruned\",\"original_cat_list\",\n",
    "                                       \"renamed_cat_list\",\"reordered_cat_list\",\"final_cat_list\",\n",
    "                                       \"dataset_specific_hardcoded_fix\",\n",
    "                                       \"numerical_dont_knows\",\n",
    "                                       \"weasel_words\",\"typos\" ] )\n",
    "    ####################################################\n",
    "\n",
    "    BES_Panel = hard_coded_fixes( dataset_name ) # side effects on BES_Panel and var_type\n",
    "    number_and_string_sequences() # side effects on BES_Panel\n",
    "\n",
    "    variable_categories = pd.read_csv( BES_small_data_files + \"question_categories_correct.csv\",\n",
    "                                       encoding = encoding,index_col=False )\n",
    "    variable_categories.drop('Unnamed: 0', axis=1,inplace=True)\n",
    "\n",
    "    ( var_cat_dict_pruned , var_cat_dict_pruned_2 ) = create_var_list( variable_categories )\n",
    "    ####################################################\n",
    "\n",
    "    missing_col_names = []\n",
    "    try:\n",
    "        for col in BES_Panel.columns:\n",
    "            print(col)\n",
    "            dt =  BES_Panel[col].dtype.name # data type\n",
    "    #         not_found = False\n",
    "\n",
    "            var_type.loc[col,\"dataset_name\"] = dataset_name\n",
    "            # dtype is either nan because not set -> set\n",
    "            if not isinstance(var_type.loc[col,\"dtype\"],str):\n",
    "                var_type.loc[ col , \"dtype\"] = dt    \n",
    "            # if dtype == category *and* cat_all_strings not already set, set\n",
    "            if (var_type.loc[ col , \"dtype\" ] == 'category') and careful_isnan( var_type.loc[ col , \"cat_all_strings\" ] ):\n",
    "                var_type.loc[ col , \"cat_all_strings\" ] = np.all([isinstance(x,str) for x in BES_Panel[ col ].cat.categories])\n",
    "\n",
    "            not_found = False      \n",
    "\n",
    "            if (col in ignore_list) or (var_type.loc[col,\"type\"] == -2): # exclude values from ignore_list *and manually coded errors*\n",
    "                var_type.loc[col,\"type\"] = -2\n",
    "                if var_type.loc[ col , \"cat_all_strings\" ]==True:\n",
    "                    var_type.loc[ col, \"original_cat_list\" ] = \"|\".join( BES_Panel[col].cat.categories )\n",
    "                elif ('float' in dt) or ('int' in dt):\n",
    "                    var_type.loc[ col, \"original_cat_list\" ] = list(BES_Panel[col].unique())\n",
    "\n",
    "            elif (col in [\"id\"] ): # id\n",
    "                var_type.loc[col,\"type\"] = -5\n",
    "\n",
    "            elif (dt == 'object'): # (probably) text\n",
    "                var_type.loc[col,\"type\"] = -4\n",
    "\n",
    "            elif (\"datetime\" in dt): # datetime\n",
    "                var_type.loc[col,\"type\"] = -3\n",
    "\n",
    "        # 0 - personality measures (in steps of .5?), personality_agreeableness ...etc, riskScaleW8        \n",
    "            elif (col in [\"personality_agreeableness\",\n",
    "                         \"personality_conscientiousness\",\n",
    "                         \"personality_extraversion\",\n",
    "                         \"personality_neuroticism\",\n",
    "                         \"personality_openness\"]) or (re.match(\"(cogempathy|affempathy|zeroSum)IRT\",col) is not None) or (re.match(\"riskScale(W[0-9]+)?\",col) is not None) :\n",
    "\n",
    "                var_type.loc[col,\"type\"] = 0\n",
    "\n",
    "        # 7 - soc2010(W3-6_comb,W5_only), v1(W5_comb), RandomIDW1(W3-6_comb), mapNames(W3_only), mapNamesW3 (W3-10_comb,W13_comb)        \n",
    "            elif re.match(\"soc2010|v1|RandomIDW1|mapNames(W[0-9]+)?\" ,col) is not None:\n",
    "                var_type.loc[col,\"type\"] = 7\n",
    "\n",
    "        # 8 - pano, electoratepcon, <party>sh10pcon, turnout10pcon, winnersh10pcon, runnerupsh10pcon, marginsh10pcon\n",
    "        # don't include 'runnerup10pcon', 'winner10pcon'- these are categorical!\n",
    "        # all relate to parliamentary constituency (pano applies to different waves - rest are about 2010 general election)\n",
    "            elif re.match( \"pano(W[0-9]+)?|electoratepcon|[a-zA-Z]+sh10pcon|turnout10pcon\" , col ) is not None:\n",
    "                var_type.loc[col,\"type\"] = 8\n",
    "\n",
    "            elif col in ['cciW1W2W3W4W5','ccinoITW1W2W3W4W5','justITW1W2W3W4W5','cciW6W7W8W9','ccinoITW6W7W8W9','justITW6W7W8W9']:\n",
    "                var_type.loc[col,\"type\"] = 9\n",
    "\n",
    "            # wave flags/weights (int and float)\n",
    "            elif re.match(\"wave[0-9]+|\"\\\n",
    "                          \"w[0-9]+core|\"\\\n",
    "                          \"w[0-9]+full|\"\\\n",
    "                          \"wt_daily_W[0-9]+|\"\\\n",
    "                          \"wt_core_W[0-9]+|\"\\\n",
    "                          \"wt_full_[W0-9]+|\"\\\n",
    "                          \"wt_new_[W0-9]+|\"\\\n",
    "                          \"CampaignDay(W[0-9]+)?|\"\\\n",
    "                          \"miilabelcertainty(W[0-9]+)?|\"\\\n",
    "                          \"Dailyweight(W[0-9]+)?|\"\\\n",
    "                          \"new_full_weight|\"\\\n",
    "                          \"w8_wave6_and_wave7|w8_wave2_and_wave6|w8_wave2_and_wave6_and_wave7|w8_wave9_to_wave13|\"\\\n",
    "                          \"wt_new_|\"\\\n",
    "                          \"wt|\"\\\n",
    "                          \"waves_taken\" , col) is not None: \n",
    "\n",
    "                var_type.loc[col,\"type\"] = -1\n",
    "\n",
    "            # waveX - wave int wave 0/1 flag\n",
    "            # wave 1-11: wt_full_W6, wt_core_W6, wt_full_W1W2W3W4W5W6W7W8W9), \n",
    "            # waves 10: wt_new_W10, wt_full_W1_W13\n",
    "            # CampaignDayWX\n",
    "            # miilabelcertaintyWX\n",
    "\n",
    "            else:\n",
    "                not_found = True\n",
    "                type_range = set(variable_categories[\"type\"].values)\n",
    "                for typ in type_range:\n",
    "                    pruned_variable_name = prune2( prune(col) )\n",
    "                    if pruned_variable_name in var_cat_dict_pruned_2[typ]:\n",
    "                        var_type.loc[col,\"type\"] = typ\n",
    "                        var_type.loc[col,\"pruned\"] = pruned_variable_name\n",
    "                        not_found = False\n",
    "\n",
    "            if not_found == True:\n",
    "                var_type.loc[col,\"type\"] = -99\n",
    "                pruned_variable_name = prune2( prune(col) )\n",
    "                var_type.loc[col,\"pruned\"] = pruned_variable_name\n",
    "                missing_col_names.append(col)\n",
    "    except Exception as e:\n",
    "        print(col, e)            \n",
    "\n",
    "    var_type[\"type\"] = var_type[\"type\"].astype(\"int8\")\n",
    "\n",
    "    # reset order of var_type rows to be same as BES_Panel\n",
    "    var_type = var_type.loc[BES_Panel.columns]\n",
    "\n",
    "    ####################################################\n",
    "\n",
    "    missing_col_names_cat_only = []\n",
    "\n",
    "    for col in missing_col_names:\n",
    "        if BES_Panel[col].dtypes.name == 'category':\n",
    "            missing_col_names_cat_only.append(col)\n",
    "\n",
    "    ####################################################\n",
    "\n",
    "    if missing_col_names:\n",
    "        updated_variable_categories = variable_categories.copy()\n",
    "        # question\tfrequency\tquestion_length\tquestion_options\tcolumn_name\ttype\n",
    "\n",
    "        for i in missing_col_names_cat_only:\n",
    "            str_list = [ str(cat) for cat in BES_Panel[i].cat.categories ]\n",
    "            joined_list = \"|\".join(str_list)\n",
    "            match  = (joined_list == updated_variable_categories[\"question\"])\n",
    "\n",
    "            if match.any(): # answer set already in records\n",
    "                index = updated_variable_categories[match].index\n",
    "                if len(index)>1: # answer set (\"question\") index should be unique!\n",
    "                    raise ValueError('answer set (\"question\") index should be unique!')\n",
    "\n",
    "                # add column name and increase frequency\n",
    "                updated_variable_categories.loc[index,\"frequency\"] = updated_variable_categories.loc[index,\"frequency\"]+1\n",
    "                current_list_col_names = updated_variable_categories.loc[index,\"column_name\"].values[0].split(\"|\")\n",
    "                current_list_col_names.append(i)\n",
    "                updated_variable_categories.loc[index,\"column_name\"] = \"|\".join( current_list_col_names )\n",
    "\n",
    "            else: # answer set not already in records - add new line to dataframe\n",
    "                df = pd.DataFrame([],  columns = updated_variable_categories.columns )\n",
    "\n",
    "                # no need to add index\n",
    "                # updated_variable_categories.shape[0], \n",
    "                df.loc[0] = [joined_list,\n",
    "                             1,\n",
    "                             len(joined_list),\n",
    "                             len(str_list),\n",
    "                             i,-99]\n",
    "                \n",
    "#                 df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "                updated_variable_categories = pd.concat( [updated_variable_categories,df], ignore_index = True  )\n",
    "#                 updated_variable_categories = updated_variable_categories.append(df, ignore_index=True)\n",
    "\n",
    "        variable_categories = updated_variable_categories\n",
    "        updated_variable_categories.to_csv(BES_small_data_files + \"question_categories_correct_updatesneeded!.csv\",\n",
    "                                           encoding = encoding )\n",
    "\n",
    "\n",
    "        display([x for x in zip(missing_col_names, BES_Panel[missing_col_names].dtypes)])\n",
    "\n",
    "        manual_fixing_advice_string = \"Stop - new variables detected\\n\"\\\n",
    "                                      \"Go look at question_categories_correct_updatesneeded!.csv\\n\"\\\n",
    "                                      \"fill in types, save as question_categories_correct.csv and rerun this code\"\n",
    "\n",
    "\n",
    "        raise Exception(manual_fixing_advice_string)\n",
    "    ####################################################\n",
    "\n",
    "    # [-5, -4, -3, -2, -1, 4, 7, 8, 9] -> meta list\n",
    "    # [0, 1, 2, 3, 5, 6] ->     \n",
    "    content_list = [0, 1, 2, 3, 5, 6]\n",
    "    meta_list = [-5, -4, -3, -2, -1, 7, 8, 9] # -99, 4 excluded because could be categorical\n",
    "    # 'numeric' columns (ones that can be transformed into numbers)\n",
    "    num_cols     = BES_Panel.columns[ (var_type[\"type\"].apply( lambda x: x in [0,1,2,3,5,6] )).values ]\n",
    "    # can't be transformed into numbers / are numbers but are meta-data rather than raw content (e.g. weights)\n",
    "    non_num_cols = BES_Panel.columns[ (var_type[\"type\"].apply( lambda x: x in [-99,-5,-4,-3,-1 ]  )).values ]\n",
    "\n",
    "    BES_numeric  = BES_Panel[num_cols].copy()\n",
    "    for col in BES_numeric:\n",
    "\n",
    "        if col not in var_type[\"type\"].index:\n",
    "            raise Exception( \"variable not registered - and somehow slipped past!\" )\n",
    "\n",
    "        if var_type.loc[ col, \"type\" ] in [0,7]:\n",
    "            continue\n",
    "\n",
    "        # force all category elements into strings\n",
    "        # ARE THEY EVER NOT?\n",
    "        BES_numeric[col].cat.rename_categories( BES_numeric[col].cat.categories.map(str), inplace=True )\n",
    "\n",
    "        join_list = \"|\".join( BES_numeric[col].cat.categories ) # create category_list_string \"strongly agree|agree|neither|...\"\n",
    "        var_type.loc[ col, \"original_cat_list\" ] = join_list    \n",
    "\n",
    "        # typos - things with weird characters\n",
    "        fixed_cat_string = fix_a_hat_chars( join_list )\n",
    "        if fixed_cat_string is not None:\n",
    "            var_type.loc[ col, \"typos\" ]   = join_list      \n",
    "            BES_numeric[col].cat.rename_categories( fixed_cat_string , inplace=True )\n",
    "            join_list = \"|\".join( BES_numeric[col].cat.categories )        \n",
    "\n",
    "        # rename categories\n",
    "        if join_list in rename_cat_dict.keys():\n",
    "            var_type.loc[ col, \"renamed_cat_list\" ]   = join_list        \n",
    "            BES_numeric[col].cat.rename_categories(  rename_cat_dict[join_list], inplace=True )\n",
    "            join_list = \"|\".join( BES_numeric[col].cat.categories )        \n",
    "\n",
    "        # reorder categories\n",
    "        if join_list in change_cat_dict.keys():\n",
    "            var_type.loc[ col, \"reordered_cat_list\" ] = join_list        \n",
    "            BES_numeric[col].cat.reorder_categories( change_cat_dict[join_list], inplace=True )\n",
    "            join_list = \"|\".join( BES_numeric[col].cat.categories )        \n",
    "\n",
    "        # remove \"Don't Know\"s that are in weird numerical form (eg. [ \"9999.0\", \"997.0\", \"222.0\", \"99.0\", \"0.0\" ])\n",
    "        # de_weasel numbers\n",
    "        numerical_dont_knows = de_weasel_nums( BES_numeric[col].cat.categories )\n",
    "        if len(numerical_dont_knows) != 0:\n",
    "            BES_numeric[col].cat.remove_categories( numerical_dont_knows , inplace=True )\n",
    "            var_type.loc[ col, \"numerical_dont_knows\" ] = \"|\".join( numerical_dont_knows )\n",
    "\n",
    "        # set all digits to floating point format, one decimal place\n",
    "        BES_numeric[col].cat.rename_categories( de_num( BES_numeric[col].cat.categories ), inplace=True )\n",
    "\n",
    "        # de_weasel\n",
    "        weasel_words = BES_numeric[col].cat.categories.intersection(Weasel_set)\n",
    "        if len(weasel_words) != 0:    \n",
    "            BES_numeric[col].cat.remove_categories( weasel_words, inplace=True )\n",
    "            var_type.loc[ col, \"weasel_words\" ] = \"|\".join( weasel_words )\n",
    "\n",
    "        # Laziness - I want an extra column with the destination category sets\n",
    "        # (should be a smaller set than original category sets)\n",
    "        var_type.loc[ col, \"final_cat_list\" ] = \"|\".join( BES_numeric[col].cat.categories )        \n",
    "    ####################################################\n",
    "\n",
    "    # save category data\n",
    "    cat_dictionary = {}\n",
    "    for col in BES_numeric.columns:\n",
    "        if var_type[\"type\"][col] in [1, 2, 3, 5]: # not just cat, but one not already numerical!\n",
    "            cat_dictionary[col] = BES_numeric[col].cat.categories\n",
    "\n",
    "\n",
    "    # turn categories into numbers\n",
    "    for col in BES_numeric:\n",
    "\n",
    "        if var_type[\"type\"][col] in [1,2,3,5]: # category type variables (other than indicators)\n",
    "            BES_numeric[col] = BES_numeric[col].cat.codes\n",
    "\n",
    "        if var_type[\"type\"][col] in [0,1,2,3,5,6,7]:\n",
    "            BES_numeric[col] = BES_numeric[col].astype('float64')\n",
    "\n",
    "    BES_numeric.replace(-1,np.nan, inplace=True) # replace -1 cat code for NaN with actual NaN - downside, requires dtype float\n",
    "    ####################################################\n",
    "\n",
    "    fname = data_subfolder + \"cat_dictionary.pkl\"\n",
    "    with open(fname, \"wb\") as f:\n",
    "        pickle.dump( cat_dictionary, f )\n",
    "\n",
    "    BES_non_numeric = BES_Panel[non_num_cols].copy()\n",
    "\n",
    "    BES_non_numeric.to_pickle( data_subfolder + \"BESnon_numeric.zip\", compression='zip' )\n",
    "\n",
    "    BES_numeric.to_pickle( data_subfolder + \"BESnumeric.zip\",  compression='zip' )\n",
    "\n",
    "    var_type.to_csv( data_subfolder + \"var_type.csv\", encoding = encoding )\n",
    "    # don't think the performance warning will be relevant on such a small dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# types\n",
    "# -99 - Uncategorised!\n",
    "# -5 - id\n",
    "# -4 - text\n",
    "# -3 - datetimes\n",
    "# -2 - ignore_list\n",
    "# -1 - weights/wave indicators/campaign day indicators/miilabeluncertainty\n",
    "# 0 - personality measures (in steps of .5?), personality_agreeableness ...etc, riskScale\n",
    "# 1 - linear category, just use  (some made linear by dropping \"Weasel_answers\")\n",
    "# 2 - categories need to be modified - order changed\n",
    "# 3 - set of non-ordered options\n",
    "# 4 - indirect variables - did someone fill something in in the free text box or not?\n",
    "# 5 - categories need to modified - things removed\n",
    "    # not so clear when this one applies - is it supposed to be whenever weasel words are removed?\n",
    "    # or when variables are *changed*\n",
    "# 6 - categories are integers - should maybe be transformed directly into numbers (mostly \"how much money do people need minimum/well off\"?)\n",
    "# 7 - soc2010(W3-6_comb,W5_only), v1(W5_comb), RandomIDW1(W3-6_comb), mapNames(W3_only), mapNamesW3 (W3-10_comb,W13_comb)        \n",
    "# 8 - pano, electoratepcon, <party>sh10pcon, turnout10pcon, winnersh10pcon, runnerupsh10pcon, marginsh10pcon\n",
    "#     all relate to parliamentary constituency (pano applies to different waves - rest are about 2010 general election)\n",
    "# 9 - 'cciW1W2W3W4W5','ccinoITW1W2W3W4W5','justITW1W2W3W4W5','cciW6W7W8W9','ccinoITW6W7W8W9','justITW6W7W8W9'\n",
    "#     floats - otherwise, no idea what these variables are!\n",
    "#     they are 0/1 - look like wave related indicator variables\n",
    "\n",
    "\n",
    "# [-5, -4, -3, -2, -1, 4, 7, 8, 9] -> meta list\n",
    "# [0, 1, 2, 3, 5, 6] -> \n",
    "\n",
    "# ordinal: 0, 1, 2, 5, 6\n",
    "# non-ordinal: 3, 7\n",
    "\n",
    "# load question_categories_correct.csv\n",
    "# sanity check by type!\n",
    "# turn into list of variables by type\n",
    "# 1, 5 handled the same way -> cat.codes\n",
    "# 6 -> int()\n",
    "# 4 ignored\n",
    "# 3 ignored for now (-> vectorized?)\n",
    "# 2 direct modification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BES_Panel = hard_coded_fixes( dataset_name )\n",
    "# BES_Panel[col].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index\n",
      "id\n",
      "starttime\n",
      "endtime\n",
      "wt\n",
      "generalElectionVote\n",
      "generalElectionVoteNonVoter\n",
      "partyId\n",
      "partyIdSqueeze\n",
      "partyIdStrength\n",
      "mii\n",
      "bestOnMII\n",
      "anyUniW26W27\n",
      "sectorW26W27\n",
      "genElecTurnoutRetro\n",
      "reasonForVote\n",
      "partyPreferred\n",
      "regretsIHaveAFew\n",
      "votingWish\n",
      "voteMethoda\n",
      "askedForID\n",
      "attemptTurnout\n",
      "reasonForTurnaway_1\n",
      "reasonForTurnaway_2\n",
      "reasonForTurnaway_3\n",
      "reasonForTurnaway_4\n",
      "reasonForTurnaway_5\n",
      "reasonForTurnaway_111\n",
      "participation_1\n",
      "participation_2\n",
      "participation_3\n",
      "participation_4\n",
      "participation_5\n",
      "polAttention\n",
      "pidWeThey\n",
      "pidInterestedOthers\n",
      "pidCriticiseParty\n",
      "pidCommonParty\n",
      "pidConnected\n",
      "pidPraiseGood\n",
      "pidWeTheyb\n",
      "pidInterestedOthersb\n",
      "pidCriticisePartyb\n",
      "pidCommonPartyb\n",
      "pidConnectedb\n",
      "pidPraiseGoodb\n",
      "likeSunak\n",
      "likeStarmer\n",
      "likeDavey\n",
      "likeSwinney\n",
      "likeIorwerth\n",
      "likeFarage\n",
      "likeRamsay\n",
      "likeDenyer\n",
      "likeHarvie\n",
      "likeSlater\n",
      "likeCon\n",
      "likeLab\n",
      "likeLD\n",
      "likeSNP\n",
      "likePC\n",
      "likeBrexitParty\n",
      "likeGrn\n",
      "prPreference\n",
      "econPersonalProsp\n",
      "econGenProsp\n",
      "econPersonalRetro\n",
      "econGenRetro\n",
      "EUIntegrationSelf\n",
      "EUIntegrationCon\n",
      "EUIntegrationLab\n",
      "EUIntegrationLD\n",
      "EUIntegrationSNP\n",
      "EUIntegrationPC\n",
      "EUIntegrationGreen\n",
      "EUIntegrationBrexit\n",
      "leftRight\n",
      "satDemUK\n",
      "satDemScot\n",
      "satDemWales\n",
      "satDemEng\n",
      "redistSelf\n",
      "redistCon\n",
      "redistLab\n",
      "redistLD\n",
      "redistSNP\n",
      "redistPC\n",
      "redistBrexit\n",
      "redistGreen\n",
      "immigSelf\n",
      "immigCon\n",
      "immigLab\n",
      "immigLD\n",
      "immigSNP\n",
      "immigPC\n",
      "immigBrexit\n",
      "immigGreen\n",
      "expectGoodConductGeneral\n",
      "referendumSettled\n",
      "scotReferendumIntention\n",
      "scotElectionVoteConst\n",
      "scotElectionVoteList\n",
      "sovereignty1\n",
      "sovereignty2\n",
      "welshElectionVoteNew\n",
      "partyContact1\n",
      "partyContactCon\n",
      "partyContactLab\n",
      "partyContactLD\n",
      "partyContactSNP\n",
      "partyContactPC\n",
      "partyContactBrexit\n",
      "partyContactGrn\n",
      "partyContact2new_13\n",
      "partyContactOtherParty\n",
      "partyContactNone\n",
      "partyContactCon_1\n",
      "partyContactCon_2\n",
      "partyContactCon_3\n",
      "partyContactCon_4\n",
      "partyContactCon_5\n",
      "partyContactCon_6\n",
      "partyContactCon_7\n",
      "partyContactLab_1\n",
      "partyContactLab_2\n",
      "partyContactLab_3\n",
      "partyContactLab_4\n",
      "partyContactLab_5\n",
      "partyContactLab_6\n",
      "partyContactLab_7\n",
      "partyContactLD_1\n",
      "partyContactLD_2\n",
      "partyContactLD_3\n",
      "partyContactLD_4\n",
      "partyContactLD_5\n",
      "partyContactLD_6\n",
      "partyContactLD_7\n",
      "partyContactSNP_1\n",
      "partyContactSNP_2\n",
      "partyContactSNP_3\n",
      "partyContactSNP_4\n",
      "partyContactSNP_5\n",
      "partyContactSNP_6\n",
      "partyContactSNP_7\n",
      "partyContactPC_1\n",
      "partyContactPC_2\n",
      "partyContactPC_3\n",
      "partyContactPC_4\n",
      "partyContactPC_5\n",
      "partyContactPC_6\n",
      "partyContactPC_7\n",
      "partyContactGreen_1\n",
      "partyContactGreen_2\n",
      "partyContactGreen_3\n",
      "partyContactGreen_4\n",
      "partyContactGreen_5\n",
      "partyContactGreen_6\n",
      "partyContactGreen_7\n",
      "partyContactBrexit_1\n",
      "partyContactBrexit_2\n",
      "partyContactBrexit_3\n",
      "partyContactBrexit_4\n",
      "partyContactBrexit_5\n",
      "partyContactBrexit_6\n",
      "partyContactBrexit_7\n",
      "partyContactInd_1\n",
      "partyContactInd_2\n",
      "partyContactInd_3\n",
      "partyContactInd_4\n",
      "partyContactInd_5\n",
      "partyContactInd_6\n",
      "partyContactInd_7\n",
      "partyContactOther_1\n",
      "partyContactOther_2\n",
      "partyContactOther_3\n",
      "partyContactOther_4\n",
      "partyContactOther_5\n",
      "partyContactOther_6\n",
      "partyContactOther_7\n",
      "partyContactConFreq1\n",
      "partyContactConFreq2\n",
      "partyContactConFreq3\n",
      "partyContactConFreq4\n",
      "partyContactConFreq5\n",
      "partyContactConFreq6\n",
      "partyContactConFreq7\n",
      "partyContactLabFreq1\n",
      "partyContactLabFreq2\n",
      "partyContactLabFreq3\n",
      "partyContactLabFreq4\n",
      "partyContactLabFreq5\n",
      "partyContactLabFreq6\n",
      "partyContactLabFreq7\n",
      "partyContactLDFreq1\n",
      "partyContactLDFreq2\n",
      "partyContactLDFreq3\n",
      "partyContactLDFreq4\n",
      "partyContactLDFreq5\n",
      "partyContactLDFreq6\n",
      "partyContactLDFreq7\n",
      "partyContactSNPFreq1\n",
      "partyContactSNPFreq2\n",
      "partyContactSNPFreq3\n",
      "partyContactSNPFreq4\n",
      "partyContactSNPFreq5\n",
      "partyContactSNPFreq6\n",
      "partyContactSNPFreq7\n",
      "partyContactPCFreq1\n",
      "partyContactPCFreq2\n",
      "partyContactPCFreq3\n",
      "partyContactPCFreq4\n",
      "partyContactPCFreq5\n",
      "partyContactPCFreq6\n",
      "partyContactPCFreq7\n",
      "partyContactGreenFreq1\n",
      "partyContactGreenFreq2\n",
      "partyContactGreenFreq3\n",
      "partyContactGreenFreq4\n",
      "partyContactGreenFreq5\n",
      "partyContactGreenFreq6\n",
      "partyContactGreenFreq7\n",
      "partyContactBrexitFreq1\n",
      "partyContactBrexitFreq2\n",
      "partyContactBrexitFreq3\n",
      "partyContactBrexitFreq4\n",
      "partyContactBrexitFreq5\n",
      "partyContactBrexitFreq6\n",
      "partyContactBrexitFreq7\n",
      "partyContactIndFreq1\n",
      "partyContactIndFreq2\n",
      "partyContactIndFreq3\n",
      "partyContactIndFreq4\n",
      "partyContactIndFreq5\n",
      "partyContactIndFreq6\n",
      "partyContactIndFreq7\n",
      "partyContactOtherFreq1\n",
      "partyContactOtherFreq2\n",
      "partyContactOtherFreq3\n",
      "partyContactOtherFreq4\n",
      "partyContactOtherFreq5\n",
      "partyContactOtherFreq6\n",
      "partyContactOtherFreq7\n",
      "infoSourceTV\n",
      "infoSourcePaper\n",
      "infoSourceRadio\n",
      "infoSourceInternet\n",
      "infoSourcePeople\n",
      "registered\n",
      "changeView\n",
      "voterIDSupport\n",
      "trustMPs\n",
      "britishness\n",
      "scottishness\n",
      "welshness\n",
      "englishness\n",
      "europeanness\n",
      "conLookAfterBA\n",
      "conLookAfterMC\n",
      "conLookAfterWC\n",
      "conLookAfterYoung\n",
      "conLookAfterRetired\n",
      "labLookAfterBA\n",
      "labLookAfterMC\n",
      "labLookAfterWC\n",
      "labLookAfterYoung\n",
      "labLookAfterRetired\n",
      "brexitLookAfterBA\n",
      "brexitLookAfterMC\n",
      "brexitLookAfterWC\n",
      "brexitLookAfterYoung\n",
      "brexitLookAfterRetired\n",
      "snpLookAfterBA\n",
      "snpLookAfterMC\n",
      "snpLookAfterWC\n",
      "snpLookAfterYoung\n",
      "snpLookAfterRetired\n",
      "pcLookAfterBA\n",
      "pcLookAfterMC\n",
      "pcLookAfterWC\n",
      "pcLookAfterYoung\n",
      "pcLookAfterRetired\n",
      "ldLookAfterBA\n",
      "ldLookAfterMC\n",
      "ldLookAfterWC\n",
      "ldLookAfterYoung\n",
      "ldLookAfterRetired\n",
      "grnLookAfterBA\n",
      "grnLookAfterMC\n",
      "grnLookAfterWC\n",
      "grnLookAfterYoung\n",
      "grnLookAfterRetired\n",
      "euRefDoOver\n",
      "euRefVoteAfter\n",
      "achieveReduceImmigCon\n",
      "achieveReduceImmigLab\n",
      "achieveReduceImmigLD\n",
      "achieveReduceImmigSNP\n",
      "achieveReduceImmigPC\n",
      "achieveReduceImmigGrn\n",
      "achieveReduceImmigBrexit\n",
      "achieveReduceImmigNone\n",
      "achieveReduceNHSCon\n",
      "achieveReduceNHSLab\n",
      "achieveReduceNHSLD\n",
      "achieveReduceNHSSNP\n",
      "achieveReduceNHSPC\n",
      "achieveReduceNHSGrn\n",
      "achieveReduceNHSBrexit\n",
      "achieveReduceNHSNone\n",
      "achieveReduceInflaCon\n",
      "achieveReduceInflaLab\n",
      "achieveReduceInflaLD\n",
      "achieveReduceInflaSNP\n",
      "achieveReduceInflaPC\n",
      "achieveReduceInflaGrn\n",
      "achieveReduceInflaBrexit\n",
      "achieveReduceInflaNone\n",
      "achieveReduceCarbCon\n",
      "achieveReduceCarbLab\n",
      "achieveReduceCarbLD\n",
      "achieveReduceCarbSNP\n",
      "achieveReduceCarbPC\n",
      "achieveReduceCarbGrn\n",
      "achieveReduceCarbBrexit\n",
      "achieveReduceCarbNone\n",
      "achieveReducePovCon\n",
      "achieveReducePovLab\n",
      "achieveReducePovLD\n",
      "achieveReducePovSNP\n",
      "achieveReducePovPC\n",
      "achieveReducePovGrn\n",
      "achieveReducePovBrexit\n",
      "achieveReducePovNone\n",
      "achieveIncGrowthCon\n",
      "achieveIncGrowthLab\n",
      "achieveIncGrowthLD\n",
      "achieveIncGrowthSNP\n",
      "achieveIncGrowthPC\n",
      "achieveIncGrowthGrn\n",
      "achieveIncGrowthBrexit\n",
      "achieveIncGrowthNone\n",
      "con_Ideas\n",
      "lab_Ideas\n",
      "ld_Ideas\n",
      "snp_Ideas\n",
      "pc_Ideas\n",
      "brexit_Ideas\n",
      "grn_Ideas\n",
      "disapprovalVote\n",
      "conTrust\n",
      "labTrust\n",
      "ldTrust\n",
      "snpTrust\n",
      "pcTrust\n",
      "brexitTrust\n",
      "grnTrust\n",
      "conCompetent\n",
      "labCompetent\n",
      "ldCompetent\n",
      "snpCompetent\n",
      "pcCompetent\n",
      "brexitCompetent\n",
      "grnCompetent\n",
      "occCheckParent\n",
      "voted_ge_2024\n",
      "mii_cat_llm\n",
      "disabilityCensusW26\n",
      "disabilityCensusImpactW26\n",
      "preschoolKidsInHouseW26\n",
      "schoolKidsInHouseW26\n",
      "sickElderlyInHouseW26\n",
      "noDependentsInHouseW26\n",
      "disabilityChildW26\n",
      "careAdult_sickW26\n",
      "careAdult_elderlyW26\n",
      "careAdult_disabledW26\n",
      "subjClassW27\n",
      "subjClassSqueezeW27\n",
      "lr1W27\n",
      "lr2W27\n",
      "lr3W27\n",
      "lr4W27\n",
      "lr5W27\n",
      "al1W27\n",
      "al2W27\n",
      "al3W27\n",
      "al4W27\n",
      "al5W27\n",
      "lr_scaleW27\n",
      "al_scaleW27\n",
      "currentUnionMemberW19_W26\n",
      "everUnionMemberW19_W26\n",
      "small_mii_cat_llm\n",
      "LRAL_mii_cat_llm\n",
      "parentOccStatus\n",
      "parentOccSupervise\n",
      "parentOccOrgSize\n",
      "parentOccEmployees\n",
      "parentNumEmployees\n",
      "headHouseholdPast\n",
      "parentEducation\n",
      "ns_sec_parent\n",
      "ns_sec_analytic_parent\n",
      "edlevelParent\n",
      "workingStatusW26W27\n",
      "prevJobW26W27\n",
      "selfOccStatusW26W27\n",
      "selfOccSuperviseW26W27\n",
      "selfOccOrgSizeW26W27\n",
      "selfOccEmployeesW26W27\n",
      "selfNumEmployeesW26W27\n",
      "selfOccStatusLastW26W27\n",
      "selfOccSuperviseLastW26W27\n",
      "selfOccOrgSizeLastW26W27\n",
      "selfOccEmployeesLastW26W27\n",
      "selfNumEmployeesLastW26W27\n",
      "occCheckW26W27\n",
      "ns_sec_analyticW26W27\n",
      "ns_secW26W27\n",
      "cci\n",
      "ccinoIT\n",
      "justIT\n",
      "jobzone\n",
      "pano\n",
      "country\n",
      "gender\n",
      "age\n",
      "ageGroup\n",
      "gor\n",
      "new_pcon\n",
      "new_pcon_code\n",
      "pcon\n",
      "pcon_code\n",
      "oslaua_code\n",
      "p_education\n",
      "p_work_stat\n",
      "p_hh_children\n",
      "p_housing\n",
      "p_gross_household\n",
      "p_gross_personal\n",
      "p_hh_size\n",
      "p_socgrade\n",
      "p_education_age\n",
      "p_sexuality\n",
      "p_paper_read\n",
      "p_marital\n",
      "p_religion\n",
      "p_job_sector\n",
      "p_disability\n",
      "p_parent\n",
      "p_country_birth\n",
      "p_ethnicity\n",
      "p_past_vote_2010\n",
      "p_past_vote_2005\n",
      "p_past_vote_2015\n",
      "p_past_vote_2017\n",
      "p_past_vote_2019\n",
      "p_turnout_2015\n",
      "p_turnout_2017\n",
      "p_turnout_2019\n",
      "p_scot_const_vote_2011\n",
      "p_scot_list_vote_2011\n",
      "p_scot_const_vote_2016\n",
      "p_scot_list_vote_2016\n",
      "p_welsh_const_vote_2016\n",
      "p_welsh_list_vote_2016\n",
      "p_eurefvote\n",
      "p_vote_scot_ref\n",
      "p_turnout_2010\n",
      "p_turnout_2005\n",
      "p_turnout_scot_ref\n",
      "p_edlevel\n",
      "p_edlevelUni\n",
      "p_eurefturnout\n"
     ]
    }
   ],
   "source": [
    "dataset_name = 'W29_only'\n",
    "\n",
    "\n",
    "BES_file_manifest = pd.read_csv( BES_small_data_files + \"BES_file_manifest.csv\",encoding = \"ISO-8859-1\" )\n",
    "manifest = BES_file_manifest[ BES_file_manifest[\"Name\"] == dataset_name ]\n",
    "\n",
    "data_subfolder = BES_data_folder + dataset_name + os.sep\n",
    "\n",
    "filename = manifest[\"Stata_Filename\"].values[0]\n",
    "\n",
    "global BES_Panel\n",
    "if \".zip\" in filename:\n",
    "    BES_Panel = pd.read_pickle( data_subfolder + filename, compression='zip')\n",
    "else:\n",
    "    BES_Panel = pd.read_stata( data_subfolder + filename)\n",
    "####################################################\n",
    "\n",
    "# use this dataframe to store *everything* we're doing to transform/ignore variables!\n",
    "global var_type\n",
    "var_type = pd.DataFrame(columns = [\"dataset_name\",\"dtype\",\"cat_all_strings\",\"type\",\"pruned\",\"original_cat_list\",\n",
    "                                   \"renamed_cat_list\",\"reordered_cat_list\",\"final_cat_list\",\n",
    "                                   \"dataset_specific_hardcoded_fix\",\n",
    "                                   \"numerical_dont_knows\",\n",
    "                                   \"weasel_words\",\"typos\" ] )\n",
    "####################################################\n",
    "\n",
    "BES_Panel = hard_coded_fixes( dataset_name ) # side effects on BES_Panel and var_type\n",
    "number_and_string_sequences() # side effects on BES_Panel\n",
    "\n",
    "variable_categories = pd.read_csv( BES_small_data_files + \"question_categories_correct.csv\",\n",
    "                                   encoding = encoding,index_col=False )\n",
    "variable_categories.drop('Unnamed: 0', axis=1,inplace=True)\n",
    "\n",
    "( var_cat_dict_pruned , var_cat_dict_pruned_2 ) = create_var_list( variable_categories )\n",
    "####################################################\n",
    "\n",
    "missing_col_names = []\n",
    "try:\n",
    "    for col in BES_Panel.columns:\n",
    "        print(col)\n",
    "        dt =  BES_Panel[col].dtype.name # data type\n",
    "#         not_found = False\n",
    "\n",
    "        var_type.loc[col,\"dataset_name\"] = dataset_name\n",
    "        # dtype is either nan because not set -> set\n",
    "        if not isinstance(var_type.loc[col,\"dtype\"],str):\n",
    "            var_type.loc[ col , \"dtype\"] = dt    \n",
    "        # if dtype == category *and* cat_all_strings not already set, set\n",
    "        if (var_type.loc[ col , \"dtype\" ] == 'category') and careful_isnan( var_type.loc[ col , \"cat_all_strings\" ] ):\n",
    "            var_type.loc[ col , \"cat_all_strings\" ] = np.all([isinstance(x,str) for x in BES_Panel[ col ].cat.categories])\n",
    "\n",
    "        not_found = False      \n",
    "\n",
    "        if (col in ignore_list) or (var_type.loc[col,\"type\"] == -2): # exclude values from ignore_list *and manually coded errors*\n",
    "            var_type.loc[col,\"type\"] = -2\n",
    "            if var_type.loc[ col , \"cat_all_strings\" ]==True:\n",
    "                var_type.loc[ col, \"original_cat_list\" ] = \"|\".join( BES_Panel[col].cat.categories )\n",
    "            elif ('float' in dt) or ('int' in dt):\n",
    "                var_type.loc[ col, \"original_cat_list\" ] = list(BES_Panel[col].unique())\n",
    "\n",
    "        elif (col in [\"id\",\"index\"] ): # id\n",
    "            var_type.loc[col,\"type\"] = -5\n",
    "\n",
    "        elif (dt == 'object'): # (probably) text\n",
    "            var_type.loc[col,\"type\"] = -4\n",
    "\n",
    "        elif (\"datetime\" in dt): # datetime\n",
    "            var_type.loc[col,\"type\"] = -3\n",
    "\n",
    "    # 0 - personality measures (in steps of .5?), personality_agreeableness ...etc, riskScaleW8        \n",
    "        elif (col in [\"personality_agreeableness\",\n",
    "                     \"personality_conscientiousness\",\n",
    "                     \"personality_extraversion\",\n",
    "                     \"personality_neuroticism\",\n",
    "                     \"personality_openness\"]) or (re.match(\"(cogempathy|affempathy|zeroSum)IRT\",col) is not None) or (re.match(\"riskScale(W[0-9]+)?\",col) is not None) :\n",
    "            \n",
    "            var_type.loc[col,\"type\"] = 0\n",
    "\n",
    "    # 7 - soc2010(W3-6_comb,W5_only), v1(W5_comb), RandomIDW1(W3-6_comb), mapNames(W3_only), mapNamesW3 (W3-10_comb,W13_comb)        \n",
    "        elif re.match(\"soc2010|v1|RandomIDW1|mapNames(W[0-9]+)?\" ,col) is not None:\n",
    "            var_type.loc[col,\"type\"] = 7\n",
    "\n",
    "    # 8 - pano, electoratepcon, <party>sh10pcon, turnout10pcon, winnersh10pcon, runnerupsh10pcon, marginsh10pcon\n",
    "    # don't include 'runnerup10pcon', 'winner10pcon'- these are categorical!\n",
    "    # all relate to parliamentary constituency (pano applies to different waves - rest are about 2010 general election)\n",
    "        elif re.match( \"pano(W[0-9]+)?|electoratepcon|[a-zA-Z]+sh10pcon|turnout10pcon\" , col ) is not None:\n",
    "            var_type.loc[col,\"type\"] = 8\n",
    "\n",
    "        elif col in ['cciW1W2W3W4W5','ccinoITW1W2W3W4W5','justITW1W2W3W4W5','cciW6W7W8W9','ccinoITW6W7W8W9','justITW6W7W8W9']:\n",
    "            var_type.loc[col,\"type\"] = 9\n",
    "\n",
    "        # wave flags/weights (int and float)\n",
    "        elif re.match(\"wave[0-9]+|\"\\\n",
    "                      \"w[0-9]+core|\"\\\n",
    "                      \"w[0-9]+full|\"\\\n",
    "                      \"wt_daily_W[0-9]+|\"\\\n",
    "                      \"wt_core_W[0-9]+|\"\\\n",
    "                      \"wt_full_[W0-9]+|\"\\\n",
    "                      \"wt_new_[W0-9]+|\"\\\n",
    "                      \"CampaignDay(W[0-9]+)?|\"\\\n",
    "                      \"miilabelcertainty(W[0-9]+)?|\"\\\n",
    "                      \"Dailyweight(W[0-9]+)?|\"\\\n",
    "                      \"new_full_weight|\"\\\n",
    "                      \"w8_wave6_and_wave7|w8_wave2_and_wave6|w8_wave2_and_wave6_and_wave7|w8_wave9_to_wave13|\"\\\n",
    "                      \"wt_new_|\"\\\n",
    "                      \"wt|\"\\\n",
    "                      \"waves_taken|wave|weight\" , col) is not None: \n",
    "\n",
    "            var_type.loc[col,\"type\"] = -1\n",
    "\n",
    "        # waveX - wave int wave 0/1 flag\n",
    "        # wave 1-11: wt_full_W6, wt_core_W6, wt_full_W1W2W3W4W5W6W7W8W9), \n",
    "        # waves 10: wt_new_W10, wt_full_W1_W13\n",
    "        # CampaignDayWX\n",
    "        # miilabelcertaintyWX\n",
    "\n",
    "        else:\n",
    "            not_found = True\n",
    "            type_range = set(variable_categories[\"type\"].values)\n",
    "            for typ in type_range:\n",
    "                pruned_variable_name = prune2( prune(col) )\n",
    "                if pruned_variable_name in var_cat_dict_pruned_2[typ]:\n",
    "                    var_type.loc[col,\"type\"] = typ\n",
    "                    var_type.loc[col,\"pruned\"] = pruned_variable_name\n",
    "                    not_found = False\n",
    "\n",
    "        if not_found == True:\n",
    "            var_type.loc[col,\"type\"] = -99\n",
    "            pruned_variable_name = prune2( prune(col) )\n",
    "            var_type.loc[col,\"pruned\"] = pruned_variable_name\n",
    "            missing_col_names.append(col)\n",
    "except Exception as e:\n",
    "    print(col, e)            \n",
    "\n",
    "var_type[\"type\"] = var_type[\"type\"].astype(\"int8\")\n",
    "\n",
    "# reset order of var_type rows to be same as BES_Panel\n",
    "var_type = var_type.loc[BES_Panel.columns]\n",
    "\n",
    "####################################################\n",
    "\n",
    "missing_col_names_cat_only = []\n",
    "\n",
    "for col in missing_col_names:\n",
    "    if BES_Panel[col].dtypes.name == 'category':\n",
    "        missing_col_names_cat_only.append(col)\n",
    "\n",
    "####################################################\n",
    "\n",
    "if missing_col_names:\n",
    "    updated_variable_categories = variable_categories.copy()\n",
    "    # question\tfrequency\tquestion_length\tquestion_options\tcolumn_name\ttype\n",
    "\n",
    "    for i in missing_col_names_cat_only:\n",
    "        str_list = [ str(cat) for cat in BES_Panel[i].cat.categories ]\n",
    "        joined_list = \"|\".join(str_list)\n",
    "        match  = (joined_list == updated_variable_categories[\"question\"])\n",
    "\n",
    "        if match.any(): # answer set already in records\n",
    "            index = updated_variable_categories[match].index\n",
    "            if len(index)>1: # answer set (\"question\") index should be unique!\n",
    "                raise ValueError('answer set (\"question\") index should be unique!')\n",
    "\n",
    "            # add column name and increase frequency\n",
    "            updated_variable_categories.loc[index,\"frequency\"] = updated_variable_categories.loc[index,\"frequency\"]+1\n",
    "            current_list_col_names = updated_variable_categories.loc[index,\"column_name\"].values[0].split(\"|\")\n",
    "            current_list_col_names.append(i)\n",
    "            updated_variable_categories.loc[index,\"column_name\"] = \"|\".join( current_list_col_names )\n",
    "\n",
    "        else: # answer set not already in records - add new line to dataframe\n",
    "            df = pd.DataFrame([],  columns = updated_variable_categories.columns )\n",
    "\n",
    "            # no need to add index\n",
    "            # updated_variable_categories.shape[0], \n",
    "            df.loc[0] = [joined_list,\n",
    "                         1,\n",
    "                         len(joined_list),\n",
    "                         len(str_list),\n",
    "                         i,-99]\n",
    "#             updated_variable_categories = updated_variable_categories.append(df, ignore_index=True)\n",
    "            updated_variable_categories = pd.concat( [updated_variable_categories,df], ignore_index = True  )\n",
    "\n",
    "    variable_categories = updated_variable_categories\n",
    "    updated_variable_categories.to_csv(BES_small_data_files + \"question_categories_correct_updatesneeded!.csv\",\n",
    "                                       encoding = encoding )\n",
    "\n",
    "\n",
    "    display([x for x in zip(missing_col_names, BES_Panel[missing_col_names].dtypes)])\n",
    "\n",
    "    manual_fixing_advice_string = \"Stop - new variables detected\\n\"\\\n",
    "                                  \"Go look at question_categories_correct_updatesneeded!.csv\\n\"\\\n",
    "                                  \"fill in types, save as question_categories_correct.csv and rerun this code\"\n",
    "\n",
    "\n",
    "    raise Exception(manual_fixing_advice_string)\n",
    "####################################################\n",
    "\n",
    "# [-5, -4, -3, -2, -1, 4, 7, 8, 9] -> meta list\n",
    "# [0, 1, 2, 3, 5, 6] ->     \n",
    "content_list = [0, 1, 2, 3, 5, 6]\n",
    "meta_list = [-5, -4, -3, -2, -1, 7, 8, 9] # -99, 4 excluded because could be categorical\n",
    "# 'numeric' columns (ones that can be transformed into numbers)\n",
    "num_cols     = BES_Panel.columns[ (var_type[\"type\"].apply( lambda x: x in [0,1,2,3,5,6] )).values ]\n",
    "# can't be transformed into numbers / are numbers but are meta-data rather than raw content (e.g. weights)\n",
    "non_num_cols = BES_Panel.columns[ (var_type[\"type\"].apply( lambda x: x in [-99,-5,-4,-3,-1 ]  )).values ]\n",
    "\n",
    "BES_numeric  = BES_Panel[num_cols].copy()\n",
    "for col in BES_numeric:\n",
    "\n",
    "    if col not in var_type[\"type\"].index:\n",
    "        raise Exception( \"variable not registered - and somehow slipped past!\" )\n",
    "\n",
    "    if var_type.loc[ col, \"type\" ] in [0,7]:\n",
    "        continue\n",
    "\n",
    "    # force all category elements into strings\n",
    "    # ARE THEY EVER NOT?\n",
    "    \n",
    "    BES_numeric[col] = BES_numeric[col].cat.rename_categories( BES_numeric[col].cat.categories.map(str) )\n",
    "\n",
    "    join_list = \"|\".join( BES_numeric[col].cat.categories ) # create category_list_string \"strongly agree|agree|neither|...\"\n",
    "    var_type.loc[ col, \"original_cat_list\" ] = join_list    \n",
    "\n",
    "    # typos - things with weird characters\n",
    "    fixed_cat_string = fix_a_hat_chars( join_list )\n",
    "    if fixed_cat_string is not None:\n",
    "        var_type.loc[ col, \"typos\" ]   = join_list      \n",
    "        BES_numeric[col] = BES_numeric[col].cat.rename_categories( fixed_cat_string )\n",
    "        join_list = \"|\".join( BES_numeric[col].cat.categories )        \n",
    "\n",
    "    # rename categories\n",
    "    if join_list in rename_cat_dict.keys():\n",
    "        var_type.loc[ col, \"renamed_cat_list\" ]   = join_list        \n",
    "        BES_numeric[col] = BES_numeric[col].cat.rename_categories(  rename_cat_dict[join_list] )\n",
    "        join_list = \"|\".join( BES_numeric[col].cat.categories )        \n",
    "\n",
    "    # reorder categories\n",
    "    if join_list in change_cat_dict.keys():\n",
    "        var_type.loc[ col, \"reordered_cat_list\" ] = join_list        \n",
    "        BES_numeric[col] = BES_numeric[col].cat.reorder_categories( change_cat_dict[join_list] )\n",
    "        join_list = \"|\".join( BES_numeric[col].cat.categories )        \n",
    "\n",
    "    # remove \"Don't Know\"s that are in weird numerical form (eg. [ \"9999.0\", \"997.0\", \"222.0\", \"99.0\", \"0.0\" ])\n",
    "    # de_weasel numbers\n",
    "    numerical_dont_knows = de_weasel_nums( BES_numeric[col].cat.categories )\n",
    "    if len(numerical_dont_knows) != 0:\n",
    "        BES_numeric[col] = BES_numeric[col].cat.remove_categories( numerical_dont_knows )\n",
    "        var_type.loc[ col, \"numerical_dont_knows\" ] = \"|\".join( numerical_dont_knows )\n",
    "\n",
    "    # set all digits to floating point format, one decimal place\n",
    "    BES_numeric[col] = BES_numeric[col].cat.rename_categories( de_num( BES_numeric[col].cat.categories ) )\n",
    "\n",
    "    # de_weasel\n",
    "    weasel_words = BES_numeric[col].cat.categories.intersection(Weasel_set)\n",
    "    if len(weasel_words) != 0:    \n",
    "        BES_numeric[col] = BES_numeric[col].cat.remove_categories( weasel_words )\n",
    "        var_type.loc[ col, \"weasel_words\" ] = \"|\".join( weasel_words )\n",
    "\n",
    "    # Laziness - I want an extra column with the destination category sets\n",
    "    # (should be a smaller set than original category sets)\n",
    "    var_type.loc[ col, \"final_cat_list\" ] = \"|\".join( BES_numeric[col].cat.categories )        \n",
    "####################################################\n",
    "\n",
    "# save category data\n",
    "cat_dictionary = {}\n",
    "for col in BES_numeric.columns:\n",
    "    if var_type[\"type\"][col] in [1, 2, 3, 5]: # not just cat, but one not already numerical!\n",
    "        cat_dictionary[col] = BES_numeric[col].cat.categories\n",
    "\n",
    "\n",
    "# turn categories into numbers\n",
    "for col in BES_numeric:\n",
    "\n",
    "    if var_type[\"type\"][col] in [1,2,3,5]: # category type variables (other than indicators)\n",
    "        BES_numeric[col] = BES_numeric[col].cat.codes\n",
    "\n",
    "    if var_type[\"type\"][col] in [0,1,2,3,5,6,7]:\n",
    "        BES_numeric[col] = BES_numeric[col].astype('float64')\n",
    "\n",
    "BES_numeric.replace(-1,np.nan, inplace=True) # replace -1 cat code for NaN with actual NaN - downside, requires dtype float\n",
    "####################################################\n",
    "\n",
    "fname = data_subfolder + \"cat_dictionary.pkl\"\n",
    "with open(fname, \"wb\") as f:\n",
    "    pickle.dump( cat_dictionary, f )\n",
    "\n",
    "BES_non_numeric = BES_Panel[non_num_cols].copy()\n",
    "\n",
    "BES_non_numeric.to_pickle( data_subfolder + \"BESnon_numeric.zip\", compression='zip' )\n",
    "\n",
    "BES_numeric.to_pickle( data_subfolder + \"BESnumeric.zip\",  compression='zip' )\n",
    "\n",
    "# var_type.to_csv( data_subfolder + \"var_type.csv\", encoding = encoding )\n",
    "var_type.to_csv( data_subfolder + \"var_type.csv\")\n",
    "# don't think the performance warning will be relevant on such a small dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'p_eurefturnout'"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "noDependentsInHouseW26\n",
       "1.0    19656\n",
       "0.0     5490\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BES_Panel['noDependentsInHouseW26'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         No\n",
       "1        Yes\n",
       "2         No\n",
       "3        Yes\n",
       "4        NaN\n",
       "        ... \n",
       "31093     No\n",
       "31094     No\n",
       "31095     No\n",
       "31096     No\n",
       "31097    Yes\n",
       "Name: disabilityCensusW26, Length: 31098, dtype: category\n",
       "Categories (2, object): ['No' < 'Yes']"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BES_Panel['disabilityCensusW26']#.value_counts()\n",
    "# BES_Panel['disabilityChildW26'].value_counts()\n",
    "# BES_Panel['careAdult_sickW26'].value_counts()\n",
    "# BES_Panel['careAdult_elderlyW26'].value_counts()\n",
    "# BES_Panel['careAdult_disabledW26'].value_counts()\n",
    "\n",
    "# disabilityCensus_replace = {0.0:\"No\",1.0:\"Yes\"}\n",
    "\n",
    "# BES_Panel['disabilityCensusImpactW26'].value_counts()\n",
    "\n",
    "# disabilityCensusImpact_replace = {1.0:\"Yes, a lot\",2.0:\"Yes, a little\",3.0:\"Not at all\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BES_Panel['careAdult_disabledW26'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_fixing_advice_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "BES_Panel[col].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BES_numeric[col].cat.rename_categories( BES_numeric[col].cat.categories.map(str), inplace=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_categories[variable_categories[\"column_name\"].apply(lambda x: \"turnoutUKGeneral\" in x if not pd.isna(x) else False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_range = set(variable_categories[\"type\"].values)\n",
    "# for typ in type_range:\n",
    "#     pruned_variable_name = prune2( prune(col) )\n",
    "#     if pruned_variable_name in var_cat_dict_pruned_2[typ]:\n",
    "#         var_type.loc[col,\"type\"] = typ\n",
    "#         var_type.loc[col,\"pruned\"] = pruned_variable_name\n",
    "#         not_found = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_categories = pd.read_csv( BES_small_data_files + \"question_categories_correct.csv\",\n",
    "                                   encoding = encoding,index_col=False,\n",
    "#                                   usecols=[\"question\",\"frequency\",\"question_length\",\n",
    "#                                                                                \"question_options\",\"column_name\",\"type\"]\n",
    "                                 )\n",
    "variable_categories.drop('Unnamed: 0', axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_categories.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_type.loc['age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
