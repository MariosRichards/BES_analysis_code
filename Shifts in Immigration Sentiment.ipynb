{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "import re\n",
    "\n",
    "from itertools import cycle\n",
    "from IPython.display import display\n",
    "import pickle, os\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "encoding = \"ISO-8859-1\"\n",
    "\n",
    "import Jupyter_module_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # you should clone this git to this subdirectory (in some directory - I call it BES_analysis - doesn't matter though)\n",
    "\n",
    "# if os.getcwd().split(os.sep)[-1] != 'BES_analysis_code':\n",
    "#     raise Exception(\"Stop! You're in the wrong directory - should be in 'BES_analysis_code'\")\n",
    "\n",
    "# BES_code_folder   = \"../BES_analysis_code/\" # we should be here!\n",
    "# BES_small_data_files = BES_code_folder + \"small data files\" + os.sep\n",
    "# if not os.path.exists( BES_small_data_files ):\n",
    "#     os.makedirs( BES_small_data_files )\n",
    "\n",
    "# # we should create these if they don't already exist\n",
    "# BES_data_folder   = \"../BES_analysis_data/\"\n",
    "# if not os.path.exists( BES_data_folder ):\n",
    "#     os.makedirs( BES_data_folder )\n",
    "\n",
    "# BES_output_folder = \"../BES_analysis_output/\"\n",
    "# if not os.path.exists( BES_output_folder ):\n",
    "#     os.makedirs( BES_output_folder )\n",
    "    \n",
    "# BES_file_manifest = pd.read_csv( BES_small_data_files + \"BES_file_manifest.csv\" )\n",
    "\n",
    "# BES_R_data_files = BES_data_folder + \"R_data\" + os.sep\n",
    "# if not os.path.exists( BES_R_data_files ):\n",
    "#     os.makedirs( BES_R_data_files )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_name = \"W13_comb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# manifest = BES_file_manifest[ BES_file_manifest[\"Name\"] == dataset_name ]\n",
    "\n",
    "# data_subfolder = BES_data_folder + dataset_name + os.sep\n",
    "\n",
    "# dataset_filename = manifest[\"Stata_Filename\"].values[0]\n",
    "# # dataset_description = manifest[\"Friendlier_Description\"].values[0]\n",
    "# # dataset_citation = manifest[\"Citation\"].values[0]\n",
    "# # dataset_start = manifest[\"Date_Start\"].values[0]\n",
    "# # dataset_stop = manifest[\"Date_Stop\"].values[0]\n",
    "# # dataset_wave = manifest[\"Wave No\"].values[0]\n",
    "\n",
    "# BES_Panel = pd.read_msgpack( data_subfolder + dataset_filename.replace(\".dta\",\".msgpack\") )\n",
    "# print(\"BES_Panel\", BES_Panel.shape )\n",
    "\n",
    "# ####\n",
    "\n",
    "# BES_numeric = pd.read_hdf( data_subfolder + \"BESnumeric.hdf\", \"BESnumeric\" )\n",
    "# print(\"BES_numeric\",  BES_numeric.shape )\n",
    "\n",
    "# var_type    = pd.read_csv( data_subfolder + \"var_type.csv\", encoding=encoding)\n",
    "# var_type.set_index(\"Unnamed: 0\", inplace=True)\n",
    "# print(\"var_type\",  var_type.shape )\n",
    "\n",
    "# fname = data_subfolder + \"cat_dictionary.pkl\"\n",
    "# with open(fname, \"rb\") as f:\n",
    "#     cat_dictionary = pickle.load( f )\n",
    "    \n",
    "# ####\n",
    "\n",
    "# BES_non_numeric = pd.read_hdf( data_subfolder + \"BESnon_numeric.hdf\", \"BESnon_numeric\" )\n",
    "# print(\"BES_non_numeric\",  BES_non_numeric.shape )\n",
    "\n",
    "# BES_reduced = pd.read_hdf( data_subfolder + \"BES_reduced.hdf\", \"BES_reduced\" )\n",
    "# print(\"BES_reduced\",  BES_reduced.shape )\n",
    "\n",
    "# BES_reduced_with_na = pd.read_hdf( data_subfolder + \"BES_reduced_with_na.hdf\", \"BES_reduced_with_na\")\n",
    "# print(\"BES_reduced_with_na\", BES_reduced_with_na.shape )\n",
    "\n",
    "# fname = data_subfolder + \"new_old_col_names.pkl\"\n",
    "# with open(fname, \"rb\") as f:\n",
    "#     new_old_col_names = pickle.load(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxoAAABhCAYAAABRTdfNAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEZklEQVR4nO3aT44UdRjH4beqe9qRFAt6hhgyM5iwJTFyABfewD+LCeEYXoDgxgUb9QIk3sCYWbhgoxvRgHFnJCE4gwkCw7T00EN3V5dHoIwvqRQ8z/q3+C5+1ZVPp4qmaZoAAABIVHY9AAAAeP0IDQAAIJ3QAAAA0gkNAAAgndAAAADSCQ0AACCd0AAAANIJDQAAIJ3QAAAA0g3bHmyaJvaPTmK5Wr3KPa+V86PDGFTbUU8Polktup7TC0W5FoNqO/aPj2LZuGtt7cyPYzjeieXhfjT1sus5vVAMhjEc78Ri8iKaVdP1nP5Yex6jahzz6WE03getFGUZo2ocMasjXLXWpqtZVFUV0+k0Vu5aK2VZRlVVsaofRoR3QVtPF+diY72MJyerqD2jrWyslzEsi5eeax0aRVHExzd+jjsPJv9r2Jtk/9LnsXXlVjz89tOYP/q16zm9MDr7fmxduRWf3LwRd5486HpOb/xx72ZcuHY79r/8KE7u3+l6Ti+sv3spLly7HXe/+S1mfz3rek5vrL/3Q1y8fDXufvd1PH/0Z9dzeuHU2fNx8fLVWP50GDHxp1Nbey9+jN3d3djb24vHjx93PacXNjc3Y3d3N549+izqxe9dz+mN6/e/jy8+GMf1XyZx7x+B1sZXH27EO6cGLz3n0ykAACCd0AAAANIJDQAAIJ3QAAAA0gkNAAAgndAAAADSCQ0AACCd0AAAANIJDQAAIJ3QAAAA0gkNAAAgndAAAADSCQ0AACCd0AAAANIJDQAAIJ3QAAAA0gkNAAAgndAAAADSCQ0AACCd0AAAANIJDQAAIJ3QAAAA0gkNAAAgndAAAADSCQ0AACCd0AAAANIJDQAAIJ3QAAAA0gkNAAAgndAAAADSCQ0AACCd0AAAANIJDQAAIJ3QAAAA0gkNAAAgndAAAADSCQ0AACCd0AAAANIJDQAAIJ3QAAAA0gkNAAAgndAAAADSCQ0AACCd0AAAANIJDQAAIJ3QAAAA0gkNAAAgndAAAADSCQ0AACCd0AAAANIJDQAAIJ3QAAAA0gkNAAAgndAAAADSCQ0AACCd0AAAANIJDQAAIJ3QAAAA0gkNAAAgndAAAADSCQ0AACCd0AAAANIJDQAAIJ3QAAAA0gkNAAAgndAAAADSCQ0AACCd0AAAANIJDQAAIJ3QAAAA0gkNAAAgndAAAADSCQ0AACCd0AAAANIVTdM0bQ8fTGYxX65e5Z7XyvnRUQxPb8Xy2YNoVi+6ntMLRflWDE9vxcHxJOarZddzemNnMYu18XYsDg+iWc67ntMLxXAUa+PtmE9Ooqlb/wy+8YrRSYyqMzGfPo1V7RltoxwMY1SdiWZWR6zctbaOm5Ooqiqm02nUdd31nF4YDAZRVVXUy78jwrugraPFudh4exBPZnUsPaKtbKyXMSyLl577T6EBAADQhk+nAACAdEIDAABIJzQAAIB0QgMAAEgnNAAAgHRCAwAASCc0AACAdEIDAABIJzQAAIB0/wKNJ9VVPPmcKAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1000x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt, seaborn as sns\n",
    "import pickle, os, gc, re\n",
    "sns.set()\n",
    "sns.palplot(sns.color_palette(\"colorblind\"))\n",
    "from IPython.display import display, display_html, HTML\n",
    "plt.rcParams[\"axes.grid\"] = False\n",
    "\n",
    "import Jupyter_module_loader\n",
    "from utility import *\n",
    "import gaussian_kde\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"W13_comb\"\n",
    "df_list = [\n",
    "           \"BES_Panel\",\n",
    "           \"BES_reduced_with_na\",\n",
    "           \"BESnumeric\",\n",
    "           \"BES_reduced\",\n",
    "#            \"BESnumeric\"\n",
    "          ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you should clone this git to a subdirectory called 'BES_analysis_code' (in some directory - I call it BES_analysis - doesn't matter though)\n",
    "# %matplotlib inline\n",
    "encoding = \"ISO-8859-1\"\n",
    "\n",
    "(BES_code_folder, BES_small_data_files, BES_data_folder,\n",
    " BES_output_folder, BES_file_manifest, BES_R_data_files) = setup_directories()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pandas' has no attribute 'read_msgpack'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_23524\\3609396068.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m\"BES_Panel\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mglobals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_msgpack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_subfolder\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdataset_filename\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.dta'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'.msgpack'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mglobals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_msgpack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_subfolder\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.msgpack'\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Users\\Gamer\\anaconda3\\envs\\test_tensorflow_install\\lib\\site-packages\\pandas\\__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m    242\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_SparseArray\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 244\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"module 'pandas' has no attribute '{name}'\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    245\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'pandas' has no attribute 'read_msgpack'"
     ]
    }
   ],
   "source": [
    "global BES_Panel, BES_numeric, BES_reduced, BES_reduced_with_na, BES_non_numeric\n",
    "data_subfolder = BES_data_folder + dataset_name + os.sep\n",
    "\n",
    "(manifest, dataset_filename, dataset_description, dataset_citation,\n",
    " dataset_start, dataset_stop, dataset_wave) = get_manifest(dataset_name, BES_file_manifest)\n",
    "\n",
    "for df in df_list:\n",
    "    if df==\"BES_Panel\":\n",
    "        globals()[df]  = pd.read_msgpack(data_subfolder + dataset_filename.replace('.dta','.msgpack'))\n",
    "    else:\n",
    "        globals()[df]  = pd.read_msgpack(data_subfolder + df + '.msgpack' )\n",
    "        globals()[df].replace(-1,np.nan,inplace=True)\n",
    "  \n",
    "(var_type, cat_dictionary, new_old_col_names, old_new_col_names) = get_small_files(data_subfolder, encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.decomposition import PCA, IncrementalPCA, NMF, TruncatedSVD, FastICA, FactorAnalysis, SparsePCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "from gaussian_kde import gaussian_kde\n",
    "from utility import display_components, display_pca_data, weighted_kde\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x for x in BES_Panel.columns if \"imm\" in x.lower()]\n",
    "# immigEcon, immigCultural \n",
    "\n",
    "# immigrationLevel SINGLE CHOICE W4W6\n",
    "# immigContributeTake SCALE W7W8\n",
    "\n",
    "# immigSelf W7W8W9W10W11W12W13\n",
    "# immig<parties> W7W8W9W10W11W12W13\n",
    "\n",
    "# immigrantsWelfareState DYNAMIC GRIDW1W2W3W4W7W8W10W11Topup\n",
    "# immigEcon W1W2W3W4W6W7W8W10W11W13\n",
    "# immigCultural W1W2W3W4W6W7W8W10W11W13\n",
    "\n",
    "# changeImmig The level of immigration  W1W2W3W4W7W8W10W11\n",
    "# changeImmigLab GRIDW1W2W3W4W7W10\n",
    "\n",
    "# tryReduceImmig<parties> W4\n",
    "\n",
    "# achieveReduceImmig<parties> W4W7W9W10W11W12\n",
    "\n",
    "# responsibleImmig<parties> W1W2W3W4\n",
    "\n",
    "# govtHandleImmig GRIDW1W2W3W4W7\n",
    "# labHandleImmig GRID W1W2W3W4W7\n",
    " # <parties>Priorities_immig W1W2W3W4W6W9\n",
    "\n",
    "# controlImmig W8W9W10W11W13\n",
    "\n",
    "# effectsEUImmigration W7W8W10W11W13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# euMIISmall -> immigration selected\n",
    "# EUMIICategory -> immigration\n",
    "['EUMIICategoryW7', 'euMIISmallW7', 'EUMIICategoryW8', 'euMIISmallW8']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x for x in BES_reduced.columns if \"eumii\" in x.lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x for x in BES_Panel.columns if \"eumii\" in x.lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = BES_Panel[[x for x in BES_Panel.columns if \"eumii\" in x.lower()]]\n",
    "temp2 = (temp == \"immigration\") | (temp == \"Immigration\")\n",
    "temp3 = temp2.astype('float')\n",
    "temp3.columns = [x+\"_immigration\" for x in temp3.columns]\n",
    "eumii_vars = temp3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# euPriorityBalance SINGLE CHOICEW10W11W12W13\n",
    "# Brexit priority: access to single market versus controlling immigration?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x for x in BES_Panel.columns if re.match(\"miilabelW\\d\",x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = BES_Panel[[x for x in BES_Panel.columns if re.match(\"miilabelW\\d\",x)]]\n",
    "temp2 = (temp == \"immigration\") | (temp == \"Immigration\")\n",
    "temp3 = temp2.astype('float')\n",
    "temp3.columns = [x+\"_immigration\" for x in temp3.columns]\n",
    "mii_vars = temp3\n",
    "# miilabel W1W2W3W4W5W6\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [x for x in BES_immig.columns if \"discrim\" in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BES_immig = pd.concat( [ BES_reduced[[x for x in BES_reduced.columns if \"imm\" in x.lower()]].drop(\"miilabelW1_immigration\",axis=1), eumii_vars, mii_vars], axis=1)\n",
    "BES_immig = BES_immig.drop([x for x in BES_immig.columns if \"discrim\" in x], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Treatment = dataset_name + \"_immigration\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_subfolder = BES_output_folder + Treatment + os.sep\n",
    "if not os.path.exists( output_subfolder ):\n",
    "    os.makedirs( output_subfolder )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalise data (subtract out the mean, divide through by standard deviation)\n",
    "clean_feature_set_std = StandardScaler().fit_transform(BES_immig.values )\n",
    "BES_std = pd.DataFrame(      clean_feature_set_std,\n",
    "                             columns = BES_immig.columns,\n",
    "                             index   = BES_immig.index      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# 5 mins\n",
    "## RUN (some variant of) PCA (potentially v slow!)\n",
    "n_components = BES_std.shape[1]\n",
    "# n_components = 2\n",
    "# (svd_solver='full', n_components='mle',whiten=True)\n",
    "# decomp = PCA(n_components = n_components,svd_solver='full')\n",
    "# decomp = FastICA(algorithm='deflation', fun='exp', fun_args=None, max_iter=1000,\n",
    "#     n_components=None, random_state=None, tol=0.07, w_init=None, whiten=False) # 2h 1min 4s \"fast\"\n",
    "# decomp = SparsePCA(n_components=n_components, alpha=2,max_iter=1000,n_jobs=4,tol=1e-10, verbose=True) # 5min\n",
    "#\n",
    "# alpha=2 -> 1hr\n",
    "\n",
    "decomp = FactorAnalysis(svd_method = 'lapack',n_components = n_components) ## ~10s ,n_components=30 -> 1.5 hrs\n",
    "decomp_method = str(decomp).split(\"(\")[0] \n",
    "# ,n_components=30\n",
    "\n",
    "X_r = decomp.fit_transform(BES_std)\n",
    "\n",
    "BES_decomp = pd.DataFrame(   X_r,\n",
    "                             columns = range(0,n_components),\n",
    "                             index   = BES_reduced.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# treatdir = BES_data_folder+Treatment\n",
    "# subdir = BES_data_folder+Treatment+decomp_method\n",
    "load_suff = \"FactorAnalysis\"\n",
    "save = True # False => Load\n",
    "\n",
    "if save & ( 'decomp' in globals() ): # SAVE    ##( 'decomp' not in globals() )\n",
    "    decomp_method = str(decomp).split(\"(\")[0] \n",
    "    subdir = output_subfolder + decomp_method\n",
    "    fname = subdir+ os.sep + decomp_method\n",
    "    # create dir, save decomp object, BES_decomp, BES_std    \n",
    "    if not os.path.exists(subdir): os.makedirs(subdir)\n",
    "    with open(fname+\".pkl\", \"wb\") as f: pickle.dump( decomp, f )\n",
    "#     BES_decomp.to_hdf(fname+\".hdf\"        , decomp_method)\n",
    "#     BES_std.to_hdf(   fname+\"_std\"+\".hdf\" , decomp_method)\n",
    "    \n",
    "else: # LOAD decomp results (default is SAVE)\n",
    "    decomp_method = load_suff\n",
    "    subdir = output_subfolder + os.sep + decomp_method    \n",
    "    fname = subdir + os.sep + decomp_method\n",
    "    if not os.path.exists(subdir): raise Exception(subdir + ' does not exist!')\n",
    "    # load decomp object, BES_decomp, BES_std, n_components\n",
    "    with open(fname+\".pkl\", \"rb\") as f: decomp = pickle.load(f) \n",
    "    BES_decomp = pd.read_hdf(fname+\".hdf\")\n",
    "    BES_std    = pd.read_hdf(fname+\"_std\"+\".hdf\")\n",
    "    n_components = decomp.components_.shape[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_pca_data(n_components, decomp, BES_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(BES_decomp, comp_labels, comp_dict) = display_components(n_components, decomp,\n",
    "                                                          BES_immig.columns, BES_decomp, manifest, \n",
    "                                                          save_folder = subdir,  \n",
    "                                                          show_first_x_comps= 4, show_histogram = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SUPER USEFUL FOR FEATURE EXTRACTION/VARIABLE PREP!\n",
    "\n",
    "if hasattr(decomp, 'noise_variance_'):\n",
    "    if not isinstance(decomp.noise_variance_, float):\n",
    "        NoiseVariance = pd.DataFrame( decomp.noise_variance_ , index = BES_std.columns, columns = [\"noise_variance_\"])\n",
    "        NoiseVariance.hist( bins = int(len( NoiseVariance )/10) )\n",
    "        NoiseVariance = NoiseVariance.sort_values(by=\"noise_variance_\")\n",
    "        display( NoiseVariance )\n",
    "        display( NoiseVariance[ NoiseVariance[\"noise_variance_\"]>.9 ].sort_index() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BES_decomp[0].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BES_export_to_R = BES_immig.apply(lambda x: x.astype('category'))\n",
    "# BES_export_to_R = BES_export_to_R.apply(lambda x: x.cat.remove_unused_categories())\n",
    "# BES_export_to_R = BES_export_to_R.apply(lambda x: x.cat.codes)\n",
    "# BES_export_to_R = BES_export_to_R.replace(-1,np.nan)\n",
    "\n",
    "# filename = Treatment+\"_export_to_R\"\n",
    "\n",
    "# BES_export_to_R.to_stata(BES_R_data_files + filename + \".dta\")\n",
    "# display(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try again with just the lowest noise variables\n",
    "# immigEcon, immigCulturalm, immigSelf, immigrantsWelfareState, euPriorityBalance, \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BES_immig = BES_reduced[[x for x in BES_reduced.columns if re.match(\"immigEcon|immigCultural|immigSelf|immigrantsWelfareState|euPriorityBalance\",x)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Treatment = dataset_name + \"_immigration_narrower\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_subfolder = BES_output_folder + Treatment + os.sep\n",
    "if not os.path.exists( output_subfolder ):\n",
    "    os.makedirs( output_subfolder )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_feature_set_std = StandardScaler().fit_transform(BES_immig.values )\n",
    "BES_std = pd.DataFrame(      clean_feature_set_std,\n",
    "                             columns = BES_immig.columns,\n",
    "                             index   = BES_immig.index      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "n_components = BES_std.shape[1]\n",
    "\n",
    "decomp = FactorAnalysis(svd_method = 'lapack',n_components = n_components) ## ~10s ,n_components=30 -> 1.5 hrs\n",
    "decomp_method = str(decomp).split(\"(\")[0] \n",
    "\n",
    "X_r = decomp.fit_transform(BES_std)\n",
    "\n",
    "BES_decomp = pd.DataFrame(   X_r,\n",
    "                             columns = range(0,n_components),\n",
    "                             index   = BES_immig.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# treatdir = BES_data_folder+Treatment\n",
    "# subdir = BES_data_folder+Treatment+decomp_method\n",
    "load_suff = \"FactorAnalysis\"\n",
    "save = True # False => Load\n",
    "\n",
    "if save & ( 'decomp' in globals() ): # SAVE    ##( 'decomp' not in globals() )\n",
    "    decomp_method = str(decomp).split(\"(\")[0] \n",
    "    subdir = output_subfolder + decomp_method\n",
    "    fname = subdir+ os.sep + decomp_method\n",
    "    # create dir, save decomp object, BES_decomp, BES_std    \n",
    "    if not os.path.exists(subdir): os.makedirs(subdir)\n",
    "    with open(fname+\".pkl\", \"wb\") as f: pickle.dump( decomp, f )\n",
    "#     BES_decomp.to_hdf(fname+\".hdf\"        , decomp_method)\n",
    "#     BES_std.to_hdf(   fname+\"_std\"+\".hdf\" , decomp_method)\n",
    "    \n",
    "else: # LOAD decomp results (default is SAVE)\n",
    "    decomp_method = load_suff\n",
    "    subdir = output_subfolder + os.sep + decomp_method    \n",
    "    fname = subdir + os.sep + decomp_method\n",
    "    if not os.path.exists(subdir): raise Exception(subdir + ' does not exist!')\n",
    "    # load decomp object, BES_decomp, BES_std, n_components\n",
    "    with open(fname+\".pkl\", \"rb\") as f: decomp = pickle.load(f) \n",
    "    BES_decomp = pd.read_hdf(fname+\".hdf\")\n",
    "    BES_std    = pd.read_hdf(fname+\"_std\"+\".hdf\")\n",
    "    n_components = decomp.components_.shape[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_pca_data(n_components, decomp, BES_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(BES_decomp, comp_labels, comp_dict) = display_components(n_components, decomp,\n",
    "                                                          BES_immig.columns, BES_decomp, manifest, \n",
    "                                                          save_folder = subdir,  \n",
    "                                                          show_first_x_comps= 4, show_histogram = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SUPER USEFUL FOR FEATURE EXTRACTION/VARIABLE PREP!\n",
    "\n",
    "if hasattr(decomp, 'noise_variance_'):\n",
    "    if not isinstance(decomp.noise_variance_, float):\n",
    "        NoiseVariance = pd.DataFrame( decomp.noise_variance_ , index = BES_std.columns, columns = [\"noise_variance_\"])\n",
    "        NoiseVariance.hist( bins = int(len( NoiseVariance )/10) )\n",
    "        NoiseVariance = NoiseVariance.sort_values(by=\"noise_variance_\")\n",
    "        display( NoiseVariance )\n",
    "        display( NoiseVariance[ NoiseVariance[\"noise_variance_\"]>.9 ].sort_index() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BES_export_to_R = BES_immig.apply(lambda x: x.astype('category'))\n",
    "# BES_export_to_R = BES_export_to_R.apply(lambda x: x.cat.remove_unused_categories())\n",
    "# BES_export_to_R = BES_export_to_R.apply(lambda x: x.cat.codes)\n",
    "# BES_export_to_R = BES_export_to_R.replace(-1,np.nan)\n",
    "\n",
    "# filename = Treatment+\"_export_to_R\"\n",
    "\n",
    "# BES_export_to_R.to_stata(BES_R_data_files + filename + \".dta\")\n",
    "# display(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hq_subset = BES_Panel[[x for x in BES_Panel.columns if re.match(\"immigEcon|immigCultural|immigSelf|immigrantsWelfareState|euPriorityBalance\",x)]].notnull().sum(axis=1)>30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hq_subset.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BES_export_to_R = BES_immig[hq_subset].apply(lambda x: x.astype('category'))\n",
    "# BES_export_to_R = BES_export_to_R.apply(lambda x: x.cat.remove_unused_categories())\n",
    "# BES_export_to_R = BES_export_to_R.apply(lambda x: x.cat.codes)\n",
    "# BES_export_to_R = BES_export_to_R.replace(-1,np.nan)\n",
    "\n",
    "# filename = Treatment+\"_export_to_R\"\n",
    "\n",
    "# BES_export_to_R.to_stata(BES_R_data_files + filename + \".dta\")\n",
    "# display(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sankey diagram for imm_preferences?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipysankeywidget import SankeyWidget\n",
    "from ipywidgets import Layout\n",
    "from ipywidgets import Button, VBox, HBox, Output\n",
    "from IPython.display import display, clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = ['red','purple','blue','yellow','black','orange','grey','cyan','brown','green','pink','olive','peru',\n",
    "        'fuchsia', 'chartreuse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipysankeywidget import SankeyWidget\n",
    "from ipywidgets import Layout\n",
    "from ipywidgets import Button, VBox, HBox, Output\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "cmap = ['red','purple','blue','yellow','black','orange','grey','cyan','brown','green','pink','olive','peru',\n",
    "        'fuchsia', 'chartreuse']\n",
    "\n",
    "def flatten(A):\n",
    "    rt = []\n",
    "    for i in A:\n",
    "        if isinstance(i,list): rt.extend(flatten(i))\n",
    "        else: rt.append(i)\n",
    "    return rt\n",
    "\n",
    "def make_sankey(BES, links, order, first_year, second_year, first_col, second_col,\n",
    "                replace_dict, threshold, colour, fixed_order, scale, nodes, wt_col, groups, group_index):\n",
    "    \n",
    "    crosstab = pd.crosstab(index   = BES[ first_col  ],\n",
    "                           columns = BES[ second_col ],\n",
    "                           values  = BES[ wt_col ],\n",
    "                           aggfunc = sum, dropna = False,\n",
    "                           normalize=True)*scale\n",
    "\n",
    "    if order == []: # initialise\n",
    "        order = [ [[x+first_year]  for x in fixed_order] ]\n",
    "    order.append( [[x+second_year] for x in fixed_order] ) # add new layer\n",
    "    \n",
    "\n",
    "    for col in crosstab.columns:\n",
    "        if col not in replace_dict.keys():\n",
    "            continue        \n",
    "        second_party = replace_dict[ col ]\n",
    "        for ind in crosstab[col].index:\n",
    "            if ind not in replace_dict.keys():\n",
    "                continue\n",
    "            first_party = replace_dict[ ind ]\n",
    "            \n",
    "            if crosstab[col][ind]>threshold:\n",
    "                if colour == []:\n",
    "                    col_to_use = colourmap[first_party]\n",
    "                else:\n",
    "                    col_to_use = cmap[colour]\n",
    "                \n",
    "                node_id_first = first_party+first_year\n",
    "                \n",
    "                # add group if not already present\n",
    "                if first_year not in group_index.keys():\n",
    "                    group_index[first_year] = len(groups)\n",
    "                    groups.append( {'id': first_year, 'title': first_year, 'nodes': []} )\n",
    "                    \n",
    "                if node_id_first not in [x['id'] for x in nodes]:\n",
    "                    nodes.append({'id':node_id_first, 'direction':'l'})\n",
    "                    groups[group_index[first_year]]['nodes'].append(node_id_first)                    \n",
    "                    \n",
    "                node_id_second = second_party+second_year\n",
    "                \n",
    "                # add group if not already present\n",
    "                if second_year not in group_index.keys():\n",
    "                    group_index[second_year] = len(groups)\n",
    "                    groups.append( {'id': second_year, 'title': second_year, 'nodes': []} )                \n",
    "                \n",
    "                if node_id_second not in [x['id'] for x in nodes]:\n",
    "                    nodes.append({'id':node_id_second, 'direction':'l'})\n",
    "                    groups[group_index[second_year]]['nodes'].append(node_id_second)\n",
    "\n",
    "                if colour ==[]:\n",
    "                    d = {'source': node_id_first,\n",
    "                         'target': node_id_second,\n",
    "                         'value': crosstab[col][ind],\n",
    "                         'color': col_to_use}\n",
    "                else:\n",
    "                    d = {'source': node_id_first,\n",
    "                         'target': node_id_second,\n",
    "                         'value': crosstab[col][ind],\n",
    "                         'color': col_to_use,'type' : str(colour)}                    \n",
    "                links.append(d)\n",
    "\n",
    "    return links, order, nodes, groups, group_index\n",
    "\n",
    "def sankify():\n",
    "    colour = []\n",
    "    order  = []\n",
    "    links  = []\n",
    "    # [\"W7\",\"W8\",\"W9\",\"W10\",\"W11\",\"W12\",\"W13\"]\n",
    "    pairs = [(x,im_var+x) for x in wave_list]\n",
    "    scale = 100\n",
    "    nodes = []\n",
    "    wt_col = 'wt_new_W13'\n",
    "    groups = []\n",
    "    group_index = {}\n",
    "    for pair_no in range(0,len(pairs)-1):\n",
    "\n",
    "\n",
    "        (links, order, nodes, groups, group_index) = make_sankey(BES_Panel, links, order,\n",
    "                            pairs[pair_no][0], pairs[pair_no+1][0],\n",
    "                            pairs[pair_no][1], pairs[pair_no+1][1],\n",
    "                            replace_dict, threshold, colour, fixed_order = base_order, scale=scale, nodes=nodes, wt_col = wt_col, groups=groups, group_index=group_index)    \n",
    "\n",
    "    sankey = SankeyWidget(links=links, order=order, nodes=[], groups=groups, margins = margins, scale=diagram_scale, layout=layout)\n",
    "    return sankey\n",
    "\n",
    "def sankify_init_col(): \n",
    "    # sankify with colour sets by initial choice\n",
    "\n",
    "    colour = []\n",
    "    order  = []\n",
    "    links  = []\n",
    "\n",
    "    pairs = [(x,im_var+x) for x in wave_list]\n",
    "    scale = 100\n",
    "    nodes = []\n",
    "    wt_col = 'wt_new_W13'\n",
    "    groups = []\n",
    "    group_index = {}\n",
    "\n",
    "    for party in base_order:\n",
    "        order  = []\n",
    "        BES = BES_immig.loc[ BES_immig[immig_vars[0]]==party ]\n",
    "        scale = 100 * BES.shape[0]/BES_immig.shape[0]\n",
    "        colour = list(colourmap.values()).index( colourmap[replace_dict[party]] )    \n",
    "\n",
    "        for pair_no in range(0,len(pairs)-1):\n",
    "\n",
    "            (links, order, nodes, groups, group_index) = make_sankey(BES, links, order,\n",
    "                                pairs[pair_no][0], pairs[pair_no+1][0],\n",
    "                                pairs[pair_no][1], pairs[pair_no+1][1],\n",
    "                                replace_dict, threshold, colour, fixed_order = base_order,\n",
    "                                scale=scale, nodes=nodes, wt_col = wt_col, groups=groups, group_index=group_index)    \n",
    "\n",
    "    sankey = SankeyWidget(layout=layout,links=links, order=order, nodes=[], groups=groups, margins = margins, scale=diagram_scale)\n",
    "    return sankey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sankify():\n",
    "    colour = []\n",
    "    order  = []\n",
    "    links  = []\n",
    "    # [\"W7\",\"W8\",\"W9\",\"W10\",\"W11\",\"W12\",\"W13\"]\n",
    "    pairs = [(x,im_var+x) for x in wave_list]\n",
    "    scale = 100\n",
    "    nodes = []\n",
    "    wt_col = 'wt_new_W13'\n",
    "    groups = []\n",
    "    group_index = {}\n",
    "    for pair_no in range(0,len(pairs)-1):\n",
    "\n",
    "\n",
    "        (links, order, nodes, groups, group_index) = make_sankey(BES_Panel, links, order,\n",
    "                            pairs[pair_no][0], pairs[pair_no+1][0],\n",
    "                            pairs[pair_no][1], pairs[pair_no+1][1],\n",
    "                            replace_dict, threshold, colour, fixed_order = base_order, scale=scale, nodes=nodes, wt_col = wt_col, groups=groups, group_index=group_index)    \n",
    "\n",
    "    sankey = SankeyWidget(links=links, order=order, nodes=[], groups=groups, margins = margins, scale=diagram_scale, layout=layout)\n",
    "    return sankey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sankify_init_col(): \n",
    "    # sankify with colour sets by initial choice\n",
    "\n",
    "    colour = []\n",
    "    order  = []\n",
    "    links  = []\n",
    "\n",
    "    pairs = [(x,im_var+x) for x in wave_list]\n",
    "    scale = 100\n",
    "    nodes = []\n",
    "    wt_col = 'wt_new_W13'\n",
    "    groups = []\n",
    "    group_index = {}\n",
    "\n",
    "    for party in base_order:\n",
    "        order  = []\n",
    "        BES = BES_immig.loc[ BES_immig[immig_vars[0]]==party ]\n",
    "        scale = 100 * BES.shape[0]/BES_immig.shape[0]\n",
    "        colour = list(colourmap.values()).index( colourmap[replace_dict[party]] )    \n",
    "\n",
    "        for pair_no in range(0,len(pairs)-1):\n",
    "\n",
    "            (links, order, nodes, groups, group_index) = make_sankey(BES, links, order,\n",
    "                                pairs[pair_no][0], pairs[pair_no+1][0],\n",
    "                                pairs[pair_no][1], pairs[pair_no+1][1],\n",
    "                                replace_dict, threshold, colour, fixed_order = base_order,\n",
    "                                scale=scale, nodes=nodes, wt_col = wt_col, groups=groups, group_index=group_index)    \n",
    "\n",
    "    sankey = SankeyWidget(layout=layout,links=links, order=order, nodes=[], groups=groups, margins = margins, scale=diagram_scale)\n",
    "    return sankey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_var = \"immigSelf\"\n",
    "\n",
    "immig_vars = [x for x in BES_Panel.columns if im_var in x]\n",
    "wave_list = [x.split(im_var)[1] for x in immig_vars]\n",
    "immig_vars.append('wt_new_W13')\n",
    "BES_immig = BES_Panel[immig_vars]\n",
    "replace_dict = {x:x for x in BES_immig[immig_vars[0]].cat.categories}\n",
    "colourmap = {BES_immig[immig_vars[0]].cat.categories[x]:cmap[x] for x in range(0, len( BES_immig[immig_vars[0]].cat.categories)) } \n",
    "base_order = BES_immig[immig_vars[0]].cat.categories\n",
    "\n",
    "wave_list = [\"W7\",\"W8\",\"W9\",\"W10\",\"W11\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "margins=dict(top=30, bottom=10, left=150, right=150)\n",
    "layout = Layout(width=\"1000\", height=\"650\")\n",
    "diagram_scale=2\n",
    "sankify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BES_Panel[[x for x in BES_Panel.columns if \"immigEcon\" in x]].notnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BES_Panel[[x for x in BES_Panel.columns if \"immigSelf\" in x]].notnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_var = \"immigEcon\"\n",
    "\n",
    "immig_vars = [x for x in BES_Panel.columns if im_var in x]\n",
    "wave_list = [x.split(im_var)[1] for x in immig_vars]\n",
    "immig_vars.append('wt_new_W13')\n",
    "BES_immig = BES_Panel[immig_vars]\n",
    "replace_dict = {x:x for x in BES_immig[immig_vars[0]].cat.categories}\n",
    "colourmap = {BES_immig[immig_vars[0]].cat.categories[x]:cmap[x] for x in range(0, len( BES_immig[immig_vars[0]].cat.categories)) } \n",
    "base_order = BES_immig[immig_vars[0]].cat.categories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "margins=dict(top=30, bottom=10, left=150, right=150)\n",
    "layout = Layout(width=\"1000\", height=\"650\")\n",
    "diagram_scale=2\n",
    "sankey = sankify()\n",
    "sankey.auto_save_png(BES_output_folder+os.sep+\"leftRight_sankey.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BES_output_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.1\n",
    "margins=dict(top=30, bottom=10, left=150, right=150)\n",
    "layout = Layout(width=\"1000\", height=\"650\")\n",
    "diagram_scale=5\n",
    "sankey = sankify_init_col()\n",
    "sankey.auto_save_png(BES_output_folder+os.sep+\"immigEcon.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wave_list = [\"W1\",\"W13\"]\n",
    "\n",
    "threshold = 0.1\n",
    "margins=dict(top=30, bottom=10, left=150, right=150)\n",
    "layout = Layout(width=\"1000\", height=\"650\")\n",
    "diagram_scale=2\n",
    "sankify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now compared immigCultural\n",
    "im_var = \"immigCultural\"\n",
    "\n",
    "immig_vars = [x for x in BES_Panel.columns if im_var in x]\n",
    "wave_list = [x.split(im_var)[1] for x in immig_vars]\n",
    "immig_vars.append('wt_new_W13')\n",
    "BES_immig = BES_Panel[immig_vars]\n",
    "replace_dict = {x:x for x in BES_immig[immig_vars[0]].cat.categories}\n",
    "colourmap = {BES_immig[immig_vars[0]].cat.categories[x]:cmap[x] for x in range(0, len( BES_immig[immig_vars[0]].cat.categories)) } \n",
    "base_order = BES_immig[immig_vars[0]].cat.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "margins=dict(top=30, bottom=10, left=150, right=150)\n",
    "layout = Layout(width=\"1000\", height=\"650\")\n",
    "diagram_scale=2\n",
    "sankify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.1\n",
    "margins=dict(top=30, bottom=10, left=150, right=150)\n",
    "layout = Layout(width=\"1000\", height=\"650\")\n",
    "diagram_scale=2\n",
    "sankify_init_col()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# immigSelf W7W8W9W10W11W12W13\n",
    "im_var = \"immigSelf\"\n",
    "\n",
    "immig_vars = [x for x in BES_Panel.columns if im_var in x]\n",
    "wave_list = [x.split(im_var)[1] for x in immig_vars]\n",
    "immig_vars.append('wt_new_W13')\n",
    "BES_immig = BES_Panel[immig_vars]\n",
    "replace_dict = {x:x for x in BES_immig[immig_vars[0]].cat.categories}\n",
    "colourmap = {BES_immig[immig_vars[0]].cat.categories[x]:cmap[x] for x in range(0, len( BES_immig[immig_vars[0]].cat.categories)) } \n",
    "base_order = BES_immig[immig_vars[0]].cat.categories\n",
    "\n",
    "# specific problem with the last two waves not overlapping the prior data!\n",
    "wave_list = ['W7', 'W8', 'W9', 'W10', 'W11']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "margins=dict(top=30, bottom=10, left=150, right=150)\n",
    "layout = Layout(width=\"1000\", height=\"650\")\n",
    "diagram_scale=2\n",
    "sankify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.1\n",
    "margins=dict(top=30, bottom=10, left=150, right=150)\n",
    "layout = Layout(width=\"1000\", height=\"650\")\n",
    "diagram_scale=2\n",
    "sankify_init_col()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#immigrantsWelfareState\n",
    "im_var = \"immigrantsWelfareState\"\n",
    "\n",
    "immig_vars = [x for x in BES_Panel.columns if im_var in x]\n",
    "wave_list = [x.split(im_var)[1] for x in immig_vars]\n",
    "immig_vars.append('wt_new_W13')\n",
    "BES_immig = BES_Panel[immig_vars]\n",
    "replace_dict = {x:x for x in BES_immig[immig_vars[0]].cat.categories}\n",
    "colourmap = {BES_immig[immig_vars[0]].cat.categories[x]:cmap[x] for x in range(0, len( BES_immig[immig_vars[0]].cat.categories)) } \n",
    "base_order = BES_immig[immig_vars[0]].cat.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "margins=dict(top=30, bottom=10, left=150, right=150)\n",
    "layout = Layout(width=\"1000\", height=\"650\")\n",
    "diagram_scale=2\n",
    "sankify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.1\n",
    "margins=dict(top=30, bottom=10, left=150, right=150)\n",
    "layout = Layout(width=\"1000\", height=\"650\")\n",
    "diagram_scale=5\n",
    "# sankify_init_col()\n",
    "sankey = sankify_init_col()\n",
    "sankey.auto_save_png(BES_output_folder+os.sep+\"W13_comb_imm_corr\"+os.sep+\"immigrantsWelfareState.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# immigrationLevel\n",
    "im_var = \"immigrationLevel\"\n",
    "\n",
    "immig_vars = [x for x in BES_Panel.columns if im_var in x]\n",
    "wave_list = [x.split(im_var)[1] for x in immig_vars]\n",
    "immig_vars.append('wt_new_W13')\n",
    "BES_immig = BES_Panel[immig_vars]\n",
    "replace_dict = {x:x for x in BES_immig[immig_vars[0]].cat.categories}\n",
    "colourmap = {BES_immig[immig_vars[0]].cat.categories[x]:cmap[x] for x in range(0, len( BES_immig[immig_vars[0]].cat.categories)) } \n",
    "base_order = BES_immig[immig_vars[0]].cat.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "margins=dict(top=30, bottom=10, left=150, right=150)\n",
    "layout = Layout(width=\"1000\", height=\"650\")\n",
    "diagram_scale=2\n",
    "sankify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# immigContributeTake\n",
    "# kind of a hassle because the categories are floats!\n",
    "\n",
    "BES_Panel[[x for x in BES_Panel.columns if \"immigContributeTake\" in x]] = BES_Panel[[x for x in BES_Panel.columns if \"immigContributeTake\" in x]].apply(lambda x: x.cat.set_categories([str(x) for x in x.cat.categories]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_var = \"immigContributeTake\"\n",
    "\n",
    "immig_vars = [x for x in BES_Panel.columns if im_var in x]\n",
    "wave_list = [x.split(im_var)[1] for x in immig_vars]\n",
    "immig_vars.append('wt_new_W13')\n",
    "BES_immig = BES_Panel[immig_vars]\n",
    "replace_dict = {x:x for x in BES_immig[immig_vars[0]].cat.categories}\n",
    "colourmap = {BES_immig[immig_vars[0]].cat.categories[x]:cmap[x] for x in range(0, len( BES_immig[immig_vars[0]].cat.categories)) } \n",
    "base_order = BES_immig[immig_vars[0]].cat.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "margins=dict(top=30, bottom=10, left=150, right=150)\n",
    "layout = Layout(width=\"1000\", height=\"650\")\n",
    "diagram_scale=2\n",
    "sankify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changeImmig\n",
    "im_var = \"changeImmig\"\n",
    "\n",
    "immig_vars = [x for x in BES_Panel.columns if re.match(im_var+\"W\\d\",  x)]\n",
    "wave_list = [x.split(im_var)[1] for x in immig_vars]\n",
    "immig_vars.append('wt_new_W13')\n",
    "BES_immig = BES_Panel[immig_vars]\n",
    "replace_dict = {x:x for x in BES_immig[immig_vars[0]].cat.categories}\n",
    "colourmap = {BES_immig[immig_vars[0]].cat.categories[x]:cmap[x] for x in range(0, len( BES_immig[immig_vars[0]].cat.categories)) } \n",
    "base_order = BES_immig[immig_vars[0]].cat.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "margins=dict(top=30, bottom=10, left=180, right=180)\n",
    "layout = Layout(width=\"1000\", height=\"650\")\n",
    "diagram_scale=2\n",
    "sankify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.1\n",
    "margins=dict(top=30, bottom=10, left=180, right=180)\n",
    "layout = Layout(width=\"1000\", height=\"650\")\n",
    "diagram_scale=5\n",
    "sankey = sankify_init_col()\n",
    "sankey.auto_save_png(BES_output_folder+os.sep+\"W13_comb_imm_corr\"+os.sep+\"changeImmig.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changeImmig\n",
    "im_var = \"changeImmigLab\"\n",
    "\n",
    "immig_vars = [x for x in BES_Panel.columns if re.match(im_var+\"W\\d\",  x)]\n",
    "wave_list = [x.split(im_var)[1] for x in immig_vars]\n",
    "immig_vars.append('wt_new_W13')\n",
    "BES_immig = BES_Panel[immig_vars]\n",
    "replace_dict = {x:x for x in BES_immig[immig_vars[0]].cat.categories}\n",
    "colourmap = {BES_immig[immig_vars[0]].cat.categories[x]:cmap[x] for x in range(0, len( BES_immig[immig_vars[0]].cat.categories)) } \n",
    "base_order = BES_immig[immig_vars[0]].cat.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "margins=dict(top=30, bottom=10, left=150, right=150)\n",
    "layout = Layout(width=\"1000\", height=\"650\")\n",
    "diagram_scale=2\n",
    "sankify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "threshold = 0.1\n",
    "margins=dict(top=30, bottom=10, left=150, right=150)\n",
    "layout = Layout(width=\"1000\", height=\"650\")\n",
    "diagram_scale=2\n",
    "sankify_init_col()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# controlImmig\n",
    "im_var = \"controlImmig\"\n",
    "\n",
    "immig_vars = [x for x in BES_Panel.columns if re.match(im_var+\"W\\d\",  x)]\n",
    "wave_list = [x.split(im_var)[1] for x in immig_vars]\n",
    "immig_vars.append('wt_new_W13')\n",
    "BES_immig = BES_Panel[immig_vars]\n",
    "replace_dict = {x:x for x in BES_immig[immig_vars[0]].cat.categories}\n",
    "colourmap = {BES_immig[immig_vars[0]].cat.categories[x]:cmap[x] for x in range(0, len( BES_immig[immig_vars[0]].cat.categories)) } \n",
    "base_order = BES_immig[immig_vars[0]].cat.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "margins=dict(top=30, bottom=10, left=150, right=150)\n",
    "layout = Layout(width=\"1000\", height=\"650\")\n",
    "diagram_scale=2\n",
    "sankify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.01\n",
    "margins=dict(top=30, bottom=10, left=150, right=150)\n",
    "layout = Layout(width=\"1000\", height=\"650\")\n",
    "diagram_scale=20\n",
    "sankify_init_col()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# asylum, eu, noneu, students, families"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_var = \"asylumMore\"\n",
    "\n",
    "immig_vars = [x for x in BES_Panel.columns if re.match(im_var+\"W\\d\",  x)]\n",
    "wave_list = [x.split(im_var)[1] for x in immig_vars]\n",
    "immig_vars.append('wt_new_W13')\n",
    "BES_immig = BES_Panel[immig_vars]\n",
    "replace_dict = {x:x for x in BES_immig[immig_vars[0]].cat.categories}\n",
    "colourmap = {BES_immig[immig_vars[0]].cat.categories[x]:cmap[x] for x in range(0, len( BES_immig[immig_vars[0]].cat.categories)) } \n",
    "base_order = BES_immig[immig_vars[0]].cat.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "margins=dict(top=30, bottom=10, left=150, right=150)\n",
    "layout = Layout(width=\"1000\", height=\"650\")\n",
    "diagram_scale=2\n",
    "sankify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.1\n",
    "margins=dict(top=30, bottom=10, left=150, right=150)\n",
    "layout = Layout(width=\"1000\", height=\"650\")\n",
    "diagram_scale=5\n",
    "sankify_init_col()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_var = \"euMore\"\n",
    "\n",
    "immig_vars = [x for x in BES_Panel.columns if re.match(im_var+\"W\\d\",  x)]\n",
    "wave_list = [x.split(im_var)[1] for x in immig_vars]\n",
    "immig_vars.append('wt_new_W13')\n",
    "BES_immig = BES_Panel[immig_vars]\n",
    "replace_dict = {x:x for x in BES_immig[immig_vars[0]].cat.categories}\n",
    "colourmap = {BES_immig[immig_vars[0]].cat.categories[x]:cmap[x] for x in range(0, len( BES_immig[immig_vars[0]].cat.categories)) } \n",
    "base_order = BES_immig[immig_vars[0]].cat.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "margins=dict(top=30, bottom=10, left=150, right=150)\n",
    "layout = Layout(width=\"1000\", height=\"650\")\n",
    "diagram_scale=2\n",
    "sankify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.1\n",
    "margins=dict(top=30, bottom=10, left=150, right=150)\n",
    "layout = Layout(width=\"1000\", height=\"650\")\n",
    "diagram_scale=5\n",
    "sankify_init_col()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_var = \"noneuMore\"\n",
    "\n",
    "immig_vars = [x for x in BES_Panel.columns if re.match(im_var+\"W\\d\",  x)]\n",
    "wave_list = [x.split(im_var)[1] for x in immig_vars]\n",
    "immig_vars.append('wt_new_W13')\n",
    "BES_immig = BES_Panel[immig_vars]\n",
    "replace_dict = {x:x for x in BES_immig[immig_vars[0]].cat.categories}\n",
    "colourmap = {BES_immig[immig_vars[0]].cat.categories[x]:cmap[x] for x in range(0, len( BES_immig[immig_vars[0]].cat.categories)) } \n",
    "base_order = BES_immig[immig_vars[0]].cat.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "margins=dict(top=30, bottom=10, left=150, right=150)\n",
    "layout = Layout(width=\"1000\", height=\"650\")\n",
    "diagram_scale=2\n",
    "sankify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.1\n",
    "margins=dict(top=30, bottom=10, left=150, right=150)\n",
    "layout = Layout(width=\"1000\", height=\"650\")\n",
    "diagram_scale=5\n",
    "sankify_init_col()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_var = \"studentsMore\"\n",
    "\n",
    "immig_vars = [x for x in BES_Panel.columns if re.match(im_var+\"W\\d\",  x)]\n",
    "wave_list = [x.split(im_var)[1] for x in immig_vars]\n",
    "immig_vars.append('wt_new_W13')\n",
    "BES_immig = BES_Panel[immig_vars]\n",
    "replace_dict = {x:x for x in BES_immig[immig_vars[0]].cat.categories}\n",
    "colourmap = {BES_immig[immig_vars[0]].cat.categories[x]:cmap[x] for x in range(0, len( BES_immig[immig_vars[0]].cat.categories)) } \n",
    "base_order = BES_immig[immig_vars[0]].cat.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "margins=dict(top=30, bottom=10, left=150, right=150)\n",
    "layout = Layout(width=\"1000\", height=\"650\")\n",
    "diagram_scale=2\n",
    "sankify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.1\n",
    "margins=dict(top=30, bottom=10, left=150, right=150)\n",
    "layout = Layout(width=\"1000\", height=\"650\")\n",
    "diagram_scale=5\n",
    "sankify_init_col()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_var = \"familiesMore\"\n",
    "\n",
    "immig_vars = [x for x in BES_Panel.columns if re.match(im_var+\"W\\d\",  x)]\n",
    "wave_list = [x.split(im_var)[1] for x in immig_vars]\n",
    "immig_vars.append('wt_new_W13')\n",
    "BES_immig = BES_Panel[immig_vars]\n",
    "replace_dict = {x:x for x in BES_immig[immig_vars[0]].cat.categories}\n",
    "colourmap = {BES_immig[immig_vars[0]].cat.categories[x]:cmap[x] for x in range(0, len( BES_immig[immig_vars[0]].cat.categories)) } \n",
    "base_order = BES_immig[immig_vars[0]].cat.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "margins=dict(top=30, bottom=10, left=150, right=150)\n",
    "layout = Layout(width=\"1000\", height=\"650\")\n",
    "diagram_scale=2\n",
    "sankify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.1\n",
    "margins=dict(top=30, bottom=10, left=150, right=150)\n",
    "layout = Layout(width=\"1000\", height=\"650\")\n",
    "diagram_scale=5\n",
    "sankify_init_col()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# effectsEUImmigration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_var = \"effectsEUImmigration\"\n",
    "\n",
    "immig_vars = [x for x in BES_Panel.columns if re.match(im_var+\"W\\d\",  x)]\n",
    "wave_list = [x.split(im_var)[1] for x in immig_vars]\n",
    "immig_vars.append('wt_new_W13')\n",
    "BES_immig = BES_Panel[immig_vars]\n",
    "replace_dict = {x:x for x in BES_immig[immig_vars[0]].cat.categories}\n",
    "colourmap = {BES_immig[immig_vars[0]].cat.categories[x]:cmap[x] for x in range(0, len( BES_immig[immig_vars[0]].cat.categories)) } \n",
    "base_order = BES_immig[immig_vars[0]].cat.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "margins=dict(top=30, bottom=10, left=150, right=150)\n",
    "layout = Layout(width=\"1000\", height=\"650\")\n",
    "diagram_scale=2\n",
    "sankify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.1\n",
    "margins=dict(top=30, bottom=10, left=150, right=150)\n",
    "layout = Layout(width=\"1000\", height=\"650\")\n",
    "diagram_scale=5\n",
    "sankify_init_col()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# euPriorityBalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_var = \"euPriorityBalance\"\n",
    "\n",
    "immig_vars = [x for x in BES_Panel.columns if re.match(im_var+\"W\\d\",  x)]\n",
    "wave_list = [x.split(im_var)[1] for x in immig_vars]\n",
    "immig_vars.append('wt_new_W13')\n",
    "BES_immig = BES_Panel[immig_vars]\n",
    "replace_dict = {x:x for x in BES_immig[immig_vars[0]].cat.categories}\n",
    "colourmap = {BES_immig[immig_vars[0]].cat.categories[x]:cmap[x] for x in range(0, len( BES_immig[immig_vars[0]].cat.categories)) } \n",
    "base_order = BES_immig[immig_vars[0]].cat.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "margins=dict(top=30, bottom=10, left=150, right=150)\n",
    "layout = Layout(width=\"1000\", height=\"650\")\n",
    "diagram_scale=2\n",
    "sankify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.01\n",
    "margins=dict(top=30, bottom=10, left=150, right=150)\n",
    "layout = Layout(width=\"1000\", height=\"650\")\n",
    "diagram_scale=5\n",
    "sankify_init_col()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# euMIISmall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(BES_immig[immig_vars[0]].cat.categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# euMIISmall\n",
    "im_var = \"euMIISmall\"\n",
    "\n",
    "immig_vars = [x for x in BES_Panel.columns if re.match(im_var+\"W\\d\",  x)]\n",
    "wave_list = [x.split(im_var)[1] for x in immig_vars]\n",
    "immig_vars.append('wt_new_W13')\n",
    "BES_immig = BES_Panel[immig_vars]\n",
    "replace_dict = {x:x for x in BES_immig[immig_vars[0]].cat.categories}\n",
    "colourmap = {BES_immig[immig_vars[0]].cat.categories[x]:cmap[x] for x in range(0, len( BES_immig[immig_vars[0]].cat.categories)) } \n",
    "base_order = BES_immig[immig_vars[0]].cat.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "margins=dict(top=30, bottom=10, left=150, right=150)\n",
    "layout = Layout(width=\"1000\", height=\"650\")\n",
    "diagram_scale=2\n",
    "sankify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EUMIICategory\n",
    "# 54 categories - too many!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# miilabel\n",
    "len(BES_immig[immig_vars[0]].cat.categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_var = \"miilabel\"\n",
    "\n",
    "immig_vars = [x for x in BES_Panel.columns if re.match(im_var+\"W\\d\",  x)]\n",
    "wave_list = [x.split(im_var)[1] for x in immig_vars]\n",
    "immig_vars_minus_wt_col = immig_vars.copy()\n",
    "immig_vars.append('wt_new_W13')\n",
    "BES_immig = BES_Panel[immig_vars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_list=  []\n",
    "for ind in range(0,len(immig_vars_minus_wt_col)):\n",
    "    vc = BES_immig[immig_vars_minus_wt_col[ind]].value_counts()\n",
    "    sig_var = vc[vc/vc.sum()>.03].index\n",
    "    [var_list.append(x) for x in sig_var if x not in var_list]\n",
    "var_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_by_freq = var_list\n",
    "#BES_immig[immig_vars_minus_wt_col].stack().value_counts().index\n",
    "temp = list(ordered_by_freq[0:12])\n",
    "temp.append(\"Other\")\n",
    "\n",
    "for x in immig_vars_minus_wt_col:\n",
    "    BES_immig[x] = BES_immig[x].cat.set_categories(temp)#.fillna(\"Other\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_dict = {x:x for x in BES_immig[immig_vars[0]].cat.categories}\n",
    "colourmap = {BES_immig[immig_vars[0]].cat.categories[x]:cmap[x] for x in range(0, len( BES_immig[immig_vars[0]].cat.categories)) } \n",
    "base_order = BES_immig[immig_vars[0]].cat.categories#.drop(\"Other\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "margins=dict(top=30, bottom=10, left=150, right=150)\n",
    "layout = Layout(width=\"1000\", height=\"650\")\n",
    "diagram_scale=2\n",
    "sankify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.1\n",
    "margins=dict(top=30, bottom=10, left=150, right=150)\n",
    "layout = Layout(width=\"1000\", height=\"650\")\n",
    "diagram_scale=5\n",
    "sankify_init_col()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imvar_list = [\"immigEcon\",\"immigCultural\", \"immigSelf\",\n",
    "             \"immigrationLevel\", \"immigContributeTake\",\n",
    "             \"immigrantsWelfareState\", \"controlImmig\",\n",
    "             \"effectsEUImmigration\", \"euPriorityBalance\",\n",
    "             \"changeImmig\", \"changeImmigLab\",\n",
    "             \"govtHandleImmig\", \"labHandleImmig\",\n",
    "             \"asylumMore\", \"euMore\", \"noneuMore\", \"studentsMore\", \"familiesMore\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.empty( (10,10) )\n",
    "number_of_waves = 13\n",
    "imvars_by_waves = pd.DataFrame(np.full( ( len(imvar_list),number_of_waves), np.nan),\n",
    "                  columns = [\"W\"+str(x) for x in range(1,number_of_waves+1)],\n",
    "                  index = imvar_list ).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BES_Panel[immig_vars[0]].cat.codes.max()\n",
    "# max_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for im_var in imvar_list:\n",
    "    immig_vars = [x for x in BES_Panel.columns if re.match(im_var+\"W\\d\",  x)]\n",
    "    wave_list = [x.split(im_var)[1] for x in immig_vars]\n",
    "\n",
    "    BES_immig = BES_Panel[immig_vars].replace(\"Don't know\",np.nan).apply(lambda x: x.cat.codes).replace(-1,np.nan)\n",
    "#     print(immig_vars, wave_list)\n",
    "    max_range = len(BES_Panel[immig_vars[0]].cat.categories.drop(\"Don't know\",errors='ignore'))-1\n",
    "    print(immig_vars[0], max_range)\n",
    "    for wave in wave_list:\n",
    "        wt_new = \"wt_new_\"+wave\n",
    "        wt_old = \"wt_full_\"+wave\n",
    "        if wt_new in BES_Panel.columns:\n",
    "            wt = BES_Panel[wt_new]\n",
    "        else:\n",
    "            wt = BES_Panel[wt_old]\n",
    "        imvars_by_waves.loc[wave,im_var] = (BES_immig[im_var+wave].multiply(wt).mean())/max_range\n",
    "        \n",
    "    top_cat = BES_Panel[immig_vars[0]].cat.categories.drop(\"Don't know\",errors='ignore')[-1]\n",
    "    imvars_by_waves.rename(index=str, columns={im_var: im_var + \"_\" + top_cat}, inplace=True)\n",
    "\n",
    "imvars_by_waves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(imvars_by_waves.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imvars_by_waves.index[imvars_by_waves[imvar].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # multiple line plot\n",
    "# # create a color palette\n",
    "# palette = plt.get_cmap('Set1')\n",
    "# # style\n",
    "# plt.style.use('seaborn-darkgrid')\n",
    "# f = plt.figure(figsize=(10,10))\n",
    "\n",
    "# num=1\n",
    "# for imvar in imvars_by_waves.columns:\n",
    "# #     plt.plot( imvars_by_waves.index, imvars_by_waves[imvar], color=palette(num))\n",
    "#     g = sns.pointplot(imvars_by_waves.index, imvars_by_waves[imvar], color =cmap[num%(len(cmap))], label = imvar)\n",
    "# # plt.plot( 'x', 'y2', data=df, marker='', color='olive', linewidth=2)\n",
    "# # plt.plot( 'x', 'y3', data=df, marker='', color='olive', linewidth=2, linestyle='dashed', label=\"toto\")\n",
    "#     num=num+1\n",
    "# g.legend();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wave_dates.loc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wave_dates = BES_file_manifest[BES_file_manifest[\"Only_or_Combined\"]==\"Only\"][[\"Wave No\",\"Date_Start\"]].set_index(\"Wave No\")\n",
    "wave_dates = wave_dates.sort_index()\n",
    "wave_dates = wave_dates[\"Date_Start\"].apply(lambda x: pd.to_datetime(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date = pd.date_range(\"2017-03\", freq=\"M\", periods=15)\n",
    "# count = np.random.rand(15,4)\n",
    "# df1 = pd.DataFrame({\"date\":date, \"count\" : count[:,0]})\n",
    "# df2 = pd.DataFrame({\"date\":date, \"count\" : count[:,1]+0.7})\n",
    "# df3 = pd.DataFrame({\"date\":date, \"count\" : count[:,2]+2})\n",
    "\n",
    "f, ax = plt.subplots(1, 1, figsize=(10,10))\n",
    "# x_col='date'\n",
    "# y_col = 'count'\n",
    "num=1\n",
    "for imvar in imvars_by_waves.columns:\n",
    "    notnull_vals = imvars_by_waves[imvar].notnull()\n",
    "    if num<=10:\n",
    "        marker = 'o'\n",
    "    else:\n",
    "        marker = 'v'\n",
    "    \n",
    "    ax.plot_date(wave_dates.values[notnull_vals],\n",
    "                 imvars_by_waves[imvar][notnull_vals],\n",
    "                 color=cmap[num%len(cmap)],\n",
    "                 label=imvar,\n",
    "                 linestyle=\"-\",\n",
    "                 marker = marker)\n",
    "    num = num +1\n",
    "# ax.plot_date(wave_dates, df2[\"count\"], color=\"red\", label=\"B\", linestyle=\"-\")\n",
    "# ax.plot_date(wave_dates, df3[\"count\"], color=\"green\", label=\"C\", linestyle=\"-\")\n",
    "\n",
    "ax.legend(loc=\"upper left\", bbox_to_anchor=(1,1))\n",
    "# legend(loc=\"upper left\", bbox_to_anchor=(1,1))\n",
    "\n",
    "plt.gcf().autofmt_xdate()\n",
    "plt.axvline(x=wave_dates.loc[3], alpha=.9)\n",
    "plt.text(wave_dates.loc[3],.8,'Peak UKIP (post EU elec.)',rotation=45)\n",
    "plt.axvline(x=wave_dates.loc[8], alpha=.9)\n",
    "plt.text(wave_dates.loc[8],.8,'2016 EU referendum',rotation=45)\n",
    "\n",
    "dataset_citation = \"Source: \" + manifest[\"Citation\"].values[0]\n",
    "plt.annotate(dataset_citation, (0,0), (0, -40),\n",
    "                             xycoords='axes fraction', textcoords='offset points', va='top', fontsize = 7)  \n",
    "\n",
    "Treatment = \"W13_comb_imm_corr\"\n",
    "plt.savefig(BES_output_folder+ Treatment + os.sep + \"Immigration_variables_by_waves.png\",bbox_inches='tight');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDA on voters who switched/stayed\n",
    "# easier imm variables - immigEcon/immigCultural\n",
    "# W8 -> W10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[ x for x in BES_Panel.columns if \"immigEcon\" in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ImmBadW8 = (BES_Panel[\"immigEconW3\"]=='Bad for economy') & (BES_Panel[\"immigEconW4\"].notnull())\n",
    "ChangedMind = BES_Panel[ImmBadW8][\"immigEconW4\"] != 'Bad for economy'\n",
    "ChangedMind.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ImmBadW8 = (BES_Panel[\"immigEconW8\"]=='Bad for economy') & (BES_Panel[\"immigEconW10\"].notnull())\n",
    "ChangedMind = BES_Panel[ImmBadW8][\"immigEconW10\"] != 'Bad for economy'\n",
    "ChangedMind.value_counts()\n",
    "# pretty distinct!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BES_imm = BES_reduced[ImmBadW8]\n",
    "# BES_imm = BES_imm.drop([x for x in BES_imm.columns if \"immigEcon\" in x] , axis=1)\n",
    "# BES_imm = BES_imm.drop([x for x in BES_imm.columns if \"immigCultural\" in x] , axis=1)\n",
    "# BES_imm = BES_imm.drop([x for x in BES_imm.columns if \"immigSelf\" in x] , axis=1)\n",
    "# BES_imm = BES_imm.drop([x for x in BES_imm.columns if \"immigrantsWelfareState\" in x] , axis=1)\n",
    "# BES_imm = BES_imm.drop([x for x in BES_imm.columns if \"euPriorityBalance\" in x] , axis=1)\n",
    "# BES_imm = BES_imm.drop([x for x in BES_imm.columns if \"UKIP\" in x] , axis=1)\n",
    "\n",
    "# immigrantsWelfareState, UKIP, euPriorityBalance, immigSelf\n",
    "# weird stuff about passport variables!\n",
    "# BES_imm = BES_imm.drop([x for x in BES_imm.columns if \"passport\" in x] , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Treatment = \"AntiImmigrantThaw\"\n",
    "output_subfolder = BES_output_folder + Treatment + os.sep\n",
    "if not os.path.exists( output_subfolder ):\n",
    "    os.makedirs( output_subfolder )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.decomposition import PCA, IncrementalPCA, NMF, TruncatedSVD, FastICA, FactorAnalysis, SparsePCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "from gaussian_kde import gaussian_kde\n",
    "from utility import display_components, display_pca_data, weighted_kde\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalise data (subtract out the mean, divide through by standard deviation)\n",
    "clean_feature_set_std = StandardScaler().fit_transform(BES_imm.values )\n",
    "BES_std = pd.DataFrame(      clean_feature_set_std,\n",
    "                             columns = BES_imm.columns,\n",
    "                             index   = BES_imm.index      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "n_components = BES_std.shape[1]\n",
    "n_components = 1\n",
    "\n",
    "decomp = LinearDiscriminantAnalysis() ## ~10s ,n_components=30 -> 1.5 hrs\n",
    "decomp_method = str(decomp).split(\"(\")[0] \n",
    "\n",
    "X_r = decomp.fit_transform(BES_std, ChangedMind)\n",
    "\n",
    "BES_decomp = pd.DataFrame(   X_r,\n",
    "                             columns = range(0,n_components),\n",
    "                             index   = BES_imm.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# treatdir = BES_data_folder+Treatment\n",
    "# subdir = BES_data_folder+Treatment+decomp_method\n",
    "load_suff = \"LinearDiscriminatAnalysis\"\n",
    "save = True # False => Load\n",
    "\n",
    "if save & ( 'decomp' in globals() ): # SAVE    ##( 'decomp' not in globals() )\n",
    "    decomp_method = str(decomp).split(\"(\")[0] \n",
    "    subdir = output_subfolder + decomp_method\n",
    "    fname = subdir+ os.sep + decomp_method\n",
    "    # create dir, save decomp object, BES_decomp, BES_std    \n",
    "    if not os.path.exists(subdir): os.makedirs(subdir)\n",
    "    with open(fname+\".pkl\", \"wb\") as f: pickle.dump( decomp, f )\n",
    "#     BES_decomp.to_hdf(fname+\".hdf\"        , decomp_method)\n",
    "#     BES_std.to_hdf(   fname+\"_std\"+\".hdf\" , decomp_method)\n",
    "    \n",
    "else: # LOAD decomp results (default is SAVE)\n",
    "    decomp_method = load_suff\n",
    "    subdir = output_subfolder + os.sep + decomp_method    \n",
    "    fname = subdir + os.sep + decomp_method\n",
    "    if not os.path.exists(subdir): raise Exception(subdir + ' does not exist!')\n",
    "    # load decomp object, BES_decomp, BES_std, n_components\n",
    "    with open(fname+\".pkl\", \"rb\") as f: decomp = pickle.load(f) \n",
    "    BES_decomp = pd.read_hdf(fname+\".hdf\")\n",
    "    BES_std    = pd.read_hdf(fname+\"_std\"+\".hdf\")\n",
    "    n_components = decomp.components_.shape[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(BES_decomp, comp_labels, comp_dict) = display_components(n_components, decomp,\n",
    "                                                          BES_imm.columns, BES_decomp, manifest, \n",
    "                                                          save_folder = subdir,  \n",
    "                                                          show_first_x_comps= 4, show_histogram = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from statsmodels.stats.outliers_influence import variance_inflation_factor    \n",
    "\n",
    "# def calculate_vif_(X, thresh=100):\n",
    "#     cols = X.columns\n",
    "#     variables = np.arange(X.shape[1])\n",
    "#     dropped=True\n",
    "#     while dropped:\n",
    "#         dropped=False\n",
    "#         c = X[cols[variables]].values\n",
    "#         vif = [variance_inflation_factor(c, ix) for ix in np.arange(c.shape[1])]\n",
    "\n",
    "#         maxloc = vif.index(max(vif))\n",
    "#         if max(vif) > thresh:\n",
    "#             print('dropping \\'' + X[cols[variables]].columns[maxloc] + '\\' at index: ' + str(maxloc))\n",
    "#             variables = np.delete(variables, maxloc)\n",
    "#             dropped=True\n",
    "\n",
    "#     print('Remaining variables:')\n",
    "#     print(X.columns[variables])\n",
    "#     return X[cols[variables]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imm_corr = BES_imm.corrwith(ChangedMind).sort_values().dropna()\n",
    "# imm_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imm_corr = BES_imm.corrwith(ChangedMind).sort_values().dropna()\n",
    "imm_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imm_corr[[x for x in imm_corr.index if \"euRef\" in x]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# realignment by social conservatism?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BES_reduced[ [x for x in BES_reduced if \"immigEcon\" in x or \"al_scale\" in x] ].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "al_lazy = BES_reduced[ [x for x in BES_reduced if \"al_scale\" in x] ].mean(axis=1)\n",
    "BES_reduced[ [x for x in BES_reduced if \"immigCultural\" in x] ].corrwith(al_lazy, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "al2 = BES_reduced[ [x for x in BES_reduced if \"al2\" in x] ].mean(axis=1)\n",
    "BES_reduced[ [x for x in BES_reduced if \"immigCultural\" in x] ].corrwith(al2, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "al_lazy = BES_reduced[ [x for x in BES_reduced if \"al_scale\" in x] ].mean(axis=1)\n",
    "BES_reduced[ [x for x in BES_reduced if \"immigEcon\" in x] ].corrwith(al_lazy, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "al2 = BES_reduced[ [x for x in BES_reduced if \"al2\" in x] ].mean(axis=1)\n",
    "BES_reduced[ [x for x in BES_reduced if \"immigEcon\" in x] ].corrwith(al2, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "al_lazy = BES_reduced[ [x for x in BES_reduced if \"al_scale\" in x] ].mean(axis=1)\n",
    "BES_reduced[ [x for x in BES_reduced if \"immigSelf\" in x] ].corrwith(al_lazy, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "al_lazy = BES_reduced[ [x for x in BES_reduced if \"al_scale\" in x] ].mean(axis=1)\n",
    "BES_reduced[ [x for x in BES_reduced if \"immigrantsWelfareState\" in x] ].corrwith(al_lazy, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "al_lazy = BES_reduced[ [x for x in BES_reduced if \"al_scale\" in x] ].mean(axis=1)\n",
    "BES_reduced[ [x for x in BES_reduced if \"controlImmig\" in x] ].corrwith(al_lazy, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "al_lazy = BES_reduced[ [x for x in BES_reduced if \"al_scale\" in x] ].mean(axis=1)\n",
    "BES_reduced[ [x for x in BES_reduced if \"effectsEUImmigration\" in x] ].corrwith(al_lazy, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "al_lazy = BES_reduced[ [x for x in BES_reduced if \"al_scale\" in x] ].mean(axis=1)\n",
    "BES_reduced[ [x for x in BES_reduced if \"euPriorityBalance\" in x] ].corrwith(al_lazy, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "al_lazy = BES_reduced[ [x for x in BES_reduced if \"al_scale\" in x] ].mean(axis=1)\n",
    "BES_reduced[ [x for x in BES_reduced if \"changeImmig\" in x] ].corrwith(al_lazy, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "al_lazy = BES_reduced[ [x for x in BES_reduced if \"al_scale\" in x] ].mean(axis=1)\n",
    "BES_reduced[ [x for x in BES_reduced if \"euMore\" in x] ].corrwith(al_lazy, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_corr = BES_reduced.corrwith(al_lazy, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_corr.drop([x for x in BES_reduced.columns if \"al\" in x]).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add these later!\n",
    "[x for x in BES_Panel.columns if \"More\" in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
