Tuesday
=======

Imm vs Sov

* crosstabs!

* wpca/epca -> pan dataset variables

* categorical density plot


- summarise list of vars by stub!
- shorten variables and put a clear [...]
- remove v high correlates

Untitled 10

* get diff / get base
* xgboost


* Welshness/regional corr.


Random Graphs

* climate change

* simple corr graphs

* categorical density plot















from wpca import PCA, WPCA, EMPCA
# train.sample(10,axis=1)
target.shape

small_train = train.copy()#.sample(1000,axis=1)
# PCA: 2 mins 40s
small_train.shape

small_train = small_train[intersection(small_train.columns,BES_reduced_with_na.columns)]
small_train.drop(small_train.columns[small_train.var()<.5],axis=1,inplace=True)

weights = BES_reduced_with_na[small_train.columns].loc[small_train.index].notnull().astype('float')
weights.shape

weights[weights==0] = 0.01

n_components=10

%%time

decomp = WPCA(n_components=n_components)
decomp_method = str(decomp).split("(")[0] 

X_r = decomp.fit_transform(small_train, weights = weights)

n_components = X_r.shape[1]

BES_decomp = pd.DataFrame(   X_r,
                             columns = range(0,n_components),
                             index   = train.index)
# print("Score: ", decomp.score(train, target))

load_suff = decomp_method
save = True # False => Load
subdir = save_load_decomp(decomp, BES_decomp, train, load_suff, save)


(BES_decomp, comp_labels, comp_dict) = display_components(n_components, decomp,
                                                          small_train.columns, BES_decomp, manifest, 
                                                          save_folder = subdir,  
                                                          show_first_x_comps= 4, show_histogram = False)
                                                          
gc.collect()






###############################################







# [53]	validation_0-rmse:0.451407

# MSE: 0.20, MAE: 0.40, EV: 0.18, R2: 0.18
# SCORE: 0.451407
# ------------------------------------
# The best hyperparameters are:  

# {'colsample_bytree': 0.7000000000000001, 'gamma': 0.65, 'learning_rate': 0.2, 'max_depth': 1, 'min_child_weight': 4.0, 'n_estimators': 891.0, 'subsample': 0.7000000000000001}
# Wall time: 10min 12s


# [439]	validation_0-rmse:0.445123
# Stopping. Best iteration:
# [272]	validation_0-rmse:0.440647

# MSE: 0.20, MAE: 0.40, EV: 0.21, R2: 0.21
# SCORE: 0.440647

# The best hyperparameters are:  

# {'colsample_bylevel': 0.8250000000000001, 'colsample_bytree': 0.625, 'gamma': 0.75, 'learning_rate': 0.15000000000000002, 'max_depth': 0, 'min_child_weight': 8.0, 'n_estimators': 1566, 'subsample': 0.75}
# Wall time: 8h 17min 46s